//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_75
.address_size 64

	// .globl	_cross_entropy_backward
.global .align 1 .b8 _$_str[11] = {95, 95, 67, 85, 68, 65, 95, 70, 84, 90};

.visible .entry _cross_entropy_backward(
	.param .u64 _cross_entropy_backward_param_0,
	.param .u32 _cross_entropy_backward_param_1,
	.param .u64 _cross_entropy_backward_param_2,
	.param .u32 _cross_entropy_backward_param_3,
	.param .u64 _cross_entropy_backward_param_4,
	.param .u64 _cross_entropy_backward_param_5,
	.param .u32 _cross_entropy_backward_param_6,
	.param .u8 _cross_entropy_backward_param_7,
	.param .u32 _cross_entropy_backward_param_8,
	.param .u8 _cross_entropy_backward_param_9,
	.param .u32 _cross_entropy_backward_param_10
)
.maxntid 256, 1, 1
{
	.reg .pred 	%p<67>;
	.reg .b16 	%rs<37>;
	.reg .b32 	%r<201>;
	.reg .f32 	%f<805>;
	.reg .b64 	%rd<25>;
	.loc	1 187 0
$L__func_begin0:
	.loc	1 187 0

	ld.param.u8 	%rs1, [_cross_entropy_backward_param_9];
	and.b16  	%rs2, %rs1, 1;
	setp.eq.b16 	%p2, %rs2, 1;
	ld.param.u8 	%rs3, [_cross_entropy_backward_param_7];
	and.b16  	%rs4, %rs3, 1;
	setp.eq.b16 	%p1, %rs4, 1;
	ld.param.u32 	%r21, [_cross_entropy_backward_param_10];
	ld.param.u32 	%r19, [_cross_entropy_backward_param_6];
	ld.param.u64 	%rd9, [_cross_entropy_backward_param_0];
	ld.param.u32 	%r24, [_cross_entropy_backward_param_1];
$L__tmp0:
	.loc	1 216 30
	// begin inline asm
	mov.u32 %r22, %ctaid.x;
	// end inline asm
	.loc	1 217 30
	// begin inline asm
	mov.u32 %r23, %ctaid.y;
	// end inline asm
	.loc	1 219 28
	mul.wide.s32 	%rd11, %r22, %r24;
	ld.param.u64 	%rd12, [_cross_entropy_backward_param_5];
	.loc	1 219 18
	shl.b64 	%rd13, %rd11, 1;
	add.s64 	%rd2, %rd9, %rd13;
	.loc	1 221 28
	shl.b32 	%r26, %r23, 12;
	.loc	1 221 54
	mov.u32 	%r27, %tid.x;
	shl.b32 	%r28, %r27, 3;
	and.b32  	%r29, %r28, 2040;
	.loc	1 221 41
	or.b32  	%r1, %r26, %r29;
	or.b32  	%r9, %r1, 2048;
	.loc	1 223 37
	mul.wide.s32 	%rd14, %r22, 8;
	add.s64 	%rd8, %rd12, %rd14;
	mov.pred 	%p3, -1;
	.loc	1 223 24
	// begin inline asm
	mov.u64 %rd7, 0x0;
	@%p3 ld.global.b64 { %rd7 }, [ %rd8 + 0 ];
	// end inline asm
	.loc	1 223 49
	cvt.u32.u64 	%r18, %rd7;
	.loc	1 225 20
	setp.eq.s32 	%p4, %r18, -100;
	mov.f32 	%f756, 0f00000000;
	.loc	1 225 7
	@%p4 bra 	$L__BB0_2;
	.loc	1 0 7
	ld.param.u64 	%rd10, [_cross_entropy_backward_param_2];
	ld.param.u32 	%r25, [_cross_entropy_backward_param_3];
	mul.lo.s32 	%r30, %r22, %r25;
	mul.wide.s32 	%rd15, %r30, 4;
	add.s64 	%rd16, %rd10, %rd15;
	.loc	1 226 24
	// begin inline asm
	mov.u32 %r31, 0x0;
	@%p3 ld.global.b32 { %r31 }, [ %rd16 + 0 ];
	// end inline asm
	mov.b32 	%f756, %r31;
$L__BB0_2:
	.loc	1 0 24
	ld.param.u64 	%rd6, [_cross_entropy_backward_param_4];
	cvt.s64.s32 	%rd1, %r22;
	or.b32  	%r8, %r1, 7;
	or.b32  	%r7, %r1, 6;
	or.b32  	%r6, %r1, 5;
	or.b32  	%r5, %r1, 4;
	or.b32  	%r4, %r1, 3;
	or.b32  	%r3, %r1, 2;
	or.b32  	%r2, %r1, 1;
	or.b32  	%r10, %r1, 2049;
	or.b32  	%r11, %r1, 2050;
	or.b32  	%r12, %r1, 2051;
	or.b32  	%r13, %r1, 2052;
	or.b32  	%r14, %r1, 2053;
	or.b32  	%r15, %r1, 2054;
	or.b32  	%r16, %r1, 2055;
	.loc	1 222 25
	setp.lt.s32 	%p11, %r9, %r19;
	setp.lt.s32 	%p6, %r1, %r19;
	.loc	1 230 29
	mul.wide.s32 	%rd19, %r1, 2;
	add.s64 	%rd22, %rd2, %rd19;
	mul.wide.s32 	%rd20, %r9, 2;
	add.s64 	%rd23, %rd2, %rd20;
	mov.b32 	%r36, -67044352;
	.loc	1 230 16
	// begin inline asm
	mov.u32 %r32, 0x0;
	mov.u32 %r33, 0x0;
	mov.u32 %r34, 0x0;
	mov.u32 %r35, 0x0;
	@%p6 ld.global.v4.b32 { %r32, %r33, %r34, %r35 }, [ %rd22 + 0 ];
	@!%p6 mov.u32 %r32, %r36;
	@!%p6 mov.u32 %r33, %r36;
	@!%p6 mov.u32 %r34, %r36;
	@!%p6 mov.u32 %r35, %r36;
	// end inline asm
	// begin inline asm
	mov.u32 %r40, 0x0;
	mov.u32 %r41, 0x0;
	mov.u32 %r42, 0x0;
	mov.u32 %r43, 0x0;
	@%p11 ld.global.v4.b32 { %r40, %r41, %r42, %r43 }, [ %rd23 + 0 ];
	@!%p11 mov.u32 %r40, %r36;
	@!%p11 mov.u32 %r41, %r36;
	@!%p11 mov.u32 %r42, %r36;
	@!%p11 mov.u32 %r43, %r36;
	// end inline asm
	.loc	1 230 81
	mov.b32 	{%rs5, %rs6}, %r35;
	cvt.f32.f16 	%f181, %rs6;
	cvt.f32.f16 	%f182, %rs5;
	mov.b32 	{%rs7, %rs8}, %r34;
	cvt.f32.f16 	%f183, %rs8;
	cvt.f32.f16 	%f184, %rs7;
	mov.b32 	{%rs9, %rs10}, %r33;
	cvt.f32.f16 	%f185, %rs10;
	cvt.f32.f16 	%f186, %rs9;
	mov.b32 	{%rs11, %rs12}, %r32;
	cvt.f32.f16 	%f187, %rs12;
	cvt.f32.f16 	%f188, %rs11;
	mov.b32 	{%rs13, %rs14}, %r43;
	cvt.f32.f16 	%f189, %rs14;
	cvt.f32.f16 	%f190, %rs13;
	mov.b32 	{%rs15, %rs16}, %r42;
	cvt.f32.f16 	%f191, %rs16;
	cvt.f32.f16 	%f192, %rs15;
	mov.b32 	{%rs17, %rs18}, %r41;
	cvt.f32.f16 	%f193, %rs18;
	cvt.f32.f16 	%f194, %rs17;
	mov.b32 	{%rs19, %rs20}, %r40;
	cvt.f32.f16 	%f195, %rs20;
	cvt.f32.f16 	%f196, %rs19;
	.loc	1 233 7
	cvt.rn.f32.s32 	%f3, %r21;
	mul.f32 	%f197, %f3, %f196;
	mul.f32 	%f198, %f3, %f195;
	mul.f32 	%f199, %f3, %f194;
	mul.f32 	%f200, %f3, %f193;
	mul.f32 	%f201, %f3, %f192;
	mul.f32 	%f202, %f3, %f191;
	mul.f32 	%f203, %f3, %f190;
	mul.f32 	%f204, %f3, %f189;
	mul.f32 	%f205, %f3, %f188;
	mul.f32 	%f206, %f3, %f187;
	mul.f32 	%f207, %f3, %f186;
	mul.f32 	%f208, %f3, %f185;
	mul.f32 	%f209, %f3, %f184;
	mul.f32 	%f210, %f3, %f183;
	mul.f32 	%f211, %f3, %f182;
	mul.f32 	%f212, %f3, %f181;
	selp.f32 	%f780, %f212, %f181, %p2;
	selp.f32 	%f779, %f211, %f182, %p2;
	selp.f32 	%f778, %f210, %f183, %p2;
	selp.f32 	%f777, %f209, %f184, %p2;
	selp.f32 	%f776, %f208, %f185, %p2;
	selp.f32 	%f775, %f207, %f186, %p2;
	selp.f32 	%f774, %f206, %f187, %p2;
	selp.f32 	%f773, %f205, %f188, %p2;
	selp.f32 	%f788, %f204, %f189, %p2;
	selp.f32 	%f787, %f203, %f190, %p2;
	selp.f32 	%f786, %f202, %f191, %p2;
	selp.f32 	%f785, %f201, %f192, %p2;
	selp.f32 	%f784, %f200, %f193, %p2;
	selp.f32 	%f783, %f199, %f194, %p2;
	selp.f32 	%f782, %f198, %f195, %p2;
	selp.f32 	%f781, %f197, %f196, %p2;
	mov.f32 	%f789, %f773;
	mov.f32 	%f790, %f774;
	mov.f32 	%f791, %f775;
	mov.f32 	%f792, %f776;
	mov.f32 	%f793, %f777;
	mov.f32 	%f794, %f778;
	mov.f32 	%f795, %f779;
	mov.f32 	%f796, %f780;
	mov.f32 	%f797, %f781;
	mov.f32 	%f798, %f782;
	mov.f32 	%f799, %f783;
	mov.f32 	%f800, %f784;
	mov.f32 	%f801, %f785;
	mov.f32 	%f802, %f786;
	mov.f32 	%f803, %f787;
	mov.f32 	%f804, %f788;
	.loc	1 240 7
	@!%p1 bra 	$L__BB0_52;
	bra.uni 	$L__BB0_3;
$L__BB0_3:
	.loc	1 0 7
	ld.param.u32 	%r20, [_cross_entropy_backward_param_8];
	.loc	1 242 34
	cvt.rn.f32.s32 	%f35, %r20;
	mov.b32 	%r57, %f773;
	mov.b32 	%r58, %f35;
	// begin inline asm
	div.full.f32 %r185, %r57, %r58;
	// end inline asm
	mov.b32 	%f36, %r185;
	mov.b32 	%r60, %f774;
	// begin inline asm
	div.full.f32 %r186, %r60, %r58;
	// end inline asm
	mov.b32 	%f37, %r186;
	mov.b32 	%r63, %f775;
	// begin inline asm
	div.full.f32 %r187, %r63, %r58;
	// end inline asm
	mov.b32 	%r66, %f776;
	.loc	1 242 30
	abs.ftz.f32 	%f52, %f36;
	setp.ltu.f32 	%p16, %f52, 0f3F19999A;
	mov.f32 	%f694, 0f3F800000;
	mov.f32 	%f695, 0fC0000000;
	mov.f32 	%f752, 0fBD563CAE;
	mov.f32 	%f753, 0f3C80F082;
	mov.f32 	%f754, 0f3E085941;
	mov.f32 	%f755, 0fBEAAA9ED;
	@%p16 bra 	$L__BB0_5;
	bra.uni 	$L__BB0_4;
$L__BB0_5:
	mul.f32 	%f221, %f36, %f36;
	fma.rn.ftz.f32 	%f224, %f753, %f221, %f752;
	fma.rn.ftz.f32 	%f226, %f224, %f221, %f754;
	fma.rn.ftz.f32 	%f228, %f226, %f221, %f755;
	mov.f32 	%f229, 0f00000000;
	fma.rn.ftz.f32 	%f230, %f228, %f221, %f229;
	fma.rn.ftz.f32 	%f773, %f230, %f36, %f36;
	bra.uni 	$L__BB0_6;
$L__BB0_4:
	mul.f32 	%f215, %f52, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f216, %f215;
	add.f32 	%f214, %f216, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f213,%f214;
	// end inline asm
	fma.rn.ftz.f32 	%f219, %f213, %f695, %f694;
	setp.ge.f32 	%p17, %f52, 0f41102CB4;
	selp.f32 	%f220, 0f3F800000, %f219, %p17;
	mov.b32 	%r104, %f220;
	and.b32  	%r106, %r185, -2147483648;
	or.b32  	%r107, %r106, %r104;
	mov.b32 	%f773, %r107;
$L__BB0_6:
	.loc	1 242 0
	mov.b32 	%r69, %f777;
	// begin inline asm
	div.full.f32 %r188, %r66, %r58;
	// end inline asm
	mov.b32 	%f38, %r187;
	.loc	1 242 30
	abs.ftz.f32 	%f56, %f37;
	setp.ltu.f32 	%p18, %f56, 0f3F19999A;
	@%p18 bra 	$L__BB0_8;
	bra.uni 	$L__BB0_7;
$L__BB0_8:
	mul.f32 	%f239, %f37, %f37;
	fma.rn.ftz.f32 	%f242, %f753, %f239, %f752;
	fma.rn.ftz.f32 	%f244, %f242, %f239, %f754;
	fma.rn.ftz.f32 	%f246, %f244, %f239, %f755;
	mov.f32 	%f247, 0f00000000;
	fma.rn.ftz.f32 	%f248, %f246, %f239, %f247;
	fma.rn.ftz.f32 	%f774, %f248, %f37, %f37;
	bra.uni 	$L__BB0_9;
$L__BB0_7:
	mul.f32 	%f233, %f56, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f234, %f233;
	add.f32 	%f232, %f234, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f231,%f232;
	// end inline asm
	fma.rn.ftz.f32 	%f237, %f231, %f695, %f694;
	setp.ge.f32 	%p19, %f56, 0f41102CB4;
	selp.f32 	%f238, 0f3F800000, %f237, %p19;
	mov.b32 	%r108, %f238;
	and.b32  	%r110, %r186, -2147483648;
	or.b32  	%r111, %r110, %r108;
	mov.b32 	%f774, %r111;
$L__BB0_9:
	.loc	1 242 0
	mov.b32 	%r72, %f778;
	// begin inline asm
	div.full.f32 %r189, %r69, %r58;
	// end inline asm
	mov.b32 	%f39, %r188;
	.loc	1 242 30
	abs.ftz.f32 	%f60, %f38;
	setp.ltu.f32 	%p20, %f60, 0f3F19999A;
	@%p20 bra 	$L__BB0_11;
	bra.uni 	$L__BB0_10;
$L__BB0_11:
	mul.f32 	%f257, %f38, %f38;
	fma.rn.ftz.f32 	%f260, %f753, %f257, %f752;
	fma.rn.ftz.f32 	%f262, %f260, %f257, %f754;
	fma.rn.ftz.f32 	%f264, %f262, %f257, %f755;
	mov.f32 	%f265, 0f00000000;
	fma.rn.ftz.f32 	%f266, %f264, %f257, %f265;
	fma.rn.ftz.f32 	%f775, %f266, %f38, %f38;
	bra.uni 	$L__BB0_12;
$L__BB0_10:
	mul.f32 	%f251, %f60, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f252, %f251;
	add.f32 	%f250, %f252, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f249,%f250;
	// end inline asm
	fma.rn.ftz.f32 	%f255, %f249, %f695, %f694;
	setp.ge.f32 	%p21, %f60, 0f41102CB4;
	selp.f32 	%f256, 0f3F800000, %f255, %p21;
	mov.b32 	%r112, %f256;
	and.b32  	%r114, %r187, -2147483648;
	or.b32  	%r115, %r114, %r112;
	mov.b32 	%f775, %r115;
$L__BB0_12:
	.loc	1 242 0
	mov.b32 	%r75, %f779;
	// begin inline asm
	div.full.f32 %r190, %r72, %r58;
	// end inline asm
	mov.b32 	%f40, %r189;
	.loc	1 242 30
	abs.ftz.f32 	%f64, %f39;
	setp.ltu.f32 	%p22, %f64, 0f3F19999A;
	@%p22 bra 	$L__BB0_14;
	bra.uni 	$L__BB0_13;
$L__BB0_14:
	mul.f32 	%f275, %f39, %f39;
	fma.rn.ftz.f32 	%f278, %f753, %f275, %f752;
	fma.rn.ftz.f32 	%f280, %f278, %f275, %f754;
	fma.rn.ftz.f32 	%f282, %f280, %f275, %f755;
	mov.f32 	%f283, 0f00000000;
	fma.rn.ftz.f32 	%f284, %f282, %f275, %f283;
	fma.rn.ftz.f32 	%f776, %f284, %f39, %f39;
	bra.uni 	$L__BB0_15;
$L__BB0_13:
	mul.f32 	%f269, %f64, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f270, %f269;
	add.f32 	%f268, %f270, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f267,%f268;
	// end inline asm
	fma.rn.ftz.f32 	%f273, %f267, %f695, %f694;
	setp.ge.f32 	%p23, %f64, 0f41102CB4;
	selp.f32 	%f274, 0f3F800000, %f273, %p23;
	mov.b32 	%r116, %f274;
	and.b32  	%r118, %r188, -2147483648;
	or.b32  	%r119, %r118, %r116;
	mov.b32 	%f776, %r119;
$L__BB0_15:
	.loc	1 242 0
	mov.b32 	%r78, %f780;
	// begin inline asm
	div.full.f32 %r191, %r75, %r58;
	// end inline asm
	mov.b32 	%f41, %r190;
	.loc	1 242 30
	abs.ftz.f32 	%f68, %f40;
	setp.ltu.f32 	%p24, %f68, 0f3F19999A;
	@%p24 bra 	$L__BB0_17;
	bra.uni 	$L__BB0_16;
$L__BB0_17:
	mul.f32 	%f293, %f40, %f40;
	fma.rn.ftz.f32 	%f296, %f753, %f293, %f752;
	fma.rn.ftz.f32 	%f298, %f296, %f293, %f754;
	fma.rn.ftz.f32 	%f300, %f298, %f293, %f755;
	mov.f32 	%f301, 0f00000000;
	fma.rn.ftz.f32 	%f302, %f300, %f293, %f301;
	fma.rn.ftz.f32 	%f777, %f302, %f40, %f40;
	bra.uni 	$L__BB0_18;
$L__BB0_16:
	mul.f32 	%f287, %f68, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f288, %f287;
	add.f32 	%f286, %f288, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f285,%f286;
	// end inline asm
	fma.rn.ftz.f32 	%f291, %f285, %f695, %f694;
	setp.ge.f32 	%p25, %f68, 0f41102CB4;
	selp.f32 	%f292, 0f3F800000, %f291, %p25;
	mov.b32 	%r120, %f292;
	and.b32  	%r122, %r189, -2147483648;
	or.b32  	%r123, %r122, %r120;
	mov.b32 	%f777, %r123;
$L__BB0_18:
	.loc	1 242 0
	mov.b32 	%r81, %f781;
	// begin inline asm
	div.full.f32 %r192, %r78, %r58;
	// end inline asm
	mov.b32 	%f42, %r191;
	.loc	1 242 30
	abs.ftz.f32 	%f72, %f41;
	setp.ltu.f32 	%p26, %f72, 0f3F19999A;
	@%p26 bra 	$L__BB0_20;
	bra.uni 	$L__BB0_19;
$L__BB0_20:
	mul.f32 	%f311, %f41, %f41;
	fma.rn.ftz.f32 	%f314, %f753, %f311, %f752;
	fma.rn.ftz.f32 	%f316, %f314, %f311, %f754;
	fma.rn.ftz.f32 	%f318, %f316, %f311, %f755;
	mov.f32 	%f319, 0f00000000;
	fma.rn.ftz.f32 	%f320, %f318, %f311, %f319;
	fma.rn.ftz.f32 	%f778, %f320, %f41, %f41;
	bra.uni 	$L__BB0_21;
$L__BB0_19:
	mul.f32 	%f305, %f72, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f306, %f305;
	add.f32 	%f304, %f306, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f303,%f304;
	// end inline asm
	fma.rn.ftz.f32 	%f309, %f303, %f695, %f694;
	setp.ge.f32 	%p27, %f72, 0f41102CB4;
	selp.f32 	%f310, 0f3F800000, %f309, %p27;
	mov.b32 	%r124, %f310;
	and.b32  	%r126, %r190, -2147483648;
	or.b32  	%r127, %r126, %r124;
	mov.b32 	%f778, %r127;
$L__BB0_21:
	.loc	1 242 0
	mov.b32 	%r84, %f782;
	// begin inline asm
	div.full.f32 %r193, %r81, %r58;
	// end inline asm
	mov.b32 	%f43, %r192;
	.loc	1 242 30
	abs.ftz.f32 	%f76, %f42;
	setp.ltu.f32 	%p28, %f76, 0f3F19999A;
	@%p28 bra 	$L__BB0_23;
	bra.uni 	$L__BB0_22;
$L__BB0_23:
	mul.f32 	%f329, %f42, %f42;
	fma.rn.ftz.f32 	%f332, %f753, %f329, %f752;
	fma.rn.ftz.f32 	%f334, %f332, %f329, %f754;
	fma.rn.ftz.f32 	%f336, %f334, %f329, %f755;
	mov.f32 	%f337, 0f00000000;
	fma.rn.ftz.f32 	%f338, %f336, %f329, %f337;
	fma.rn.ftz.f32 	%f779, %f338, %f42, %f42;
	bra.uni 	$L__BB0_24;
$L__BB0_22:
	mul.f32 	%f323, %f76, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f324, %f323;
	add.f32 	%f322, %f324, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f321,%f322;
	// end inline asm
	fma.rn.ftz.f32 	%f327, %f321, %f695, %f694;
	setp.ge.f32 	%p29, %f76, 0f41102CB4;
	selp.f32 	%f328, 0f3F800000, %f327, %p29;
	mov.b32 	%r128, %f328;
	and.b32  	%r130, %r191, -2147483648;
	or.b32  	%r131, %r130, %r128;
	mov.b32 	%f779, %r131;
$L__BB0_24:
	.loc	1 242 0
	mov.b32 	%r87, %f783;
	// begin inline asm
	div.full.f32 %r194, %r84, %r58;
	// end inline asm
	mov.b32 	%f44, %r193;
	.loc	1 242 30
	abs.ftz.f32 	%f80, %f43;
	setp.ltu.f32 	%p30, %f80, 0f3F19999A;
	@%p30 bra 	$L__BB0_26;
	bra.uni 	$L__BB0_25;
$L__BB0_26:
	mul.f32 	%f347, %f43, %f43;
	fma.rn.ftz.f32 	%f350, %f753, %f347, %f752;
	fma.rn.ftz.f32 	%f352, %f350, %f347, %f754;
	fma.rn.ftz.f32 	%f354, %f352, %f347, %f755;
	mov.f32 	%f355, 0f00000000;
	fma.rn.ftz.f32 	%f356, %f354, %f347, %f355;
	fma.rn.ftz.f32 	%f780, %f356, %f43, %f43;
	bra.uni 	$L__BB0_27;
$L__BB0_25:
	mul.f32 	%f341, %f80, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f342, %f341;
	add.f32 	%f340, %f342, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f339,%f340;
	// end inline asm
	fma.rn.ftz.f32 	%f345, %f339, %f695, %f694;
	setp.ge.f32 	%p31, %f80, 0f41102CB4;
	selp.f32 	%f346, 0f3F800000, %f345, %p31;
	mov.b32 	%r132, %f346;
	and.b32  	%r134, %r192, -2147483648;
	or.b32  	%r135, %r134, %r132;
	mov.b32 	%f780, %r135;
$L__BB0_27:
	.loc	1 242 0
	mov.b32 	%r90, %f784;
	// begin inline asm
	div.full.f32 %r195, %r87, %r58;
	// end inline asm
	mov.b32 	%f45, %r194;
	.loc	1 242 30
	abs.ftz.f32 	%f84, %f44;
	setp.ltu.f32 	%p32, %f84, 0f3F19999A;
	@%p32 bra 	$L__BB0_29;
	bra.uni 	$L__BB0_28;
$L__BB0_29:
	mul.f32 	%f365, %f44, %f44;
	fma.rn.ftz.f32 	%f368, %f753, %f365, %f752;
	fma.rn.ftz.f32 	%f370, %f368, %f365, %f754;
	fma.rn.ftz.f32 	%f372, %f370, %f365, %f755;
	mov.f32 	%f373, 0f00000000;
	fma.rn.ftz.f32 	%f374, %f372, %f365, %f373;
	fma.rn.ftz.f32 	%f781, %f374, %f44, %f44;
	bra.uni 	$L__BB0_30;
$L__BB0_28:
	mul.f32 	%f359, %f84, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f360, %f359;
	add.f32 	%f358, %f360, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f357,%f358;
	// end inline asm
	fma.rn.ftz.f32 	%f363, %f357, %f695, %f694;
	setp.ge.f32 	%p33, %f84, 0f41102CB4;
	selp.f32 	%f364, 0f3F800000, %f363, %p33;
	mov.b32 	%r136, %f364;
	and.b32  	%r138, %r193, -2147483648;
	or.b32  	%r139, %r138, %r136;
	mov.b32 	%f781, %r139;
$L__BB0_30:
	.loc	1 242 0
	mov.b32 	%r93, %f785;
	// begin inline asm
	div.full.f32 %r196, %r90, %r58;
	// end inline asm
	mov.b32 	%f46, %r195;
	.loc	1 242 30
	abs.ftz.f32 	%f88, %f45;
	setp.ltu.f32 	%p34, %f88, 0f3F19999A;
	@%p34 bra 	$L__BB0_32;
	bra.uni 	$L__BB0_31;
$L__BB0_32:
	mul.f32 	%f383, %f45, %f45;
	fma.rn.ftz.f32 	%f386, %f753, %f383, %f752;
	fma.rn.ftz.f32 	%f388, %f386, %f383, %f754;
	fma.rn.ftz.f32 	%f390, %f388, %f383, %f755;
	mov.f32 	%f391, 0f00000000;
	fma.rn.ftz.f32 	%f392, %f390, %f383, %f391;
	fma.rn.ftz.f32 	%f782, %f392, %f45, %f45;
	bra.uni 	$L__BB0_33;
$L__BB0_31:
	mul.f32 	%f377, %f88, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f378, %f377;
	add.f32 	%f376, %f378, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f375,%f376;
	// end inline asm
	fma.rn.ftz.f32 	%f381, %f375, %f695, %f694;
	setp.ge.f32 	%p35, %f88, 0f41102CB4;
	selp.f32 	%f382, 0f3F800000, %f381, %p35;
	mov.b32 	%r140, %f382;
	and.b32  	%r142, %r194, -2147483648;
	or.b32  	%r143, %r142, %r140;
	mov.b32 	%f782, %r143;
$L__BB0_33:
	.loc	1 242 0
	mov.b32 	%r96, %f786;
	// begin inline asm
	div.full.f32 %r197, %r93, %r58;
	// end inline asm
	mov.b32 	%f47, %r196;
	.loc	1 242 30
	abs.ftz.f32 	%f92, %f46;
	setp.ltu.f32 	%p36, %f92, 0f3F19999A;
	@%p36 bra 	$L__BB0_35;
	bra.uni 	$L__BB0_34;
$L__BB0_35:
	mul.f32 	%f401, %f46, %f46;
	fma.rn.ftz.f32 	%f404, %f753, %f401, %f752;
	fma.rn.ftz.f32 	%f406, %f404, %f401, %f754;
	fma.rn.ftz.f32 	%f408, %f406, %f401, %f755;
	mov.f32 	%f409, 0f00000000;
	fma.rn.ftz.f32 	%f410, %f408, %f401, %f409;
	fma.rn.ftz.f32 	%f783, %f410, %f46, %f46;
	bra.uni 	$L__BB0_36;
$L__BB0_34:
	mul.f32 	%f395, %f92, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f396, %f395;
	add.f32 	%f394, %f396, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f393,%f394;
	// end inline asm
	fma.rn.ftz.f32 	%f399, %f393, %f695, %f694;
	setp.ge.f32 	%p37, %f92, 0f41102CB4;
	selp.f32 	%f400, 0f3F800000, %f399, %p37;
	mov.b32 	%r144, %f400;
	and.b32  	%r146, %r195, -2147483648;
	or.b32  	%r147, %r146, %r144;
	mov.b32 	%f783, %r147;
$L__BB0_36:
	.loc	1 242 0
	mov.b32 	%r99, %f787;
	// begin inline asm
	div.full.f32 %r198, %r96, %r58;
	// end inline asm
	mov.b32 	%f48, %r197;
	.loc	1 242 30
	abs.ftz.f32 	%f96, %f47;
	setp.ltu.f32 	%p38, %f96, 0f3F19999A;
	@%p38 bra 	$L__BB0_38;
	bra.uni 	$L__BB0_37;
$L__BB0_38:
	mul.f32 	%f419, %f47, %f47;
	fma.rn.ftz.f32 	%f422, %f753, %f419, %f752;
	fma.rn.ftz.f32 	%f424, %f422, %f419, %f754;
	fma.rn.ftz.f32 	%f426, %f424, %f419, %f755;
	mov.f32 	%f427, 0f00000000;
	fma.rn.ftz.f32 	%f428, %f426, %f419, %f427;
	fma.rn.ftz.f32 	%f784, %f428, %f47, %f47;
	bra.uni 	$L__BB0_39;
$L__BB0_37:
	mul.f32 	%f413, %f96, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f414, %f413;
	add.f32 	%f412, %f414, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f411,%f412;
	// end inline asm
	fma.rn.ftz.f32 	%f417, %f411, %f695, %f694;
	setp.ge.f32 	%p39, %f96, 0f41102CB4;
	selp.f32 	%f418, 0f3F800000, %f417, %p39;
	mov.b32 	%r148, %f418;
	and.b32  	%r150, %r196, -2147483648;
	or.b32  	%r151, %r150, %r148;
	mov.b32 	%f784, %r151;
$L__BB0_39:
	.loc	1 242 0
	mov.b32 	%r102, %f788;
	// begin inline asm
	div.full.f32 %r199, %r99, %r58;
	// end inline asm
	mov.b32 	%f49, %r198;
	.loc	1 242 30
	abs.ftz.f32 	%f100, %f48;
	setp.ltu.f32 	%p40, %f100, 0f3F19999A;
	@%p40 bra 	$L__BB0_41;
	bra.uni 	$L__BB0_40;
$L__BB0_41:
	mul.f32 	%f437, %f48, %f48;
	fma.rn.ftz.f32 	%f440, %f753, %f437, %f752;
	fma.rn.ftz.f32 	%f442, %f440, %f437, %f754;
	fma.rn.ftz.f32 	%f444, %f442, %f437, %f755;
	mov.f32 	%f445, 0f00000000;
	fma.rn.ftz.f32 	%f446, %f444, %f437, %f445;
	fma.rn.ftz.f32 	%f785, %f446, %f48, %f48;
	bra.uni 	$L__BB0_42;
$L__BB0_40:
	mul.f32 	%f431, %f100, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f432, %f431;
	add.f32 	%f430, %f432, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f429,%f430;
	// end inline asm
	fma.rn.ftz.f32 	%f435, %f429, %f695, %f694;
	setp.ge.f32 	%p41, %f100, 0f41102CB4;
	selp.f32 	%f436, 0f3F800000, %f435, %p41;
	mov.b32 	%r152, %f436;
	and.b32  	%r154, %r197, -2147483648;
	or.b32  	%r155, %r154, %r152;
	mov.b32 	%f785, %r155;
$L__BB0_42:
	.loc	1 242 0
	// begin inline asm
	div.full.f32 %r200, %r102, %r58;
	// end inline asm
	mov.b32 	%f50, %r199;
	.loc	1 242 30
	abs.ftz.f32 	%f104, %f49;
	setp.ltu.f32 	%p42, %f104, 0f3F19999A;
	@%p42 bra 	$L__BB0_44;
	bra.uni 	$L__BB0_43;
$L__BB0_44:
	mul.f32 	%f455, %f49, %f49;
	fma.rn.ftz.f32 	%f458, %f753, %f455, %f752;
	fma.rn.ftz.f32 	%f460, %f458, %f455, %f754;
	fma.rn.ftz.f32 	%f462, %f460, %f455, %f755;
	mov.f32 	%f463, 0f00000000;
	fma.rn.ftz.f32 	%f464, %f462, %f455, %f463;
	fma.rn.ftz.f32 	%f786, %f464, %f49, %f49;
	bra.uni 	$L__BB0_45;
$L__BB0_43:
	mul.f32 	%f449, %f104, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f450, %f449;
	add.f32 	%f448, %f450, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f447,%f448;
	// end inline asm
	fma.rn.ftz.f32 	%f453, %f447, %f695, %f694;
	setp.ge.f32 	%p43, %f104, 0f41102CB4;
	selp.f32 	%f454, 0f3F800000, %f453, %p43;
	mov.b32 	%r156, %f454;
	and.b32  	%r158, %r198, -2147483648;
	or.b32  	%r159, %r158, %r156;
	mov.b32 	%f786, %r159;
$L__BB0_45:
	.loc	1 242 0
	mov.b32 	%f51, %r200;
	.loc	1 242 30
	abs.ftz.f32 	%f108, %f50;
	setp.ltu.f32 	%p44, %f108, 0f3F19999A;
	@%p44 bra 	$L__BB0_47;
	bra.uni 	$L__BB0_46;
$L__BB0_47:
	mul.f32 	%f473, %f50, %f50;
	fma.rn.ftz.f32 	%f476, %f753, %f473, %f752;
	fma.rn.ftz.f32 	%f478, %f476, %f473, %f754;
	fma.rn.ftz.f32 	%f480, %f478, %f473, %f755;
	mov.f32 	%f481, 0f00000000;
	fma.rn.ftz.f32 	%f482, %f480, %f473, %f481;
	fma.rn.ftz.f32 	%f787, %f482, %f50, %f50;
	bra.uni 	$L__BB0_48;
$L__BB0_46:
	mul.f32 	%f467, %f108, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f468, %f467;
	add.f32 	%f466, %f468, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f465,%f466;
	// end inline asm
	fma.rn.ftz.f32 	%f471, %f465, %f695, %f694;
	setp.ge.f32 	%p45, %f108, 0f41102CB4;
	selp.f32 	%f472, 0f3F800000, %f471, %p45;
	mov.b32 	%r160, %f472;
	and.b32  	%r162, %r199, -2147483648;
	or.b32  	%r163, %r162, %r160;
	mov.b32 	%f787, %r163;
$L__BB0_48:
	abs.ftz.f32 	%f112, %f51;
	setp.ltu.f32 	%p46, %f112, 0f3F19999A;
	@%p46 bra 	$L__BB0_50;
	bra.uni 	$L__BB0_49;
$L__BB0_50:
	mul.f32 	%f491, %f51, %f51;
	fma.rn.ftz.f32 	%f494, %f753, %f491, %f752;
	fma.rn.ftz.f32 	%f496, %f494, %f491, %f754;
	fma.rn.ftz.f32 	%f498, %f496, %f491, %f755;
	mov.f32 	%f499, 0f00000000;
	fma.rn.ftz.f32 	%f500, %f498, %f491, %f499;
	fma.rn.ftz.f32 	%f788, %f500, %f51, %f51;
	bra.uni 	$L__BB0_51;
$L__BB0_49:
	mul.f32 	%f485, %f112, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f486, %f485;
	add.f32 	%f484, %f486, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f483,%f484;
	// end inline asm
	fma.rn.ftz.f32 	%f489, %f483, %f695, %f694;
	setp.ge.f32 	%p47, %f112, 0f41102CB4;
	selp.f32 	%f490, 0f3F800000, %f489, %p47;
	mov.b32 	%r164, %f490;
	and.b32  	%r166, %r200, -2147483648;
	or.b32  	%r167, %r166, %r164;
	mov.b32 	%f788, %r167;
$L__BB0_51:
	.loc	1 243 22
	mul.f32 	%f804, %f788, %f35;
	mul.f32 	%f803, %f787, %f35;
	mul.f32 	%f802, %f786, %f35;
	mul.f32 	%f801, %f785, %f35;
	mul.f32 	%f800, %f784, %f35;
	mul.f32 	%f799, %f783, %f35;
	mul.f32 	%f798, %f782, %f35;
	mul.f32 	%f797, %f781, %f35;
	mul.f32 	%f796, %f780, %f35;
	mul.f32 	%f795, %f779, %f35;
	mul.f32 	%f794, %f778, %f35;
	mul.f32 	%f793, %f777, %f35;
	mul.f32 	%f792, %f776, %f35;
	mul.f32 	%f791, %f775, %f35;
	mul.f32 	%f790, %f774, %f35;
	mul.f32 	%f789, %f773, %f35;
$L__BB0_52:
	.loc	1 246 40
	shl.b64 	%rd24, %rd1, 2;
	add.s64 	%rd21, %rd6, %rd24;
	.loc	1 246 24
	// begin inline asm
	mov.u32 %r168, 0x0;
	@%p3 ld.global.b32 { %r168 }, [ %rd21 + 0 ];
	// end inline asm
	mov.b32 	%f533, %r168;
	.loc	1 247 19
	sub.f32 	%f534, %f789, %f533;
	sub.f32 	%f535, %f790, %f533;
	sub.f32 	%f536, %f791, %f533;
	sub.f32 	%f537, %f792, %f533;
	sub.f32 	%f538, %f793, %f533;
	sub.f32 	%f539, %f794, %f533;
	sub.f32 	%f540, %f795, %f533;
	sub.f32 	%f541, %f796, %f533;
	sub.f32 	%f542, %f797, %f533;
	sub.f32 	%f543, %f798, %f533;
	sub.f32 	%f544, %f799, %f533;
	sub.f32 	%f545, %f800, %f533;
	sub.f32 	%f546, %f801, %f533;
	sub.f32 	%f547, %f802, %f533;
	sub.f32 	%f548, %f803, %f533;
	sub.f32 	%f549, %f804, %f533;
	.loc	1 247 15
	mul.f32 	%f502, %f534, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f501, %f502;
	// end inline asm
	mul.f32 	%f504, %f535, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f503, %f504;
	// end inline asm
	mul.f32 	%f506, %f536, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f505, %f506;
	// end inline asm
	mul.f32 	%f508, %f537, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f507, %f508;
	// end inline asm
	mul.f32 	%f510, %f538, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f509, %f510;
	// end inline asm
	mul.f32 	%f512, %f539, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f511, %f512;
	// end inline asm
	mul.f32 	%f514, %f540, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f513, %f514;
	// end inline asm
	mul.f32 	%f516, %f541, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f515, %f516;
	// end inline asm
	mul.f32 	%f518, %f542, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f517, %f518;
	// end inline asm
	mul.f32 	%f520, %f543, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f519, %f520;
	// end inline asm
	mul.f32 	%f522, %f544, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f521, %f522;
	// end inline asm
	mul.f32 	%f524, %f545, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f523, %f524;
	// end inline asm
	mul.f32 	%f526, %f546, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f525, %f526;
	// end inline asm
	mul.f32 	%f528, %f547, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f527, %f528;
	// end inline asm
	mul.f32 	%f530, %f548, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f529, %f530;
	// end inline asm
	mul.f32 	%f532, %f549, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f531, %f532;
	// end inline asm
	.loc	1 249 23
	setp.eq.s32 	%p51, %r1, %r18;
	setp.eq.s32 	%p52, %r2, %r18;
	setp.eq.s32 	%p53, %r3, %r18;
	setp.eq.s32 	%p54, %r4, %r18;
	setp.eq.s32 	%p55, %r6, %r18;
	setp.eq.s32 	%p56, %r5, %r18;
	setp.eq.s32 	%p57, %r8, %r18;
	setp.eq.s32 	%p58, %r7, %r18;
	setp.eq.s32 	%p59, %r10, %r18;
	setp.eq.s32 	%p60, %r9, %r18;
	setp.eq.s32 	%p61, %r12, %r18;
	setp.eq.s32 	%p62, %r11, %r18;
	setp.eq.s32 	%p63, %r14, %r18;
	setp.eq.s32 	%p64, %r13, %r18;
	setp.eq.s32 	%p65, %r16, %r18;
	setp.eq.s32 	%p66, %r15, %r18;
	.loc	1 250 12
	add.f32 	%f550, %f501, 0fBF800000;
	add.f32 	%f551, %f503, 0fBF800000;
	add.f32 	%f552, %f505, 0fBF800000;
	add.f32 	%f553, %f507, 0fBF800000;
	add.f32 	%f554, %f511, 0fBF800000;
	add.f32 	%f555, %f509, 0fBF800000;
	add.f32 	%f556, %f515, 0fBF800000;
	add.f32 	%f557, %f513, 0fBF800000;
	add.f32 	%f558, %f519, 0fBF800000;
	add.f32 	%f559, %f517, 0fBF800000;
	add.f32 	%f560, %f523, 0fBF800000;
	add.f32 	%f561, %f521, 0fBF800000;
	add.f32 	%f562, %f527, 0fBF800000;
	add.f32 	%f563, %f525, 0fBF800000;
	add.f32 	%f564, %f531, 0fBF800000;
	add.f32 	%f565, %f529, 0fBF800000;
	.loc	1 251 8
	selp.f32 	%f566, %f565, %f529, %p66;
	selp.f32 	%f567, %f564, %f531, %p65;
	selp.f32 	%f568, %f563, %f525, %p64;
	selp.f32 	%f569, %f562, %f527, %p63;
	selp.f32 	%f570, %f561, %f521, %p62;
	selp.f32 	%f571, %f560, %f523, %p61;
	selp.f32 	%f572, %f559, %f517, %p60;
	selp.f32 	%f573, %f558, %f519, %p59;
	selp.f32 	%f574, %f557, %f513, %p58;
	selp.f32 	%f575, %f556, %f515, %p57;
	selp.f32 	%f576, %f555, %f509, %p56;
	selp.f32 	%f577, %f554, %f511, %p55;
	selp.f32 	%f578, %f553, %f507, %p54;
	selp.f32 	%f579, %f552, %f505, %p53;
	selp.f32 	%f580, %f551, %f503, %p52;
	selp.f32 	%f581, %f550, %f501, %p51;
	.loc	1 254 7
	mul.f32 	%f582, %f581, %f3;
	mul.f32 	%f583, %f580, %f3;
	mul.f32 	%f584, %f579, %f3;
	mul.f32 	%f585, %f578, %f3;
	mul.f32 	%f586, %f577, %f3;
	mul.f32 	%f587, %f576, %f3;
	mul.f32 	%f588, %f575, %f3;
	mul.f32 	%f589, %f574, %f3;
	mul.f32 	%f590, %f573, %f3;
	mul.f32 	%f591, %f572, %f3;
	mul.f32 	%f592, %f571, %f3;
	mul.f32 	%f593, %f570, %f3;
	mul.f32 	%f594, %f569, %f3;
	mul.f32 	%f595, %f568, %f3;
	mul.f32 	%f596, %f567, %f3;
	mul.f32 	%f597, %f566, %f3;
	selp.f32 	%f598, %f597, %f566, %p2;
	selp.f32 	%f599, %f596, %f567, %p2;
	selp.f32 	%f600, %f595, %f568, %p2;
	selp.f32 	%f601, %f594, %f569, %p2;
	selp.f32 	%f602, %f593, %f570, %p2;
	selp.f32 	%f603, %f592, %f571, %p2;
	selp.f32 	%f604, %f591, %f572, %p2;
	selp.f32 	%f605, %f590, %f573, %p2;
	selp.f32 	%f606, %f589, %f574, %p2;
	selp.f32 	%f607, %f588, %f575, %p2;
	selp.f32 	%f608, %f587, %f576, %p2;
	selp.f32 	%f609, %f586, %f577, %p2;
	selp.f32 	%f610, %f585, %f578, %p2;
	selp.f32 	%f611, %f584, %f579, %p2;
	selp.f32 	%f612, %f583, %f580, %p2;
	selp.f32 	%f613, %f582, %f581, %p2;
	.loc	1 259 7
	neg.f32 	%f614, %f787;
	fma.rn.f32 	%f615, %f614, %f787, 0f3F800000;
	neg.f32 	%f616, %f788;
	fma.rn.f32 	%f617, %f616, %f788, 0f3F800000;
	neg.f32 	%f618, %f785;
	fma.rn.f32 	%f619, %f618, %f785, 0f3F800000;
	neg.f32 	%f620, %f786;
	fma.rn.f32 	%f621, %f620, %f786, 0f3F800000;
	neg.f32 	%f622, %f783;
	fma.rn.f32 	%f623, %f622, %f783, 0f3F800000;
	neg.f32 	%f624, %f784;
	fma.rn.f32 	%f625, %f624, %f784, 0f3F800000;
	neg.f32 	%f626, %f781;
	fma.rn.f32 	%f627, %f626, %f781, 0f3F800000;
	neg.f32 	%f628, %f782;
	fma.rn.f32 	%f629, %f628, %f782, 0f3F800000;
	neg.f32 	%f630, %f779;
	fma.rn.f32 	%f631, %f630, %f779, 0f3F800000;
	neg.f32 	%f632, %f780;
	fma.rn.f32 	%f633, %f632, %f780, 0f3F800000;
	neg.f32 	%f634, %f777;
	fma.rn.f32 	%f635, %f634, %f777, 0f3F800000;
	neg.f32 	%f636, %f778;
	fma.rn.f32 	%f637, %f636, %f778, 0f3F800000;
	neg.f32 	%f638, %f776;
	fma.rn.f32 	%f639, %f638, %f776, 0f3F800000;
	neg.f32 	%f640, %f775;
	fma.rn.f32 	%f641, %f640, %f775, 0f3F800000;
	neg.f32 	%f642, %f774;
	fma.rn.f32 	%f643, %f642, %f774, 0f3F800000;
	neg.f32 	%f644, %f773;
	fma.rn.f32 	%f645, %f644, %f773, 0f3F800000;
	mul.f32 	%f646, %f645, %f613;
	mul.f32 	%f647, %f643, %f612;
	mul.f32 	%f648, %f641, %f611;
	mul.f32 	%f649, %f639, %f610;
	mul.f32 	%f650, %f637, %f609;
	mul.f32 	%f651, %f635, %f608;
	mul.f32 	%f652, %f633, %f607;
	mul.f32 	%f653, %f631, %f606;
	mul.f32 	%f654, %f629, %f605;
	mul.f32 	%f655, %f627, %f604;
	mul.f32 	%f656, %f625, %f603;
	mul.f32 	%f657, %f623, %f602;
	mul.f32 	%f658, %f621, %f601;
	mul.f32 	%f659, %f619, %f600;
	mul.f32 	%f660, %f617, %f599;
	mul.f32 	%f661, %f615, %f598;
	selp.f32 	%f662, %f661, %f598, %p1;
	selp.f32 	%f663, %f660, %f599, %p1;
	selp.f32 	%f664, %f659, %f600, %p1;
	selp.f32 	%f665, %f658, %f601, %p1;
	selp.f32 	%f666, %f657, %f602, %p1;
	selp.f32 	%f667, %f656, %f603, %p1;
	selp.f32 	%f668, %f655, %f604, %p1;
	selp.f32 	%f669, %f654, %f605, %p1;
	selp.f32 	%f670, %f653, %f606, %p1;
	selp.f32 	%f671, %f652, %f607, %p1;
	selp.f32 	%f672, %f651, %f608, %p1;
	selp.f32 	%f673, %f650, %f609, %p1;
	selp.f32 	%f674, %f649, %f610, %p1;
	selp.f32 	%f675, %f648, %f611, %p1;
	selp.f32 	%f676, %f647, %f612, %p1;
	selp.f32 	%f677, %f646, %f613, %p1;
	.loc	1 265 47
	mul.f32 	%f678, %f756, %f677;
	mul.f32 	%f679, %f756, %f676;
	.loc	1 265 39
	cvt.rn.f16.f32 	%rs21, %f679;
	cvt.rn.f16.f32 	%rs22, %f678;
	mov.b32 	%r177, {%rs22, %rs21};
	.loc	1 265 47
	mul.f32 	%f680, %f756, %f675;
	mul.f32 	%f681, %f756, %f674;
	.loc	1 265 39
	cvt.rn.f16.f32 	%rs23, %f681;
	cvt.rn.f16.f32 	%rs24, %f680;
	mov.b32 	%r178, {%rs24, %rs23};
	.loc	1 265 47
	mul.f32 	%f682, %f756, %f673;
	mul.f32 	%f683, %f756, %f672;
	.loc	1 265 39
	cvt.rn.f16.f32 	%rs25, %f683;
	cvt.rn.f16.f32 	%rs26, %f682;
	mov.b32 	%r179, {%rs25, %rs26};
	.loc	1 265 47
	mul.f32 	%f684, %f756, %f671;
	mul.f32 	%f685, %f756, %f670;
	.loc	1 265 39
	cvt.rn.f16.f32 	%rs27, %f685;
	cvt.rn.f16.f32 	%rs28, %f684;
	mov.b32 	%r180, {%rs27, %rs28};
	.loc	1 265 47
	mul.f32 	%f686, %f756, %f669;
	mul.f32 	%f687, %f756, %f668;
	.loc	1 265 39
	cvt.rn.f16.f32 	%rs29, %f687;
	cvt.rn.f16.f32 	%rs30, %f686;
	mov.b32 	%r181, {%rs29, %rs30};
	.loc	1 265 47
	mul.f32 	%f688, %f756, %f667;
	mul.f32 	%f689, %f756, %f666;
	.loc	1 265 39
	cvt.rn.f16.f32 	%rs31, %f689;
	cvt.rn.f16.f32 	%rs32, %f688;
	mov.b32 	%r182, {%rs31, %rs32};
	.loc	1 265 47
	mul.f32 	%f690, %f756, %f665;
	mul.f32 	%f691, %f756, %f664;
	.loc	1 265 39
	cvt.rn.f16.f32 	%rs33, %f691;
	cvt.rn.f16.f32 	%rs34, %f690;
	mov.b32 	%r183, {%rs33, %rs34};
	.loc	1 265 47
	mul.f32 	%f692, %f756, %f663;
	mul.f32 	%f693, %f756, %f662;
	.loc	1 265 39
	cvt.rn.f16.f32 	%rs35, %f693;
	cvt.rn.f16.f32 	%rs36, %f692;
	mov.b32 	%r184, {%rs35, %rs36};
	// begin inline asm
	@%p6 st.global.v4.b32 [ %rd22 + 0 ], { %r177, %r178, %r179, %r180 };
	// end inline asm
	// begin inline asm
	@%p11 st.global.v4.b32 [ %rd23 + 0 ], { %r181, %r182, %r183, %r184 };
	// end inline asm
	.loc	1 265 4
	ret;
$L__tmp1:
$L__func_end0:

}
	.file	1 "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/unsloth/kernels/cross_entropy_loss.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 0
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 142
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 99
.b8 114
.b8 111
.b8 115
.b8 115
.b8 95
.b8 101
.b8 110
.b8 116
.b8 114
.b8 111
.b8 112
.b8 121
.b8 95
.b8 108
.b8 111
.b8 115
.b8 115
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 47
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 122
.b8 101
.b8 117
.b8 115
.b8 47
.b8 109
.b8 105
.b8 110
.b8 105
.b8 99
.b8 111
.b8 110
.b8 100
.b8 97
.b8 51
.b8 47
.b8 101
.b8 110
.b8 118
.b8 115
.b8 47
.b8 99
.b8 108
.b8 111
.b8 117
.b8 100
.b8 115
.b8 112
.b8 97
.b8 99
.b8 101
.b8 47
.b8 108
.b8 105
.b8 98
.b8 47
.b8 112
.b8 121
.b8 116
.b8 104
.b8 111
.b8 110
.b8 51
.b8 46
.b8 49
.b8 49
.b8 47
.b8 115
.b8 105
.b8 116
.b8 101
.b8 45
.b8 112
.b8 97
.b8 99
.b8 107
.b8 97
.b8 103
.b8 101
.b8 115
.b8 47
.b8 117
.b8 110
.b8 115
.b8 108
.b8 111
.b8 116
.b8 104
.b8 47
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 115
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
	}
	.section	.debug_loc	{	}
