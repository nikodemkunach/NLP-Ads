//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_75
.address_size 64

	// .globl	_chunked_cross_entropy_forward
.extern .shared .align 16 .b8 global_smem[];
.global .align 1 .b8 _$_str[11] = {95, 95, 67, 85, 68, 65, 95, 70, 84, 90};

.visible .entry _chunked_cross_entropy_forward(
	.param .u64 _chunked_cross_entropy_forward_param_0,
	.param .u32 _chunked_cross_entropy_forward_param_1,
	.param .u64 _chunked_cross_entropy_forward_param_2,
	.param .u64 _chunked_cross_entropy_forward_param_3,
	.param .u64 _chunked_cross_entropy_forward_param_4,
	.param .u32 _chunked_cross_entropy_forward_param_5,
	.param .u32 _chunked_cross_entropy_forward_param_6,
	.param .u8 _chunked_cross_entropy_forward_param_7,
	.param .u32 _chunked_cross_entropy_forward_param_8,
	.param .u8 _chunked_cross_entropy_forward_param_9,
	.param .u32 _chunked_cross_entropy_forward_param_10
)
.maxntid 1024, 1, 1
{
	.reg .pred 	%p<189>;
	.reg .b16 	%rs<71>;
	.reg .b32 	%r<707>;
	.reg .f32 	%f<2351>;
	.reg .b64 	%rd<27>;
	.loc	1 105 0
$L__func_begin0:
	.loc	1 105 0

	ld.param.u8 	%rs1, [_chunked_cross_entropy_forward_param_7];
	and.b16  	%rs2, %rs1, 1;
	setp.eq.b16 	%p1, %rs2, 1;
	ld.param.u8 	%rs3, [_chunked_cross_entropy_forward_param_9];
	and.b16  	%rs4, %rs3, 1;
	setp.eq.b16 	%p2, %rs4, 1;
	ld.param.u32 	%r10, [_chunked_cross_entropy_forward_param_8];
	ld.param.u64 	%rd14, [_chunked_cross_entropy_forward_param_0];
$L__tmp0:
	.loc	1 143 30
	// begin inline asm
	mov.u32 %r11, %ctaid.x;
	// end inline asm
	ld.param.u32 	%r77, [_chunked_cross_entropy_forward_param_1];
	.loc	1 144 30
	// begin inline asm
	mov.u32 %r12, %ctaid.y;
	// end inline asm
	ld.param.u64 	%rd16, [_chunked_cross_entropy_forward_param_4];
	.loc	1 145 31
	mul.wide.s32 	%rd17, %r11, %r77;
	ld.param.u32 	%r78, [_chunked_cross_entropy_forward_param_5];
	.loc	1 145 21
	shl.b64 	%rd18, %rd17, 1;
	add.s64 	%rd1, %rd14, %rd18;
	.loc	1 148 21
	mul.wide.s32 	%rd20, %r11, 8;
	add.s64 	%rd5, %rd16, %rd20;
	.loc	1 150 28
	shl.b32 	%r79, %r12, 16;
	.loc	1 150 54
	mov.u32 	%r3, %tid.x;
	ld.param.u32 	%r80, [_chunked_cross_entropy_forward_param_10];
	and.b32  	%r4, %r3, 31;
	shr.u32 	%r5, %r3, 5;
	shl.b32 	%r81, %r3, 3;
	and.b32  	%r82, %r81, 8184;
	.loc	1 150 41
	or.b32  	%r83, %r79, %r82;
	or.b32  	%r84, %r83, 8192;
	or.b32  	%r85, %r83, 16384;
	or.b32  	%r86, %r83, 24576;
	or.b32  	%r87, %r83, 32768;
	or.b32  	%r88, %r83, 40960;
	or.b32  	%r89, %r83, 49152;
	or.b32  	%r90, %r83, 57344;
	.loc	1 151 25
	setp.lt.s32 	%p4, %r83, %r78;
	setp.lt.s32 	%p9, %r84, %r78;
	setp.lt.s32 	%p14, %r85, %r78;
	setp.lt.s32 	%p19, %r86, %r78;
	setp.lt.s32 	%p24, %r87, %r78;
	setp.lt.s32 	%p29, %r88, %r78;
	setp.lt.s32 	%p34, %r89, %r78;
	setp.lt.s32 	%p39, %r90, %r78;
	mov.pred 	%p3, -1;
	.loc	1 153 24
	// begin inline asm
	mov.u64 %rd4, 0x0;
	@%p3 ld.global.b64 { %rd4 }, [ %rd5 + 0 ];
	// end inline asm
	.loc	1 154 34
	mul.wide.s32 	%rd21, %r83, 2;
	add.s64 	%rd6, %rd1, %rd21;
	add.s64 	%rd7, %rd6, 16384;
	add.s64 	%rd8, %rd6, 32768;
	add.s64 	%rd9, %rd6, 49152;
	add.s64 	%rd10, %rd6, 65536;
	add.s64 	%rd11, %rd6, 81920;
	add.s64 	%rd12, %rd6, 98304;
	add.s64 	%rd13, %rd6, 114688;
	mov.b32 	%r17, -67044352;
	.loc	1 154 21
	// begin inline asm
	mov.u32 %r13, 0x0;
	mov.u32 %r14, 0x0;
	mov.u32 %r15, 0x0;
	mov.u32 %r16, 0x0;
	@%p4 ld.global.v4.b32 { %r13, %r14, %r15, %r16 }, [ %rd6 + 0 ];
	@!%p4 mov.u32 %r13, %r17;
	@!%p4 mov.u32 %r14, %r17;
	@!%p4 mov.u32 %r15, %r17;
	@!%p4 mov.u32 %r16, %r17;
	// end inline asm
	// begin inline asm
	mov.u32 %r21, 0x0;
	mov.u32 %r22, 0x0;
	mov.u32 %r23, 0x0;
	mov.u32 %r24, 0x0;
	@%p9 ld.global.v4.b32 { %r21, %r22, %r23, %r24 }, [ %rd7 + 0 ];
	@!%p9 mov.u32 %r21, %r17;
	@!%p9 mov.u32 %r22, %r17;
	@!%p9 mov.u32 %r23, %r17;
	@!%p9 mov.u32 %r24, %r17;
	// end inline asm
	// begin inline asm
	mov.u32 %r29, 0x0;
	mov.u32 %r30, 0x0;
	mov.u32 %r31, 0x0;
	mov.u32 %r32, 0x0;
	@%p14 ld.global.v4.b32 { %r29, %r30, %r31, %r32 }, [ %rd8 + 0 ];
	@!%p14 mov.u32 %r29, %r17;
	@!%p14 mov.u32 %r30, %r17;
	@!%p14 mov.u32 %r31, %r17;
	@!%p14 mov.u32 %r32, %r17;
	// end inline asm
	// begin inline asm
	mov.u32 %r37, 0x0;
	mov.u32 %r38, 0x0;
	mov.u32 %r39, 0x0;
	mov.u32 %r40, 0x0;
	@%p19 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd9 + 0 ];
	@!%p19 mov.u32 %r37, %r17;
	@!%p19 mov.u32 %r38, %r17;
	@!%p19 mov.u32 %r39, %r17;
	@!%p19 mov.u32 %r40, %r17;
	// end inline asm
	// begin inline asm
	mov.u32 %r45, 0x0;
	mov.u32 %r46, 0x0;
	mov.u32 %r47, 0x0;
	mov.u32 %r48, 0x0;
	@%p24 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd10 + 0 ];
	@!%p24 mov.u32 %r45, %r17;
	@!%p24 mov.u32 %r46, %r17;
	@!%p24 mov.u32 %r47, %r17;
	@!%p24 mov.u32 %r48, %r17;
	// end inline asm
	// begin inline asm
	mov.u32 %r53, 0x0;
	mov.u32 %r54, 0x0;
	mov.u32 %r55, 0x0;
	mov.u32 %r56, 0x0;
	@%p29 ld.global.v4.b32 { %r53, %r54, %r55, %r56 }, [ %rd11 + 0 ];
	@!%p29 mov.u32 %r53, %r17;
	@!%p29 mov.u32 %r54, %r17;
	@!%p29 mov.u32 %r55, %r17;
	@!%p29 mov.u32 %r56, %r17;
	// end inline asm
	// begin inline asm
	mov.u32 %r61, 0x0;
	mov.u32 %r62, 0x0;
	mov.u32 %r63, 0x0;
	mov.u32 %r64, 0x0;
	@%p34 ld.global.v4.b32 { %r61, %r62, %r63, %r64 }, [ %rd12 + 0 ];
	@!%p34 mov.u32 %r61, %r17;
	@!%p34 mov.u32 %r62, %r17;
	@!%p34 mov.u32 %r63, %r17;
	@!%p34 mov.u32 %r64, %r17;
	// end inline asm
	// begin inline asm
	mov.u32 %r69, 0x0;
	mov.u32 %r70, 0x0;
	mov.u32 %r71, 0x0;
	mov.u32 %r72, 0x0;
	@%p39 ld.global.v4.b32 { %r69, %r70, %r71, %r72 }, [ %rd13 + 0 ];
	@!%p39 mov.u32 %r69, %r17;
	@!%p39 mov.u32 %r70, %r17;
	@!%p39 mov.u32 %r71, %r17;
	@!%p39 mov.u32 %r72, %r17;
	// end inline asm
	.loc	1 154 86
	mov.b32 	{%rs5, %rs6}, %r16;
	cvt.f32.f16 	%f529, %rs6;
	cvt.f32.f16 	%f530, %rs5;
	mov.b32 	{%rs7, %rs8}, %r15;
	cvt.f32.f16 	%f531, %rs8;
	cvt.f32.f16 	%f532, %rs7;
	mov.b32 	{%rs9, %rs10}, %r14;
	cvt.f32.f16 	%f533, %rs10;
	cvt.f32.f16 	%f534, %rs9;
	mov.b32 	{%rs11, %rs12}, %r13;
	cvt.f32.f16 	%f535, %rs12;
	cvt.f32.f16 	%f536, %rs11;
	mov.b32 	{%rs13, %rs14}, %r24;
	cvt.f32.f16 	%f537, %rs14;
	cvt.f32.f16 	%f538, %rs13;
	mov.b32 	{%rs15, %rs16}, %r23;
	cvt.f32.f16 	%f539, %rs16;
	cvt.f32.f16 	%f540, %rs15;
	mov.b32 	{%rs17, %rs18}, %r22;
	cvt.f32.f16 	%f541, %rs18;
	cvt.f32.f16 	%f542, %rs17;
	mov.b32 	{%rs19, %rs20}, %r21;
	cvt.f32.f16 	%f543, %rs20;
	cvt.f32.f16 	%f544, %rs19;
	mov.b32 	{%rs21, %rs22}, %r32;
	cvt.f32.f16 	%f545, %rs22;
	cvt.f32.f16 	%f546, %rs21;
	mov.b32 	{%rs23, %rs24}, %r31;
	cvt.f32.f16 	%f547, %rs24;
	cvt.f32.f16 	%f548, %rs23;
	mov.b32 	{%rs25, %rs26}, %r30;
	cvt.f32.f16 	%f549, %rs26;
	cvt.f32.f16 	%f550, %rs25;
	mov.b32 	{%rs27, %rs28}, %r29;
	cvt.f32.f16 	%f551, %rs28;
	cvt.f32.f16 	%f552, %rs27;
	mov.b32 	{%rs29, %rs30}, %r40;
	cvt.f32.f16 	%f553, %rs30;
	cvt.f32.f16 	%f554, %rs29;
	mov.b32 	{%rs31, %rs32}, %r39;
	cvt.f32.f16 	%f555, %rs32;
	cvt.f32.f16 	%f556, %rs31;
	mov.b32 	{%rs33, %rs34}, %r38;
	cvt.f32.f16 	%f557, %rs34;
	cvt.f32.f16 	%f558, %rs33;
	mov.b32 	{%rs35, %rs36}, %r37;
	cvt.f32.f16 	%f559, %rs36;
	cvt.f32.f16 	%f560, %rs35;
	mov.b32 	{%rs37, %rs38}, %r48;
	cvt.f32.f16 	%f561, %rs38;
	cvt.f32.f16 	%f562, %rs37;
	mov.b32 	{%rs39, %rs40}, %r47;
	cvt.f32.f16 	%f563, %rs40;
	cvt.f32.f16 	%f564, %rs39;
	mov.b32 	{%rs41, %rs42}, %r46;
	cvt.f32.f16 	%f565, %rs42;
	cvt.f32.f16 	%f566, %rs41;
	mov.b32 	{%rs43, %rs44}, %r45;
	cvt.f32.f16 	%f567, %rs44;
	cvt.f32.f16 	%f568, %rs43;
	mov.b32 	{%rs45, %rs46}, %r56;
	cvt.f32.f16 	%f569, %rs46;
	cvt.f32.f16 	%f570, %rs45;
	mov.b32 	{%rs47, %rs48}, %r55;
	cvt.f32.f16 	%f571, %rs48;
	cvt.f32.f16 	%f572, %rs47;
	mov.b32 	{%rs49, %rs50}, %r54;
	cvt.f32.f16 	%f573, %rs50;
	cvt.f32.f16 	%f574, %rs49;
	mov.b32 	{%rs51, %rs52}, %r53;
	cvt.f32.f16 	%f575, %rs52;
	cvt.f32.f16 	%f576, %rs51;
	mov.b32 	{%rs53, %rs54}, %r64;
	cvt.f32.f16 	%f577, %rs54;
	cvt.f32.f16 	%f578, %rs53;
	mov.b32 	{%rs55, %rs56}, %r63;
	cvt.f32.f16 	%f579, %rs56;
	cvt.f32.f16 	%f580, %rs55;
	mov.b32 	{%rs57, %rs58}, %r62;
	cvt.f32.f16 	%f581, %rs58;
	cvt.f32.f16 	%f582, %rs57;
	mov.b32 	{%rs59, %rs60}, %r61;
	cvt.f32.f16 	%f583, %rs60;
	cvt.f32.f16 	%f584, %rs59;
	mov.b32 	{%rs61, %rs62}, %r72;
	cvt.f32.f16 	%f585, %rs62;
	cvt.f32.f16 	%f586, %rs61;
	mov.b32 	{%rs63, %rs64}, %r71;
	cvt.f32.f16 	%f587, %rs64;
	cvt.f32.f16 	%f588, %rs63;
	mov.b32 	{%rs65, %rs66}, %r70;
	cvt.f32.f16 	%f589, %rs66;
	cvt.f32.f16 	%f590, %rs65;
	mov.b32 	{%rs67, %rs68}, %r69;
	cvt.f32.f16 	%f591, %rs68;
	cvt.f32.f16 	%f592, %rs67;
	.loc	1 157 7
	cvt.rn.f32.s32 	%f1, %r80;
	mul.f32 	%f593, %f1, %f592;
	mul.f32 	%f594, %f1, %f591;
	mul.f32 	%f595, %f1, %f590;
	mul.f32 	%f596, %f1, %f589;
	mul.f32 	%f597, %f1, %f588;
	mul.f32 	%f598, %f1, %f587;
	mul.f32 	%f599, %f1, %f586;
	mul.f32 	%f600, %f1, %f585;
	mul.f32 	%f601, %f1, %f584;
	mul.f32 	%f602, %f1, %f583;
	mul.f32 	%f603, %f1, %f582;
	mul.f32 	%f604, %f1, %f581;
	mul.f32 	%f605, %f1, %f580;
	mul.f32 	%f606, %f1, %f579;
	mul.f32 	%f607, %f1, %f578;
	mul.f32 	%f608, %f1, %f577;
	mul.f32 	%f609, %f1, %f576;
	mul.f32 	%f610, %f1, %f575;
	mul.f32 	%f611, %f1, %f574;
	mul.f32 	%f612, %f1, %f573;
	mul.f32 	%f613, %f1, %f572;
	mul.f32 	%f614, %f1, %f571;
	mul.f32 	%f615, %f1, %f570;
	mul.f32 	%f616, %f1, %f569;
	mul.f32 	%f617, %f1, %f568;
	mul.f32 	%f618, %f1, %f567;
	mul.f32 	%f619, %f1, %f566;
	mul.f32 	%f620, %f1, %f565;
	mul.f32 	%f621, %f1, %f564;
	mul.f32 	%f622, %f1, %f563;
	mul.f32 	%f623, %f1, %f562;
	mul.f32 	%f624, %f1, %f561;
	mul.f32 	%f625, %f1, %f560;
	mul.f32 	%f626, %f1, %f559;
	mul.f32 	%f627, %f1, %f558;
	mul.f32 	%f628, %f1, %f557;
	mul.f32 	%f629, %f1, %f556;
	mul.f32 	%f630, %f1, %f555;
	mul.f32 	%f631, %f1, %f554;
	mul.f32 	%f632, %f1, %f553;
	mul.f32 	%f633, %f1, %f552;
	mul.f32 	%f634, %f1, %f551;
	mul.f32 	%f635, %f1, %f550;
	mul.f32 	%f636, %f1, %f549;
	mul.f32 	%f637, %f1, %f548;
	mul.f32 	%f638, %f1, %f547;
	mul.f32 	%f639, %f1, %f546;
	mul.f32 	%f640, %f1, %f545;
	mul.f32 	%f641, %f1, %f544;
	mul.f32 	%f642, %f1, %f543;
	mul.f32 	%f643, %f1, %f542;
	mul.f32 	%f644, %f1, %f541;
	mul.f32 	%f645, %f1, %f540;
	mul.f32 	%f646, %f1, %f539;
	mul.f32 	%f647, %f1, %f538;
	mul.f32 	%f648, %f1, %f537;
	mul.f32 	%f649, %f1, %f536;
	mul.f32 	%f650, %f1, %f535;
	mul.f32 	%f651, %f1, %f534;
	mul.f32 	%f652, %f1, %f533;
	mul.f32 	%f653, %f1, %f532;
	mul.f32 	%f654, %f1, %f531;
	mul.f32 	%f655, %f1, %f530;
	mul.f32 	%f656, %f1, %f529;
	selp.f32 	%f2291, %f656, %f529, %p2;
	selp.f32 	%f2290, %f655, %f530, %p2;
	selp.f32 	%f2289, %f654, %f531, %p2;
	selp.f32 	%f2288, %f653, %f532, %p2;
	selp.f32 	%f2287, %f652, %f533, %p2;
	selp.f32 	%f2286, %f651, %f534, %p2;
	selp.f32 	%f2285, %f650, %f535, %p2;
	selp.f32 	%f2284, %f649, %f536, %p2;
	selp.f32 	%f2299, %f648, %f537, %p2;
	selp.f32 	%f2298, %f647, %f538, %p2;
	selp.f32 	%f2297, %f646, %f539, %p2;
	selp.f32 	%f2296, %f645, %f540, %p2;
	selp.f32 	%f2295, %f644, %f541, %p2;
	selp.f32 	%f2294, %f643, %f542, %p2;
	selp.f32 	%f2293, %f642, %f543, %p2;
	selp.f32 	%f2292, %f641, %f544, %p2;
	selp.f32 	%f2307, %f640, %f545, %p2;
	selp.f32 	%f2306, %f639, %f546, %p2;
	selp.f32 	%f2305, %f638, %f547, %p2;
	selp.f32 	%f2304, %f637, %f548, %p2;
	selp.f32 	%f2303, %f636, %f549, %p2;
	selp.f32 	%f2302, %f635, %f550, %p2;
	selp.f32 	%f2301, %f634, %f551, %p2;
	selp.f32 	%f2300, %f633, %f552, %p2;
	selp.f32 	%f2315, %f632, %f553, %p2;
	selp.f32 	%f2314, %f631, %f554, %p2;
	selp.f32 	%f2313, %f630, %f555, %p2;
	selp.f32 	%f2312, %f629, %f556, %p2;
	selp.f32 	%f2311, %f628, %f557, %p2;
	selp.f32 	%f2310, %f627, %f558, %p2;
	selp.f32 	%f2309, %f626, %f559, %p2;
	selp.f32 	%f2308, %f625, %f560, %p2;
	selp.f32 	%f2323, %f624, %f561, %p2;
	selp.f32 	%f2322, %f623, %f562, %p2;
	selp.f32 	%f2321, %f622, %f563, %p2;
	selp.f32 	%f2320, %f621, %f564, %p2;
	selp.f32 	%f2319, %f620, %f565, %p2;
	selp.f32 	%f2318, %f619, %f566, %p2;
	selp.f32 	%f2317, %f618, %f567, %p2;
	selp.f32 	%f2316, %f617, %f568, %p2;
	selp.f32 	%f2331, %f616, %f569, %p2;
	selp.f32 	%f2330, %f615, %f570, %p2;
	selp.f32 	%f2329, %f614, %f571, %p2;
	selp.f32 	%f2328, %f613, %f572, %p2;
	selp.f32 	%f2327, %f612, %f573, %p2;
	selp.f32 	%f2326, %f611, %f574, %p2;
	selp.f32 	%f2325, %f610, %f575, %p2;
	selp.f32 	%f2324, %f609, %f576, %p2;
	selp.f32 	%f2339, %f608, %f577, %p2;
	selp.f32 	%f2338, %f607, %f578, %p2;
	selp.f32 	%f2337, %f606, %f579, %p2;
	selp.f32 	%f2336, %f605, %f580, %p2;
	selp.f32 	%f2335, %f604, %f581, %p2;
	selp.f32 	%f2334, %f603, %f582, %p2;
	selp.f32 	%f2333, %f602, %f583, %p2;
	selp.f32 	%f2332, %f601, %f584, %p2;
	selp.f32 	%f2347, %f600, %f585, %p2;
	selp.f32 	%f2346, %f599, %f586, %p2;
	selp.f32 	%f2345, %f598, %f587, %p2;
	selp.f32 	%f2344, %f597, %f588, %p2;
	selp.f32 	%f2343, %f596, %f589, %p2;
	selp.f32 	%f2342, %f595, %f590, %p2;
	selp.f32 	%f2341, %f594, %f591, %p2;
	selp.f32 	%f2340, %f593, %f592, %p2;
	.loc	1 159 7
	@!%p1 bra 	$L__BB0_194;
	bra.uni 	$L__BB0_1;
$L__BB0_1:
	.loc	1 159 65
	cvt.rn.f32.s32 	%f66, %r10;
	mov.b32 	%r124, %f2284;
	mov.b32 	%r125, %f66;
	// begin inline asm
	div.full.f32 %r641, %r124, %r125;
	// end inline asm
	mov.b32 	%f67, %r641;
	mov.b32 	%r127, %f2285;
	// begin inline asm
	div.full.f32 %r642, %r127, %r125;
	// end inline asm
	mov.b32 	%f68, %r642;
	mov.b32 	%r130, %f2286;
	// begin inline asm
	div.full.f32 %r643, %r130, %r125;
	// end inline asm
	mov.b32 	%r133, %f2287;
	.loc	1 159 56
	abs.ftz.f32 	%f131, %f67;
	setp.ltu.f32 	%p44, %f131, 0f3F19999A;
	@%p44 bra 	$L__BB0_3;
	bra.uni 	$L__BB0_2;
$L__BB0_3:
	mul.f32 	%f665, %f67, %f67;
	mov.f32 	%f666, 0fBD563CAE;
	mov.f32 	%f667, 0f3C80F082;
	fma.rn.ftz.f32 	%f668, %f667, %f665, %f666;
	mov.f32 	%f669, 0f3E085941;
	fma.rn.ftz.f32 	%f670, %f668, %f665, %f669;
	mov.f32 	%f671, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f672, %f670, %f665, %f671;
	mov.f32 	%f673, 0f00000000;
	fma.rn.ftz.f32 	%f674, %f672, %f665, %f673;
	fma.rn.ftz.f32 	%f2220, %f674, %f67, %f67;
	bra.uni 	$L__BB0_4;
$L__BB0_2:
	mul.f32 	%f659, %f131, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f660, %f659;
	add.f32 	%f658, %f660, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f657,%f658;
	// end inline asm
	mov.f32 	%f661, 0f3F800000;
	mov.f32 	%f662, 0fC0000000;
	fma.rn.ftz.f32 	%f663, %f657, %f662, %f661;
	setp.ge.f32 	%p45, %f131, 0f41102CB4;
	selp.f32 	%f664, 0f3F800000, %f663, %p45;
	mov.b32 	%r315, %f664;
	and.b32  	%r317, %r641, -2147483648;
	or.b32  	%r318, %r317, %r315;
	mov.b32 	%f2220, %r318;
$L__BB0_4:
	.loc	1 159 0
	mov.b32 	%r136, %f2288;
	// begin inline asm
	div.full.f32 %r644, %r133, %r125;
	// end inline asm
	mov.b32 	%f69, %r643;
	.loc	1 159 56
	abs.ftz.f32 	%f135, %f68;
	setp.ltu.f32 	%p46, %f135, 0f3F19999A;
	@%p46 bra 	$L__BB0_6;
	bra.uni 	$L__BB0_5;
$L__BB0_6:
	mul.f32 	%f683, %f68, %f68;
	mov.f32 	%f684, 0fBD563CAE;
	mov.f32 	%f685, 0f3C80F082;
	fma.rn.ftz.f32 	%f686, %f685, %f683, %f684;
	mov.f32 	%f687, 0f3E085941;
	fma.rn.ftz.f32 	%f688, %f686, %f683, %f687;
	mov.f32 	%f689, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f690, %f688, %f683, %f689;
	mov.f32 	%f691, 0f00000000;
	fma.rn.ftz.f32 	%f692, %f690, %f683, %f691;
	fma.rn.ftz.f32 	%f2221, %f692, %f68, %f68;
	bra.uni 	$L__BB0_7;
$L__BB0_5:
	mul.f32 	%f677, %f135, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f678, %f677;
	add.f32 	%f676, %f678, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f675,%f676;
	// end inline asm
	mov.f32 	%f679, 0f3F800000;
	mov.f32 	%f680, 0fC0000000;
	fma.rn.ftz.f32 	%f681, %f675, %f680, %f679;
	setp.ge.f32 	%p47, %f135, 0f41102CB4;
	selp.f32 	%f682, 0f3F800000, %f681, %p47;
	mov.b32 	%r319, %f682;
	and.b32  	%r321, %r642, -2147483648;
	or.b32  	%r322, %r321, %r319;
	mov.b32 	%f2221, %r322;
$L__BB0_7:
	.loc	1 159 0
	mov.b32 	%r139, %f2289;
	// begin inline asm
	div.full.f32 %r645, %r136, %r125;
	// end inline asm
	mov.b32 	%f70, %r644;
	.loc	1 159 56
	abs.ftz.f32 	%f139, %f69;
	setp.ltu.f32 	%p48, %f139, 0f3F19999A;
	@%p48 bra 	$L__BB0_9;
	bra.uni 	$L__BB0_8;
$L__BB0_9:
	mul.f32 	%f701, %f69, %f69;
	mov.f32 	%f702, 0fBD563CAE;
	mov.f32 	%f703, 0f3C80F082;
	fma.rn.ftz.f32 	%f704, %f703, %f701, %f702;
	mov.f32 	%f705, 0f3E085941;
	fma.rn.ftz.f32 	%f706, %f704, %f701, %f705;
	mov.f32 	%f707, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f708, %f706, %f701, %f707;
	mov.f32 	%f709, 0f00000000;
	fma.rn.ftz.f32 	%f710, %f708, %f701, %f709;
	fma.rn.ftz.f32 	%f2222, %f710, %f69, %f69;
	bra.uni 	$L__BB0_10;
$L__BB0_8:
	mul.f32 	%f695, %f139, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f696, %f695;
	add.f32 	%f694, %f696, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f693,%f694;
	// end inline asm
	mov.f32 	%f697, 0f3F800000;
	mov.f32 	%f698, 0fC0000000;
	fma.rn.ftz.f32 	%f699, %f693, %f698, %f697;
	setp.ge.f32 	%p49, %f139, 0f41102CB4;
	selp.f32 	%f700, 0f3F800000, %f699, %p49;
	mov.b32 	%r323, %f700;
	and.b32  	%r325, %r643, -2147483648;
	or.b32  	%r326, %r325, %r323;
	mov.b32 	%f2222, %r326;
$L__BB0_10:
	.loc	1 159 0
	mov.b32 	%r142, %f2290;
	// begin inline asm
	div.full.f32 %r646, %r139, %r125;
	// end inline asm
	mov.b32 	%f71, %r645;
	.loc	1 159 56
	abs.ftz.f32 	%f143, %f70;
	setp.ltu.f32 	%p50, %f143, 0f3F19999A;
	@%p50 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_11;
$L__BB0_12:
	mul.f32 	%f719, %f70, %f70;
	mov.f32 	%f720, 0fBD563CAE;
	mov.f32 	%f721, 0f3C80F082;
	fma.rn.ftz.f32 	%f722, %f721, %f719, %f720;
	mov.f32 	%f723, 0f3E085941;
	fma.rn.ftz.f32 	%f724, %f722, %f719, %f723;
	mov.f32 	%f725, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f726, %f724, %f719, %f725;
	mov.f32 	%f727, 0f00000000;
	fma.rn.ftz.f32 	%f728, %f726, %f719, %f727;
	fma.rn.ftz.f32 	%f2223, %f728, %f70, %f70;
	bra.uni 	$L__BB0_13;
$L__BB0_11:
	mul.f32 	%f713, %f143, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f714, %f713;
	add.f32 	%f712, %f714, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f711,%f712;
	// end inline asm
	mov.f32 	%f715, 0f3F800000;
	mov.f32 	%f716, 0fC0000000;
	fma.rn.ftz.f32 	%f717, %f711, %f716, %f715;
	setp.ge.f32 	%p51, %f143, 0f41102CB4;
	selp.f32 	%f718, 0f3F800000, %f717, %p51;
	mov.b32 	%r327, %f718;
	and.b32  	%r329, %r644, -2147483648;
	or.b32  	%r330, %r329, %r327;
	mov.b32 	%f2223, %r330;
$L__BB0_13:
	.loc	1 159 0
	mov.b32 	%r145, %f2291;
	// begin inline asm
	div.full.f32 %r647, %r142, %r125;
	// end inline asm
	mov.b32 	%f72, %r646;
	.loc	1 159 56
	abs.ftz.f32 	%f147, %f71;
	setp.ltu.f32 	%p52, %f147, 0f3F19999A;
	@%p52 bra 	$L__BB0_15;
	bra.uni 	$L__BB0_14;
$L__BB0_15:
	mul.f32 	%f737, %f71, %f71;
	mov.f32 	%f738, 0fBD563CAE;
	mov.f32 	%f739, 0f3C80F082;
	fma.rn.ftz.f32 	%f740, %f739, %f737, %f738;
	mov.f32 	%f741, 0f3E085941;
	fma.rn.ftz.f32 	%f742, %f740, %f737, %f741;
	mov.f32 	%f743, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f744, %f742, %f737, %f743;
	mov.f32 	%f745, 0f00000000;
	fma.rn.ftz.f32 	%f746, %f744, %f737, %f745;
	fma.rn.ftz.f32 	%f2224, %f746, %f71, %f71;
	bra.uni 	$L__BB0_16;
$L__BB0_14:
	mul.f32 	%f731, %f147, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f732, %f731;
	add.f32 	%f730, %f732, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f729,%f730;
	// end inline asm
	mov.f32 	%f733, 0f3F800000;
	mov.f32 	%f734, 0fC0000000;
	fma.rn.ftz.f32 	%f735, %f729, %f734, %f733;
	setp.ge.f32 	%p53, %f147, 0f41102CB4;
	selp.f32 	%f736, 0f3F800000, %f735, %p53;
	mov.b32 	%r331, %f736;
	and.b32  	%r333, %r645, -2147483648;
	or.b32  	%r334, %r333, %r331;
	mov.b32 	%f2224, %r334;
$L__BB0_16:
	.loc	1 159 0
	mov.b32 	%r148, %f2292;
	// begin inline asm
	div.full.f32 %r648, %r145, %r125;
	// end inline asm
	mov.b32 	%f73, %r647;
	.loc	1 159 56
	abs.ftz.f32 	%f151, %f72;
	setp.ltu.f32 	%p54, %f151, 0f3F19999A;
	@%p54 bra 	$L__BB0_18;
	bra.uni 	$L__BB0_17;
$L__BB0_18:
	mul.f32 	%f755, %f72, %f72;
	mov.f32 	%f756, 0fBD563CAE;
	mov.f32 	%f757, 0f3C80F082;
	fma.rn.ftz.f32 	%f758, %f757, %f755, %f756;
	mov.f32 	%f759, 0f3E085941;
	fma.rn.ftz.f32 	%f760, %f758, %f755, %f759;
	mov.f32 	%f761, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f762, %f760, %f755, %f761;
	mov.f32 	%f763, 0f00000000;
	fma.rn.ftz.f32 	%f764, %f762, %f755, %f763;
	fma.rn.ftz.f32 	%f2225, %f764, %f72, %f72;
	bra.uni 	$L__BB0_19;
$L__BB0_17:
	mul.f32 	%f749, %f151, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f750, %f749;
	add.f32 	%f748, %f750, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f747,%f748;
	// end inline asm
	mov.f32 	%f751, 0f3F800000;
	mov.f32 	%f752, 0fC0000000;
	fma.rn.ftz.f32 	%f753, %f747, %f752, %f751;
	setp.ge.f32 	%p55, %f151, 0f41102CB4;
	selp.f32 	%f754, 0f3F800000, %f753, %p55;
	mov.b32 	%r335, %f754;
	and.b32  	%r337, %r646, -2147483648;
	or.b32  	%r338, %r337, %r335;
	mov.b32 	%f2225, %r338;
$L__BB0_19:
	.loc	1 159 0
	mov.b32 	%r151, %f2293;
	// begin inline asm
	div.full.f32 %r649, %r148, %r125;
	// end inline asm
	mov.b32 	%f74, %r648;
	.loc	1 159 56
	abs.ftz.f32 	%f155, %f73;
	setp.ltu.f32 	%p56, %f155, 0f3F19999A;
	@%p56 bra 	$L__BB0_21;
	bra.uni 	$L__BB0_20;
$L__BB0_21:
	mul.f32 	%f773, %f73, %f73;
	mov.f32 	%f774, 0fBD563CAE;
	mov.f32 	%f775, 0f3C80F082;
	fma.rn.ftz.f32 	%f776, %f775, %f773, %f774;
	mov.f32 	%f777, 0f3E085941;
	fma.rn.ftz.f32 	%f778, %f776, %f773, %f777;
	mov.f32 	%f779, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f780, %f778, %f773, %f779;
	mov.f32 	%f781, 0f00000000;
	fma.rn.ftz.f32 	%f782, %f780, %f773, %f781;
	fma.rn.ftz.f32 	%f2226, %f782, %f73, %f73;
	bra.uni 	$L__BB0_22;
$L__BB0_20:
	mul.f32 	%f767, %f155, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f768, %f767;
	add.f32 	%f766, %f768, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f765,%f766;
	// end inline asm
	mov.f32 	%f769, 0f3F800000;
	mov.f32 	%f770, 0fC0000000;
	fma.rn.ftz.f32 	%f771, %f765, %f770, %f769;
	setp.ge.f32 	%p57, %f155, 0f41102CB4;
	selp.f32 	%f772, 0f3F800000, %f771, %p57;
	mov.b32 	%r339, %f772;
	and.b32  	%r341, %r647, -2147483648;
	or.b32  	%r342, %r341, %r339;
	mov.b32 	%f2226, %r342;
$L__BB0_22:
	.loc	1 159 0
	mov.b32 	%r154, %f2294;
	// begin inline asm
	div.full.f32 %r650, %r151, %r125;
	// end inline asm
	mov.b32 	%f75, %r649;
	.loc	1 159 56
	abs.ftz.f32 	%f159, %f74;
	setp.ltu.f32 	%p58, %f159, 0f3F19999A;
	@%p58 bra 	$L__BB0_24;
	bra.uni 	$L__BB0_23;
$L__BB0_24:
	mul.f32 	%f791, %f74, %f74;
	mov.f32 	%f792, 0fBD563CAE;
	mov.f32 	%f793, 0f3C80F082;
	fma.rn.ftz.f32 	%f794, %f793, %f791, %f792;
	mov.f32 	%f795, 0f3E085941;
	fma.rn.ftz.f32 	%f796, %f794, %f791, %f795;
	mov.f32 	%f797, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f798, %f796, %f791, %f797;
	mov.f32 	%f799, 0f00000000;
	fma.rn.ftz.f32 	%f800, %f798, %f791, %f799;
	fma.rn.ftz.f32 	%f2227, %f800, %f74, %f74;
	bra.uni 	$L__BB0_25;
$L__BB0_23:
	mul.f32 	%f785, %f159, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f786, %f785;
	add.f32 	%f784, %f786, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f783,%f784;
	// end inline asm
	mov.f32 	%f787, 0f3F800000;
	mov.f32 	%f788, 0fC0000000;
	fma.rn.ftz.f32 	%f789, %f783, %f788, %f787;
	setp.ge.f32 	%p59, %f159, 0f41102CB4;
	selp.f32 	%f790, 0f3F800000, %f789, %p59;
	mov.b32 	%r343, %f790;
	and.b32  	%r345, %r648, -2147483648;
	or.b32  	%r346, %r345, %r343;
	mov.b32 	%f2227, %r346;
$L__BB0_25:
	.loc	1 159 0
	mov.b32 	%r157, %f2295;
	// begin inline asm
	div.full.f32 %r651, %r154, %r125;
	// end inline asm
	mov.b32 	%f76, %r650;
	.loc	1 159 56
	abs.ftz.f32 	%f163, %f75;
	setp.ltu.f32 	%p60, %f163, 0f3F19999A;
	@%p60 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_26;
$L__BB0_27:
	mul.f32 	%f809, %f75, %f75;
	mov.f32 	%f810, 0fBD563CAE;
	mov.f32 	%f811, 0f3C80F082;
	fma.rn.ftz.f32 	%f812, %f811, %f809, %f810;
	mov.f32 	%f813, 0f3E085941;
	fma.rn.ftz.f32 	%f814, %f812, %f809, %f813;
	mov.f32 	%f815, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f816, %f814, %f809, %f815;
	mov.f32 	%f817, 0f00000000;
	fma.rn.ftz.f32 	%f818, %f816, %f809, %f817;
	fma.rn.ftz.f32 	%f2228, %f818, %f75, %f75;
	bra.uni 	$L__BB0_28;
$L__BB0_26:
	mul.f32 	%f803, %f163, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f804, %f803;
	add.f32 	%f802, %f804, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f801,%f802;
	// end inline asm
	mov.f32 	%f805, 0f3F800000;
	mov.f32 	%f806, 0fC0000000;
	fma.rn.ftz.f32 	%f807, %f801, %f806, %f805;
	setp.ge.f32 	%p61, %f163, 0f41102CB4;
	selp.f32 	%f808, 0f3F800000, %f807, %p61;
	mov.b32 	%r347, %f808;
	and.b32  	%r349, %r649, -2147483648;
	or.b32  	%r350, %r349, %r347;
	mov.b32 	%f2228, %r350;
$L__BB0_28:
	.loc	1 159 0
	mov.b32 	%r160, %f2296;
	// begin inline asm
	div.full.f32 %r652, %r157, %r125;
	// end inline asm
	mov.b32 	%f77, %r651;
	.loc	1 159 56
	abs.ftz.f32 	%f167, %f76;
	setp.ltu.f32 	%p62, %f167, 0f3F19999A;
	@%p62 bra 	$L__BB0_30;
	bra.uni 	$L__BB0_29;
$L__BB0_30:
	mul.f32 	%f827, %f76, %f76;
	mov.f32 	%f828, 0fBD563CAE;
	mov.f32 	%f829, 0f3C80F082;
	fma.rn.ftz.f32 	%f830, %f829, %f827, %f828;
	mov.f32 	%f831, 0f3E085941;
	fma.rn.ftz.f32 	%f832, %f830, %f827, %f831;
	mov.f32 	%f833, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f834, %f832, %f827, %f833;
	mov.f32 	%f835, 0f00000000;
	fma.rn.ftz.f32 	%f836, %f834, %f827, %f835;
	fma.rn.ftz.f32 	%f2229, %f836, %f76, %f76;
	bra.uni 	$L__BB0_31;
$L__BB0_29:
	mul.f32 	%f821, %f167, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f822, %f821;
	add.f32 	%f820, %f822, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f819,%f820;
	// end inline asm
	mov.f32 	%f823, 0f3F800000;
	mov.f32 	%f824, 0fC0000000;
	fma.rn.ftz.f32 	%f825, %f819, %f824, %f823;
	setp.ge.f32 	%p63, %f167, 0f41102CB4;
	selp.f32 	%f826, 0f3F800000, %f825, %p63;
	mov.b32 	%r351, %f826;
	and.b32  	%r353, %r650, -2147483648;
	or.b32  	%r354, %r353, %r351;
	mov.b32 	%f2229, %r354;
$L__BB0_31:
	.loc	1 159 0
	mov.b32 	%r163, %f2297;
	// begin inline asm
	div.full.f32 %r653, %r160, %r125;
	// end inline asm
	mov.b32 	%f78, %r652;
	.loc	1 159 56
	abs.ftz.f32 	%f171, %f77;
	setp.ltu.f32 	%p64, %f171, 0f3F19999A;
	@%p64 bra 	$L__BB0_33;
	bra.uni 	$L__BB0_32;
$L__BB0_33:
	mul.f32 	%f845, %f77, %f77;
	mov.f32 	%f846, 0fBD563CAE;
	mov.f32 	%f847, 0f3C80F082;
	fma.rn.ftz.f32 	%f848, %f847, %f845, %f846;
	mov.f32 	%f849, 0f3E085941;
	fma.rn.ftz.f32 	%f850, %f848, %f845, %f849;
	mov.f32 	%f851, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f852, %f850, %f845, %f851;
	mov.f32 	%f853, 0f00000000;
	fma.rn.ftz.f32 	%f854, %f852, %f845, %f853;
	fma.rn.ftz.f32 	%f2230, %f854, %f77, %f77;
	bra.uni 	$L__BB0_34;
$L__BB0_32:
	mul.f32 	%f839, %f171, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f840, %f839;
	add.f32 	%f838, %f840, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f837,%f838;
	// end inline asm
	mov.f32 	%f841, 0f3F800000;
	mov.f32 	%f842, 0fC0000000;
	fma.rn.ftz.f32 	%f843, %f837, %f842, %f841;
	setp.ge.f32 	%p65, %f171, 0f41102CB4;
	selp.f32 	%f844, 0f3F800000, %f843, %p65;
	mov.b32 	%r355, %f844;
	and.b32  	%r357, %r651, -2147483648;
	or.b32  	%r358, %r357, %r355;
	mov.b32 	%f2230, %r358;
$L__BB0_34:
	.loc	1 159 0
	mov.b32 	%r166, %f2298;
	// begin inline asm
	div.full.f32 %r654, %r163, %r125;
	// end inline asm
	mov.b32 	%f79, %r653;
	.loc	1 159 56
	abs.ftz.f32 	%f175, %f78;
	setp.ltu.f32 	%p66, %f175, 0f3F19999A;
	@%p66 bra 	$L__BB0_36;
	bra.uni 	$L__BB0_35;
$L__BB0_36:
	mul.f32 	%f863, %f78, %f78;
	mov.f32 	%f864, 0fBD563CAE;
	mov.f32 	%f865, 0f3C80F082;
	fma.rn.ftz.f32 	%f866, %f865, %f863, %f864;
	mov.f32 	%f867, 0f3E085941;
	fma.rn.ftz.f32 	%f868, %f866, %f863, %f867;
	mov.f32 	%f869, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f870, %f868, %f863, %f869;
	mov.f32 	%f871, 0f00000000;
	fma.rn.ftz.f32 	%f872, %f870, %f863, %f871;
	fma.rn.ftz.f32 	%f2231, %f872, %f78, %f78;
	bra.uni 	$L__BB0_37;
$L__BB0_35:
	mul.f32 	%f857, %f175, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f858, %f857;
	add.f32 	%f856, %f858, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f855,%f856;
	// end inline asm
	mov.f32 	%f859, 0f3F800000;
	mov.f32 	%f860, 0fC0000000;
	fma.rn.ftz.f32 	%f861, %f855, %f860, %f859;
	setp.ge.f32 	%p67, %f175, 0f41102CB4;
	selp.f32 	%f862, 0f3F800000, %f861, %p67;
	mov.b32 	%r359, %f862;
	and.b32  	%r361, %r652, -2147483648;
	or.b32  	%r362, %r361, %r359;
	mov.b32 	%f2231, %r362;
$L__BB0_37:
	.loc	1 159 0
	mov.b32 	%r169, %f2299;
	// begin inline asm
	div.full.f32 %r655, %r166, %r125;
	// end inline asm
	mov.b32 	%f80, %r654;
	.loc	1 159 56
	abs.ftz.f32 	%f179, %f79;
	setp.ltu.f32 	%p68, %f179, 0f3F19999A;
	@%p68 bra 	$L__BB0_39;
	bra.uni 	$L__BB0_38;
$L__BB0_39:
	mul.f32 	%f881, %f79, %f79;
	mov.f32 	%f882, 0fBD563CAE;
	mov.f32 	%f883, 0f3C80F082;
	fma.rn.ftz.f32 	%f884, %f883, %f881, %f882;
	mov.f32 	%f885, 0f3E085941;
	fma.rn.ftz.f32 	%f886, %f884, %f881, %f885;
	mov.f32 	%f887, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f888, %f886, %f881, %f887;
	mov.f32 	%f889, 0f00000000;
	fma.rn.ftz.f32 	%f890, %f888, %f881, %f889;
	fma.rn.ftz.f32 	%f2232, %f890, %f79, %f79;
	bra.uni 	$L__BB0_40;
$L__BB0_38:
	mul.f32 	%f875, %f179, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f876, %f875;
	add.f32 	%f874, %f876, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f873,%f874;
	// end inline asm
	mov.f32 	%f877, 0f3F800000;
	mov.f32 	%f878, 0fC0000000;
	fma.rn.ftz.f32 	%f879, %f873, %f878, %f877;
	setp.ge.f32 	%p69, %f179, 0f41102CB4;
	selp.f32 	%f880, 0f3F800000, %f879, %p69;
	mov.b32 	%r363, %f880;
	and.b32  	%r365, %r653, -2147483648;
	or.b32  	%r366, %r365, %r363;
	mov.b32 	%f2232, %r366;
$L__BB0_40:
	.loc	1 159 0
	mov.b32 	%r172, %f2300;
	// begin inline asm
	div.full.f32 %r656, %r169, %r125;
	// end inline asm
	mov.b32 	%f81, %r655;
	.loc	1 159 56
	abs.ftz.f32 	%f183, %f80;
	setp.ltu.f32 	%p70, %f183, 0f3F19999A;
	@%p70 bra 	$L__BB0_42;
	bra.uni 	$L__BB0_41;
$L__BB0_42:
	mul.f32 	%f899, %f80, %f80;
	mov.f32 	%f900, 0fBD563CAE;
	mov.f32 	%f901, 0f3C80F082;
	fma.rn.ftz.f32 	%f902, %f901, %f899, %f900;
	mov.f32 	%f903, 0f3E085941;
	fma.rn.ftz.f32 	%f904, %f902, %f899, %f903;
	mov.f32 	%f905, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f906, %f904, %f899, %f905;
	mov.f32 	%f907, 0f00000000;
	fma.rn.ftz.f32 	%f908, %f906, %f899, %f907;
	fma.rn.ftz.f32 	%f2233, %f908, %f80, %f80;
	bra.uni 	$L__BB0_43;
$L__BB0_41:
	mul.f32 	%f893, %f183, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f894, %f893;
	add.f32 	%f892, %f894, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f891,%f892;
	// end inline asm
	mov.f32 	%f895, 0f3F800000;
	mov.f32 	%f896, 0fC0000000;
	fma.rn.ftz.f32 	%f897, %f891, %f896, %f895;
	setp.ge.f32 	%p71, %f183, 0f41102CB4;
	selp.f32 	%f898, 0f3F800000, %f897, %p71;
	mov.b32 	%r367, %f898;
	and.b32  	%r369, %r654, -2147483648;
	or.b32  	%r370, %r369, %r367;
	mov.b32 	%f2233, %r370;
$L__BB0_43:
	.loc	1 159 0
	mov.b32 	%r175, %f2301;
	// begin inline asm
	div.full.f32 %r657, %r172, %r125;
	// end inline asm
	mov.b32 	%f82, %r656;
	.loc	1 159 56
	abs.ftz.f32 	%f187, %f81;
	setp.ltu.f32 	%p72, %f187, 0f3F19999A;
	@%p72 bra 	$L__BB0_45;
	bra.uni 	$L__BB0_44;
$L__BB0_45:
	mul.f32 	%f917, %f81, %f81;
	mov.f32 	%f918, 0fBD563CAE;
	mov.f32 	%f919, 0f3C80F082;
	fma.rn.ftz.f32 	%f920, %f919, %f917, %f918;
	mov.f32 	%f921, 0f3E085941;
	fma.rn.ftz.f32 	%f922, %f920, %f917, %f921;
	mov.f32 	%f923, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f924, %f922, %f917, %f923;
	mov.f32 	%f925, 0f00000000;
	fma.rn.ftz.f32 	%f926, %f924, %f917, %f925;
	fma.rn.ftz.f32 	%f2234, %f926, %f81, %f81;
	bra.uni 	$L__BB0_46;
$L__BB0_44:
	mul.f32 	%f911, %f187, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f912, %f911;
	add.f32 	%f910, %f912, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f909,%f910;
	// end inline asm
	mov.f32 	%f913, 0f3F800000;
	mov.f32 	%f914, 0fC0000000;
	fma.rn.ftz.f32 	%f915, %f909, %f914, %f913;
	setp.ge.f32 	%p73, %f187, 0f41102CB4;
	selp.f32 	%f916, 0f3F800000, %f915, %p73;
	mov.b32 	%r371, %f916;
	and.b32  	%r373, %r655, -2147483648;
	or.b32  	%r374, %r373, %r371;
	mov.b32 	%f2234, %r374;
$L__BB0_46:
	.loc	1 159 0
	mov.b32 	%r178, %f2302;
	// begin inline asm
	div.full.f32 %r658, %r175, %r125;
	// end inline asm
	mov.b32 	%f83, %r657;
	.loc	1 159 56
	abs.ftz.f32 	%f191, %f82;
	setp.ltu.f32 	%p74, %f191, 0f3F19999A;
	@%p74 bra 	$L__BB0_48;
	bra.uni 	$L__BB0_47;
$L__BB0_48:
	mul.f32 	%f935, %f82, %f82;
	mov.f32 	%f936, 0fBD563CAE;
	mov.f32 	%f937, 0f3C80F082;
	fma.rn.ftz.f32 	%f938, %f937, %f935, %f936;
	mov.f32 	%f939, 0f3E085941;
	fma.rn.ftz.f32 	%f940, %f938, %f935, %f939;
	mov.f32 	%f941, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f942, %f940, %f935, %f941;
	mov.f32 	%f943, 0f00000000;
	fma.rn.ftz.f32 	%f944, %f942, %f935, %f943;
	fma.rn.ftz.f32 	%f2235, %f944, %f82, %f82;
	bra.uni 	$L__BB0_49;
$L__BB0_47:
	mul.f32 	%f929, %f191, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f930, %f929;
	add.f32 	%f928, %f930, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f927,%f928;
	// end inline asm
	mov.f32 	%f931, 0f3F800000;
	mov.f32 	%f932, 0fC0000000;
	fma.rn.ftz.f32 	%f933, %f927, %f932, %f931;
	setp.ge.f32 	%p75, %f191, 0f41102CB4;
	selp.f32 	%f934, 0f3F800000, %f933, %p75;
	mov.b32 	%r375, %f934;
	and.b32  	%r377, %r656, -2147483648;
	or.b32  	%r378, %r377, %r375;
	mov.b32 	%f2235, %r378;
$L__BB0_49:
	.loc	1 159 0
	mov.b32 	%r181, %f2303;
	// begin inline asm
	div.full.f32 %r659, %r178, %r125;
	// end inline asm
	mov.b32 	%f84, %r658;
	.loc	1 159 56
	abs.ftz.f32 	%f195, %f83;
	setp.ltu.f32 	%p76, %f195, 0f3F19999A;
	@%p76 bra 	$L__BB0_51;
	bra.uni 	$L__BB0_50;
$L__BB0_51:
	mul.f32 	%f953, %f83, %f83;
	mov.f32 	%f954, 0fBD563CAE;
	mov.f32 	%f955, 0f3C80F082;
	fma.rn.ftz.f32 	%f956, %f955, %f953, %f954;
	mov.f32 	%f957, 0f3E085941;
	fma.rn.ftz.f32 	%f958, %f956, %f953, %f957;
	mov.f32 	%f959, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f960, %f958, %f953, %f959;
	mov.f32 	%f961, 0f00000000;
	fma.rn.ftz.f32 	%f962, %f960, %f953, %f961;
	fma.rn.ftz.f32 	%f2236, %f962, %f83, %f83;
	bra.uni 	$L__BB0_52;
$L__BB0_50:
	mul.f32 	%f947, %f195, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f948, %f947;
	add.f32 	%f946, %f948, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f945,%f946;
	// end inline asm
	mov.f32 	%f949, 0f3F800000;
	mov.f32 	%f950, 0fC0000000;
	fma.rn.ftz.f32 	%f951, %f945, %f950, %f949;
	setp.ge.f32 	%p77, %f195, 0f41102CB4;
	selp.f32 	%f952, 0f3F800000, %f951, %p77;
	mov.b32 	%r379, %f952;
	and.b32  	%r381, %r657, -2147483648;
	or.b32  	%r382, %r381, %r379;
	mov.b32 	%f2236, %r382;
$L__BB0_52:
	.loc	1 159 0
	mov.b32 	%r184, %f2304;
	// begin inline asm
	div.full.f32 %r660, %r181, %r125;
	// end inline asm
	mov.b32 	%f85, %r659;
	.loc	1 159 56
	abs.ftz.f32 	%f199, %f84;
	setp.ltu.f32 	%p78, %f199, 0f3F19999A;
	@%p78 bra 	$L__BB0_54;
	bra.uni 	$L__BB0_53;
$L__BB0_54:
	mul.f32 	%f971, %f84, %f84;
	mov.f32 	%f972, 0fBD563CAE;
	mov.f32 	%f973, 0f3C80F082;
	fma.rn.ftz.f32 	%f974, %f973, %f971, %f972;
	mov.f32 	%f975, 0f3E085941;
	fma.rn.ftz.f32 	%f976, %f974, %f971, %f975;
	mov.f32 	%f977, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f978, %f976, %f971, %f977;
	mov.f32 	%f979, 0f00000000;
	fma.rn.ftz.f32 	%f980, %f978, %f971, %f979;
	fma.rn.ftz.f32 	%f2237, %f980, %f84, %f84;
	bra.uni 	$L__BB0_55;
$L__BB0_53:
	mul.f32 	%f965, %f199, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f966, %f965;
	add.f32 	%f964, %f966, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f963,%f964;
	// end inline asm
	mov.f32 	%f967, 0f3F800000;
	mov.f32 	%f968, 0fC0000000;
	fma.rn.ftz.f32 	%f969, %f963, %f968, %f967;
	setp.ge.f32 	%p79, %f199, 0f41102CB4;
	selp.f32 	%f970, 0f3F800000, %f969, %p79;
	mov.b32 	%r383, %f970;
	and.b32  	%r385, %r658, -2147483648;
	or.b32  	%r386, %r385, %r383;
	mov.b32 	%f2237, %r386;
$L__BB0_55:
	.loc	1 159 0
	mov.b32 	%r187, %f2305;
	// begin inline asm
	div.full.f32 %r661, %r184, %r125;
	// end inline asm
	mov.b32 	%f86, %r660;
	.loc	1 159 56
	abs.ftz.f32 	%f203, %f85;
	setp.ltu.f32 	%p80, %f203, 0f3F19999A;
	@%p80 bra 	$L__BB0_57;
	bra.uni 	$L__BB0_56;
$L__BB0_57:
	mul.f32 	%f989, %f85, %f85;
	mov.f32 	%f990, 0fBD563CAE;
	mov.f32 	%f991, 0f3C80F082;
	fma.rn.ftz.f32 	%f992, %f991, %f989, %f990;
	mov.f32 	%f993, 0f3E085941;
	fma.rn.ftz.f32 	%f994, %f992, %f989, %f993;
	mov.f32 	%f995, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f996, %f994, %f989, %f995;
	mov.f32 	%f997, 0f00000000;
	fma.rn.ftz.f32 	%f998, %f996, %f989, %f997;
	fma.rn.ftz.f32 	%f2238, %f998, %f85, %f85;
	bra.uni 	$L__BB0_58;
$L__BB0_56:
	mul.f32 	%f983, %f203, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f984, %f983;
	add.f32 	%f982, %f984, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f981,%f982;
	// end inline asm
	mov.f32 	%f985, 0f3F800000;
	mov.f32 	%f986, 0fC0000000;
	fma.rn.ftz.f32 	%f987, %f981, %f986, %f985;
	setp.ge.f32 	%p81, %f203, 0f41102CB4;
	selp.f32 	%f988, 0f3F800000, %f987, %p81;
	mov.b32 	%r387, %f988;
	and.b32  	%r389, %r659, -2147483648;
	or.b32  	%r390, %r389, %r387;
	mov.b32 	%f2238, %r390;
$L__BB0_58:
	.loc	1 159 0
	mov.b32 	%r190, %f2306;
	// begin inline asm
	div.full.f32 %r662, %r187, %r125;
	// end inline asm
	mov.b32 	%f87, %r661;
	.loc	1 159 56
	abs.ftz.f32 	%f207, %f86;
	setp.ltu.f32 	%p82, %f207, 0f3F19999A;
	@%p82 bra 	$L__BB0_60;
	bra.uni 	$L__BB0_59;
$L__BB0_60:
	mul.f32 	%f1007, %f86, %f86;
	mov.f32 	%f1008, 0fBD563CAE;
	mov.f32 	%f1009, 0f3C80F082;
	fma.rn.ftz.f32 	%f1010, %f1009, %f1007, %f1008;
	mov.f32 	%f1011, 0f3E085941;
	fma.rn.ftz.f32 	%f1012, %f1010, %f1007, %f1011;
	mov.f32 	%f1013, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1014, %f1012, %f1007, %f1013;
	mov.f32 	%f1015, 0f00000000;
	fma.rn.ftz.f32 	%f1016, %f1014, %f1007, %f1015;
	fma.rn.ftz.f32 	%f2239, %f1016, %f86, %f86;
	bra.uni 	$L__BB0_61;
$L__BB0_59:
	mul.f32 	%f1001, %f207, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1002, %f1001;
	add.f32 	%f1000, %f1002, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f999,%f1000;
	// end inline asm
	mov.f32 	%f1003, 0f3F800000;
	mov.f32 	%f1004, 0fC0000000;
	fma.rn.ftz.f32 	%f1005, %f999, %f1004, %f1003;
	setp.ge.f32 	%p83, %f207, 0f41102CB4;
	selp.f32 	%f1006, 0f3F800000, %f1005, %p83;
	mov.b32 	%r391, %f1006;
	and.b32  	%r393, %r660, -2147483648;
	or.b32  	%r394, %r393, %r391;
	mov.b32 	%f2239, %r394;
$L__BB0_61:
	.loc	1 159 0
	mov.b32 	%r193, %f2307;
	// begin inline asm
	div.full.f32 %r663, %r190, %r125;
	// end inline asm
	mov.b32 	%f88, %r662;
	.loc	1 159 56
	abs.ftz.f32 	%f211, %f87;
	setp.ltu.f32 	%p84, %f211, 0f3F19999A;
	@%p84 bra 	$L__BB0_63;
	bra.uni 	$L__BB0_62;
$L__BB0_63:
	mul.f32 	%f1025, %f87, %f87;
	mov.f32 	%f1026, 0fBD563CAE;
	mov.f32 	%f1027, 0f3C80F082;
	fma.rn.ftz.f32 	%f1028, %f1027, %f1025, %f1026;
	mov.f32 	%f1029, 0f3E085941;
	fma.rn.ftz.f32 	%f1030, %f1028, %f1025, %f1029;
	mov.f32 	%f1031, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1032, %f1030, %f1025, %f1031;
	mov.f32 	%f1033, 0f00000000;
	fma.rn.ftz.f32 	%f1034, %f1032, %f1025, %f1033;
	fma.rn.ftz.f32 	%f2240, %f1034, %f87, %f87;
	bra.uni 	$L__BB0_64;
$L__BB0_62:
	mul.f32 	%f1019, %f211, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1020, %f1019;
	add.f32 	%f1018, %f1020, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1017,%f1018;
	// end inline asm
	mov.f32 	%f1021, 0f3F800000;
	mov.f32 	%f1022, 0fC0000000;
	fma.rn.ftz.f32 	%f1023, %f1017, %f1022, %f1021;
	setp.ge.f32 	%p85, %f211, 0f41102CB4;
	selp.f32 	%f1024, 0f3F800000, %f1023, %p85;
	mov.b32 	%r395, %f1024;
	and.b32  	%r397, %r661, -2147483648;
	or.b32  	%r398, %r397, %r395;
	mov.b32 	%f2240, %r398;
$L__BB0_64:
	.loc	1 159 0
	mov.b32 	%r196, %f2308;
	// begin inline asm
	div.full.f32 %r664, %r193, %r125;
	// end inline asm
	mov.b32 	%f89, %r663;
	.loc	1 159 56
	abs.ftz.f32 	%f215, %f88;
	setp.ltu.f32 	%p86, %f215, 0f3F19999A;
	@%p86 bra 	$L__BB0_66;
	bra.uni 	$L__BB0_65;
$L__BB0_66:
	mul.f32 	%f1043, %f88, %f88;
	mov.f32 	%f1044, 0fBD563CAE;
	mov.f32 	%f1045, 0f3C80F082;
	fma.rn.ftz.f32 	%f1046, %f1045, %f1043, %f1044;
	mov.f32 	%f1047, 0f3E085941;
	fma.rn.ftz.f32 	%f1048, %f1046, %f1043, %f1047;
	mov.f32 	%f1049, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1050, %f1048, %f1043, %f1049;
	mov.f32 	%f1051, 0f00000000;
	fma.rn.ftz.f32 	%f1052, %f1050, %f1043, %f1051;
	fma.rn.ftz.f32 	%f2241, %f1052, %f88, %f88;
	bra.uni 	$L__BB0_67;
$L__BB0_65:
	mul.f32 	%f1037, %f215, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1038, %f1037;
	add.f32 	%f1036, %f1038, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1035,%f1036;
	// end inline asm
	mov.f32 	%f1039, 0f3F800000;
	mov.f32 	%f1040, 0fC0000000;
	fma.rn.ftz.f32 	%f1041, %f1035, %f1040, %f1039;
	setp.ge.f32 	%p87, %f215, 0f41102CB4;
	selp.f32 	%f1042, 0f3F800000, %f1041, %p87;
	mov.b32 	%r399, %f1042;
	and.b32  	%r401, %r662, -2147483648;
	or.b32  	%r402, %r401, %r399;
	mov.b32 	%f2241, %r402;
$L__BB0_67:
	.loc	1 159 0
	mov.b32 	%r199, %f2309;
	// begin inline asm
	div.full.f32 %r665, %r196, %r125;
	// end inline asm
	mov.b32 	%f90, %r664;
	.loc	1 159 56
	abs.ftz.f32 	%f219, %f89;
	setp.ltu.f32 	%p88, %f219, 0f3F19999A;
	@%p88 bra 	$L__BB0_69;
	bra.uni 	$L__BB0_68;
$L__BB0_69:
	mul.f32 	%f1061, %f89, %f89;
	mov.f32 	%f1062, 0fBD563CAE;
	mov.f32 	%f1063, 0f3C80F082;
	fma.rn.ftz.f32 	%f1064, %f1063, %f1061, %f1062;
	mov.f32 	%f1065, 0f3E085941;
	fma.rn.ftz.f32 	%f1066, %f1064, %f1061, %f1065;
	mov.f32 	%f1067, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1068, %f1066, %f1061, %f1067;
	mov.f32 	%f1069, 0f00000000;
	fma.rn.ftz.f32 	%f1070, %f1068, %f1061, %f1069;
	fma.rn.ftz.f32 	%f2242, %f1070, %f89, %f89;
	bra.uni 	$L__BB0_70;
$L__BB0_68:
	mul.f32 	%f1055, %f219, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1056, %f1055;
	add.f32 	%f1054, %f1056, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1053,%f1054;
	// end inline asm
	mov.f32 	%f1057, 0f3F800000;
	mov.f32 	%f1058, 0fC0000000;
	fma.rn.ftz.f32 	%f1059, %f1053, %f1058, %f1057;
	setp.ge.f32 	%p89, %f219, 0f41102CB4;
	selp.f32 	%f1060, 0f3F800000, %f1059, %p89;
	mov.b32 	%r403, %f1060;
	and.b32  	%r405, %r663, -2147483648;
	or.b32  	%r406, %r405, %r403;
	mov.b32 	%f2242, %r406;
$L__BB0_70:
	.loc	1 159 0
	mov.b32 	%r202, %f2310;
	// begin inline asm
	div.full.f32 %r666, %r199, %r125;
	// end inline asm
	mov.b32 	%f91, %r665;
	.loc	1 159 56
	abs.ftz.f32 	%f223, %f90;
	setp.ltu.f32 	%p90, %f223, 0f3F19999A;
	@%p90 bra 	$L__BB0_72;
	bra.uni 	$L__BB0_71;
$L__BB0_72:
	mul.f32 	%f1079, %f90, %f90;
	mov.f32 	%f1080, 0fBD563CAE;
	mov.f32 	%f1081, 0f3C80F082;
	fma.rn.ftz.f32 	%f1082, %f1081, %f1079, %f1080;
	mov.f32 	%f1083, 0f3E085941;
	fma.rn.ftz.f32 	%f1084, %f1082, %f1079, %f1083;
	mov.f32 	%f1085, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1086, %f1084, %f1079, %f1085;
	mov.f32 	%f1087, 0f00000000;
	fma.rn.ftz.f32 	%f1088, %f1086, %f1079, %f1087;
	fma.rn.ftz.f32 	%f2243, %f1088, %f90, %f90;
	bra.uni 	$L__BB0_73;
$L__BB0_71:
	mul.f32 	%f1073, %f223, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1074, %f1073;
	add.f32 	%f1072, %f1074, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1071,%f1072;
	// end inline asm
	mov.f32 	%f1075, 0f3F800000;
	mov.f32 	%f1076, 0fC0000000;
	fma.rn.ftz.f32 	%f1077, %f1071, %f1076, %f1075;
	setp.ge.f32 	%p91, %f223, 0f41102CB4;
	selp.f32 	%f1078, 0f3F800000, %f1077, %p91;
	mov.b32 	%r407, %f1078;
	and.b32  	%r409, %r664, -2147483648;
	or.b32  	%r410, %r409, %r407;
	mov.b32 	%f2243, %r410;
$L__BB0_73:
	.loc	1 159 0
	mov.b32 	%r205, %f2311;
	// begin inline asm
	div.full.f32 %r667, %r202, %r125;
	// end inline asm
	mov.b32 	%f92, %r666;
	.loc	1 159 56
	abs.ftz.f32 	%f227, %f91;
	setp.ltu.f32 	%p92, %f227, 0f3F19999A;
	@%p92 bra 	$L__BB0_75;
	bra.uni 	$L__BB0_74;
$L__BB0_75:
	mul.f32 	%f1097, %f91, %f91;
	mov.f32 	%f1098, 0fBD563CAE;
	mov.f32 	%f1099, 0f3C80F082;
	fma.rn.ftz.f32 	%f1100, %f1099, %f1097, %f1098;
	mov.f32 	%f1101, 0f3E085941;
	fma.rn.ftz.f32 	%f1102, %f1100, %f1097, %f1101;
	mov.f32 	%f1103, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1104, %f1102, %f1097, %f1103;
	mov.f32 	%f1105, 0f00000000;
	fma.rn.ftz.f32 	%f1106, %f1104, %f1097, %f1105;
	fma.rn.ftz.f32 	%f2244, %f1106, %f91, %f91;
	bra.uni 	$L__BB0_76;
$L__BB0_74:
	mul.f32 	%f1091, %f227, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1092, %f1091;
	add.f32 	%f1090, %f1092, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1089,%f1090;
	// end inline asm
	mov.f32 	%f1093, 0f3F800000;
	mov.f32 	%f1094, 0fC0000000;
	fma.rn.ftz.f32 	%f1095, %f1089, %f1094, %f1093;
	setp.ge.f32 	%p93, %f227, 0f41102CB4;
	selp.f32 	%f1096, 0f3F800000, %f1095, %p93;
	mov.b32 	%r411, %f1096;
	and.b32  	%r413, %r665, -2147483648;
	or.b32  	%r414, %r413, %r411;
	mov.b32 	%f2244, %r414;
$L__BB0_76:
	.loc	1 159 0
	mov.b32 	%r208, %f2312;
	// begin inline asm
	div.full.f32 %r668, %r205, %r125;
	// end inline asm
	mov.b32 	%f93, %r667;
	.loc	1 159 56
	abs.ftz.f32 	%f231, %f92;
	setp.ltu.f32 	%p94, %f231, 0f3F19999A;
	@%p94 bra 	$L__BB0_78;
	bra.uni 	$L__BB0_77;
$L__BB0_78:
	mul.f32 	%f1115, %f92, %f92;
	mov.f32 	%f1116, 0fBD563CAE;
	mov.f32 	%f1117, 0f3C80F082;
	fma.rn.ftz.f32 	%f1118, %f1117, %f1115, %f1116;
	mov.f32 	%f1119, 0f3E085941;
	fma.rn.ftz.f32 	%f1120, %f1118, %f1115, %f1119;
	mov.f32 	%f1121, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1122, %f1120, %f1115, %f1121;
	mov.f32 	%f1123, 0f00000000;
	fma.rn.ftz.f32 	%f1124, %f1122, %f1115, %f1123;
	fma.rn.ftz.f32 	%f2245, %f1124, %f92, %f92;
	bra.uni 	$L__BB0_79;
$L__BB0_77:
	mul.f32 	%f1109, %f231, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1110, %f1109;
	add.f32 	%f1108, %f1110, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1107,%f1108;
	// end inline asm
	mov.f32 	%f1111, 0f3F800000;
	mov.f32 	%f1112, 0fC0000000;
	fma.rn.ftz.f32 	%f1113, %f1107, %f1112, %f1111;
	setp.ge.f32 	%p95, %f231, 0f41102CB4;
	selp.f32 	%f1114, 0f3F800000, %f1113, %p95;
	mov.b32 	%r415, %f1114;
	and.b32  	%r417, %r666, -2147483648;
	or.b32  	%r418, %r417, %r415;
	mov.b32 	%f2245, %r418;
$L__BB0_79:
	.loc	1 159 0
	mov.b32 	%r211, %f2313;
	// begin inline asm
	div.full.f32 %r669, %r208, %r125;
	// end inline asm
	mov.b32 	%f94, %r668;
	.loc	1 159 56
	abs.ftz.f32 	%f235, %f93;
	setp.ltu.f32 	%p96, %f235, 0f3F19999A;
	@%p96 bra 	$L__BB0_81;
	bra.uni 	$L__BB0_80;
$L__BB0_81:
	mul.f32 	%f1133, %f93, %f93;
	mov.f32 	%f1134, 0fBD563CAE;
	mov.f32 	%f1135, 0f3C80F082;
	fma.rn.ftz.f32 	%f1136, %f1135, %f1133, %f1134;
	mov.f32 	%f1137, 0f3E085941;
	fma.rn.ftz.f32 	%f1138, %f1136, %f1133, %f1137;
	mov.f32 	%f1139, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1140, %f1138, %f1133, %f1139;
	mov.f32 	%f1141, 0f00000000;
	fma.rn.ftz.f32 	%f1142, %f1140, %f1133, %f1141;
	fma.rn.ftz.f32 	%f2246, %f1142, %f93, %f93;
	bra.uni 	$L__BB0_82;
$L__BB0_80:
	mul.f32 	%f1127, %f235, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1128, %f1127;
	add.f32 	%f1126, %f1128, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1125,%f1126;
	// end inline asm
	mov.f32 	%f1129, 0f3F800000;
	mov.f32 	%f1130, 0fC0000000;
	fma.rn.ftz.f32 	%f1131, %f1125, %f1130, %f1129;
	setp.ge.f32 	%p97, %f235, 0f41102CB4;
	selp.f32 	%f1132, 0f3F800000, %f1131, %p97;
	mov.b32 	%r419, %f1132;
	and.b32  	%r421, %r667, -2147483648;
	or.b32  	%r422, %r421, %r419;
	mov.b32 	%f2246, %r422;
$L__BB0_82:
	.loc	1 159 0
	mov.b32 	%r214, %f2314;
	// begin inline asm
	div.full.f32 %r670, %r211, %r125;
	// end inline asm
	mov.b32 	%f95, %r669;
	.loc	1 159 56
	abs.ftz.f32 	%f239, %f94;
	setp.ltu.f32 	%p98, %f239, 0f3F19999A;
	@%p98 bra 	$L__BB0_84;
	bra.uni 	$L__BB0_83;
$L__BB0_84:
	mul.f32 	%f1151, %f94, %f94;
	mov.f32 	%f1152, 0fBD563CAE;
	mov.f32 	%f1153, 0f3C80F082;
	fma.rn.ftz.f32 	%f1154, %f1153, %f1151, %f1152;
	mov.f32 	%f1155, 0f3E085941;
	fma.rn.ftz.f32 	%f1156, %f1154, %f1151, %f1155;
	mov.f32 	%f1157, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1158, %f1156, %f1151, %f1157;
	mov.f32 	%f1159, 0f00000000;
	fma.rn.ftz.f32 	%f1160, %f1158, %f1151, %f1159;
	fma.rn.ftz.f32 	%f2247, %f1160, %f94, %f94;
	bra.uni 	$L__BB0_85;
$L__BB0_83:
	mul.f32 	%f1145, %f239, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1146, %f1145;
	add.f32 	%f1144, %f1146, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1143,%f1144;
	// end inline asm
	mov.f32 	%f1147, 0f3F800000;
	mov.f32 	%f1148, 0fC0000000;
	fma.rn.ftz.f32 	%f1149, %f1143, %f1148, %f1147;
	setp.ge.f32 	%p99, %f239, 0f41102CB4;
	selp.f32 	%f1150, 0f3F800000, %f1149, %p99;
	mov.b32 	%r423, %f1150;
	and.b32  	%r425, %r668, -2147483648;
	or.b32  	%r426, %r425, %r423;
	mov.b32 	%f2247, %r426;
$L__BB0_85:
	.loc	1 159 0
	mov.b32 	%r217, %f2315;
	// begin inline asm
	div.full.f32 %r671, %r214, %r125;
	// end inline asm
	mov.b32 	%f96, %r670;
	.loc	1 159 56
	abs.ftz.f32 	%f243, %f95;
	setp.ltu.f32 	%p100, %f243, 0f3F19999A;
	@%p100 bra 	$L__BB0_87;
	bra.uni 	$L__BB0_86;
$L__BB0_87:
	mul.f32 	%f1169, %f95, %f95;
	mov.f32 	%f1170, 0fBD563CAE;
	mov.f32 	%f1171, 0f3C80F082;
	fma.rn.ftz.f32 	%f1172, %f1171, %f1169, %f1170;
	mov.f32 	%f1173, 0f3E085941;
	fma.rn.ftz.f32 	%f1174, %f1172, %f1169, %f1173;
	mov.f32 	%f1175, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1176, %f1174, %f1169, %f1175;
	mov.f32 	%f1177, 0f00000000;
	fma.rn.ftz.f32 	%f1178, %f1176, %f1169, %f1177;
	fma.rn.ftz.f32 	%f2248, %f1178, %f95, %f95;
	bra.uni 	$L__BB0_88;
$L__BB0_86:
	mul.f32 	%f1163, %f243, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1164, %f1163;
	add.f32 	%f1162, %f1164, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1161,%f1162;
	// end inline asm
	mov.f32 	%f1165, 0f3F800000;
	mov.f32 	%f1166, 0fC0000000;
	fma.rn.ftz.f32 	%f1167, %f1161, %f1166, %f1165;
	setp.ge.f32 	%p101, %f243, 0f41102CB4;
	selp.f32 	%f1168, 0f3F800000, %f1167, %p101;
	mov.b32 	%r427, %f1168;
	and.b32  	%r429, %r669, -2147483648;
	or.b32  	%r430, %r429, %r427;
	mov.b32 	%f2248, %r430;
$L__BB0_88:
	.loc	1 159 0
	mov.b32 	%r220, %f2316;
	// begin inline asm
	div.full.f32 %r672, %r217, %r125;
	// end inline asm
	mov.b32 	%f97, %r671;
	.loc	1 159 56
	abs.ftz.f32 	%f247, %f96;
	setp.ltu.f32 	%p102, %f247, 0f3F19999A;
	@%p102 bra 	$L__BB0_90;
	bra.uni 	$L__BB0_89;
$L__BB0_90:
	mul.f32 	%f1187, %f96, %f96;
	mov.f32 	%f1188, 0fBD563CAE;
	mov.f32 	%f1189, 0f3C80F082;
	fma.rn.ftz.f32 	%f1190, %f1189, %f1187, %f1188;
	mov.f32 	%f1191, 0f3E085941;
	fma.rn.ftz.f32 	%f1192, %f1190, %f1187, %f1191;
	mov.f32 	%f1193, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1194, %f1192, %f1187, %f1193;
	mov.f32 	%f1195, 0f00000000;
	fma.rn.ftz.f32 	%f1196, %f1194, %f1187, %f1195;
	fma.rn.ftz.f32 	%f2249, %f1196, %f96, %f96;
	bra.uni 	$L__BB0_91;
$L__BB0_89:
	mul.f32 	%f1181, %f247, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1182, %f1181;
	add.f32 	%f1180, %f1182, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1179,%f1180;
	// end inline asm
	mov.f32 	%f1183, 0f3F800000;
	mov.f32 	%f1184, 0fC0000000;
	fma.rn.ftz.f32 	%f1185, %f1179, %f1184, %f1183;
	setp.ge.f32 	%p103, %f247, 0f41102CB4;
	selp.f32 	%f1186, 0f3F800000, %f1185, %p103;
	mov.b32 	%r431, %f1186;
	and.b32  	%r433, %r670, -2147483648;
	or.b32  	%r434, %r433, %r431;
	mov.b32 	%f2249, %r434;
$L__BB0_91:
	.loc	1 159 0
	mov.b32 	%r223, %f2317;
	// begin inline asm
	div.full.f32 %r673, %r220, %r125;
	// end inline asm
	mov.b32 	%f98, %r672;
	.loc	1 159 56
	abs.ftz.f32 	%f251, %f97;
	setp.ltu.f32 	%p104, %f251, 0f3F19999A;
	@%p104 bra 	$L__BB0_93;
	bra.uni 	$L__BB0_92;
$L__BB0_93:
	mul.f32 	%f1205, %f97, %f97;
	mov.f32 	%f1206, 0fBD563CAE;
	mov.f32 	%f1207, 0f3C80F082;
	fma.rn.ftz.f32 	%f1208, %f1207, %f1205, %f1206;
	mov.f32 	%f1209, 0f3E085941;
	fma.rn.ftz.f32 	%f1210, %f1208, %f1205, %f1209;
	mov.f32 	%f1211, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1212, %f1210, %f1205, %f1211;
	mov.f32 	%f1213, 0f00000000;
	fma.rn.ftz.f32 	%f1214, %f1212, %f1205, %f1213;
	fma.rn.ftz.f32 	%f2250, %f1214, %f97, %f97;
	bra.uni 	$L__BB0_94;
$L__BB0_92:
	mul.f32 	%f1199, %f251, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1200, %f1199;
	add.f32 	%f1198, %f1200, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1197,%f1198;
	// end inline asm
	mov.f32 	%f1201, 0f3F800000;
	mov.f32 	%f1202, 0fC0000000;
	fma.rn.ftz.f32 	%f1203, %f1197, %f1202, %f1201;
	setp.ge.f32 	%p105, %f251, 0f41102CB4;
	selp.f32 	%f1204, 0f3F800000, %f1203, %p105;
	mov.b32 	%r435, %f1204;
	and.b32  	%r437, %r671, -2147483648;
	or.b32  	%r438, %r437, %r435;
	mov.b32 	%f2250, %r438;
$L__BB0_94:
	.loc	1 159 0
	mov.b32 	%r226, %f2318;
	// begin inline asm
	div.full.f32 %r674, %r223, %r125;
	// end inline asm
	mov.b32 	%f99, %r673;
	.loc	1 159 56
	abs.ftz.f32 	%f255, %f98;
	setp.ltu.f32 	%p106, %f255, 0f3F19999A;
	@%p106 bra 	$L__BB0_96;
	bra.uni 	$L__BB0_95;
$L__BB0_96:
	mul.f32 	%f1223, %f98, %f98;
	mov.f32 	%f1224, 0fBD563CAE;
	mov.f32 	%f1225, 0f3C80F082;
	fma.rn.ftz.f32 	%f1226, %f1225, %f1223, %f1224;
	mov.f32 	%f1227, 0f3E085941;
	fma.rn.ftz.f32 	%f1228, %f1226, %f1223, %f1227;
	mov.f32 	%f1229, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1230, %f1228, %f1223, %f1229;
	mov.f32 	%f1231, 0f00000000;
	fma.rn.ftz.f32 	%f1232, %f1230, %f1223, %f1231;
	fma.rn.ftz.f32 	%f2251, %f1232, %f98, %f98;
	bra.uni 	$L__BB0_97;
$L__BB0_95:
	mul.f32 	%f1217, %f255, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1218, %f1217;
	add.f32 	%f1216, %f1218, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1215,%f1216;
	// end inline asm
	mov.f32 	%f1219, 0f3F800000;
	mov.f32 	%f1220, 0fC0000000;
	fma.rn.ftz.f32 	%f1221, %f1215, %f1220, %f1219;
	setp.ge.f32 	%p107, %f255, 0f41102CB4;
	selp.f32 	%f1222, 0f3F800000, %f1221, %p107;
	mov.b32 	%r439, %f1222;
	and.b32  	%r441, %r672, -2147483648;
	or.b32  	%r442, %r441, %r439;
	mov.b32 	%f2251, %r442;
$L__BB0_97:
	.loc	1 159 0
	mov.b32 	%r229, %f2319;
	// begin inline asm
	div.full.f32 %r675, %r226, %r125;
	// end inline asm
	mov.b32 	%f100, %r674;
	.loc	1 159 56
	abs.ftz.f32 	%f259, %f99;
	setp.ltu.f32 	%p108, %f259, 0f3F19999A;
	@%p108 bra 	$L__BB0_99;
	bra.uni 	$L__BB0_98;
$L__BB0_99:
	mul.f32 	%f1241, %f99, %f99;
	mov.f32 	%f1242, 0fBD563CAE;
	mov.f32 	%f1243, 0f3C80F082;
	fma.rn.ftz.f32 	%f1244, %f1243, %f1241, %f1242;
	mov.f32 	%f1245, 0f3E085941;
	fma.rn.ftz.f32 	%f1246, %f1244, %f1241, %f1245;
	mov.f32 	%f1247, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1248, %f1246, %f1241, %f1247;
	mov.f32 	%f1249, 0f00000000;
	fma.rn.ftz.f32 	%f1250, %f1248, %f1241, %f1249;
	fma.rn.ftz.f32 	%f2252, %f1250, %f99, %f99;
	bra.uni 	$L__BB0_100;
$L__BB0_98:
	mul.f32 	%f1235, %f259, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1236, %f1235;
	add.f32 	%f1234, %f1236, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1233,%f1234;
	// end inline asm
	mov.f32 	%f1237, 0f3F800000;
	mov.f32 	%f1238, 0fC0000000;
	fma.rn.ftz.f32 	%f1239, %f1233, %f1238, %f1237;
	setp.ge.f32 	%p109, %f259, 0f41102CB4;
	selp.f32 	%f1240, 0f3F800000, %f1239, %p109;
	mov.b32 	%r443, %f1240;
	and.b32  	%r445, %r673, -2147483648;
	or.b32  	%r446, %r445, %r443;
	mov.b32 	%f2252, %r446;
$L__BB0_100:
	.loc	1 159 0
	mov.b32 	%r232, %f2320;
	// begin inline asm
	div.full.f32 %r676, %r229, %r125;
	// end inline asm
	mov.b32 	%f101, %r675;
	.loc	1 159 56
	abs.ftz.f32 	%f263, %f100;
	setp.ltu.f32 	%p110, %f263, 0f3F19999A;
	@%p110 bra 	$L__BB0_102;
	bra.uni 	$L__BB0_101;
$L__BB0_102:
	mul.f32 	%f1259, %f100, %f100;
	mov.f32 	%f1260, 0fBD563CAE;
	mov.f32 	%f1261, 0f3C80F082;
	fma.rn.ftz.f32 	%f1262, %f1261, %f1259, %f1260;
	mov.f32 	%f1263, 0f3E085941;
	fma.rn.ftz.f32 	%f1264, %f1262, %f1259, %f1263;
	mov.f32 	%f1265, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1266, %f1264, %f1259, %f1265;
	mov.f32 	%f1267, 0f00000000;
	fma.rn.ftz.f32 	%f1268, %f1266, %f1259, %f1267;
	fma.rn.ftz.f32 	%f2253, %f1268, %f100, %f100;
	bra.uni 	$L__BB0_103;
$L__BB0_101:
	mul.f32 	%f1253, %f263, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1254, %f1253;
	add.f32 	%f1252, %f1254, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1251,%f1252;
	// end inline asm
	mov.f32 	%f1255, 0f3F800000;
	mov.f32 	%f1256, 0fC0000000;
	fma.rn.ftz.f32 	%f1257, %f1251, %f1256, %f1255;
	setp.ge.f32 	%p111, %f263, 0f41102CB4;
	selp.f32 	%f1258, 0f3F800000, %f1257, %p111;
	mov.b32 	%r447, %f1258;
	and.b32  	%r449, %r674, -2147483648;
	or.b32  	%r450, %r449, %r447;
	mov.b32 	%f2253, %r450;
$L__BB0_103:
	.loc	1 159 0
	mov.b32 	%r235, %f2321;
	// begin inline asm
	div.full.f32 %r677, %r232, %r125;
	// end inline asm
	mov.b32 	%f102, %r676;
	.loc	1 159 56
	abs.ftz.f32 	%f267, %f101;
	setp.ltu.f32 	%p112, %f267, 0f3F19999A;
	@%p112 bra 	$L__BB0_105;
	bra.uni 	$L__BB0_104;
$L__BB0_105:
	mul.f32 	%f1277, %f101, %f101;
	mov.f32 	%f1278, 0fBD563CAE;
	mov.f32 	%f1279, 0f3C80F082;
	fma.rn.ftz.f32 	%f1280, %f1279, %f1277, %f1278;
	mov.f32 	%f1281, 0f3E085941;
	fma.rn.ftz.f32 	%f1282, %f1280, %f1277, %f1281;
	mov.f32 	%f1283, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1284, %f1282, %f1277, %f1283;
	mov.f32 	%f1285, 0f00000000;
	fma.rn.ftz.f32 	%f1286, %f1284, %f1277, %f1285;
	fma.rn.ftz.f32 	%f2254, %f1286, %f101, %f101;
	bra.uni 	$L__BB0_106;
$L__BB0_104:
	mul.f32 	%f1271, %f267, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1272, %f1271;
	add.f32 	%f1270, %f1272, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1269,%f1270;
	// end inline asm
	mov.f32 	%f1273, 0f3F800000;
	mov.f32 	%f1274, 0fC0000000;
	fma.rn.ftz.f32 	%f1275, %f1269, %f1274, %f1273;
	setp.ge.f32 	%p113, %f267, 0f41102CB4;
	selp.f32 	%f1276, 0f3F800000, %f1275, %p113;
	mov.b32 	%r451, %f1276;
	and.b32  	%r453, %r675, -2147483648;
	or.b32  	%r454, %r453, %r451;
	mov.b32 	%f2254, %r454;
$L__BB0_106:
	.loc	1 159 0
	mov.b32 	%r238, %f2322;
	// begin inline asm
	div.full.f32 %r678, %r235, %r125;
	// end inline asm
	mov.b32 	%f103, %r677;
	.loc	1 159 56
	abs.ftz.f32 	%f271, %f102;
	setp.ltu.f32 	%p114, %f271, 0f3F19999A;
	@%p114 bra 	$L__BB0_108;
	bra.uni 	$L__BB0_107;
$L__BB0_108:
	mul.f32 	%f1295, %f102, %f102;
	mov.f32 	%f1296, 0fBD563CAE;
	mov.f32 	%f1297, 0f3C80F082;
	fma.rn.ftz.f32 	%f1298, %f1297, %f1295, %f1296;
	mov.f32 	%f1299, 0f3E085941;
	fma.rn.ftz.f32 	%f1300, %f1298, %f1295, %f1299;
	mov.f32 	%f1301, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1302, %f1300, %f1295, %f1301;
	mov.f32 	%f1303, 0f00000000;
	fma.rn.ftz.f32 	%f1304, %f1302, %f1295, %f1303;
	fma.rn.ftz.f32 	%f2255, %f1304, %f102, %f102;
	bra.uni 	$L__BB0_109;
$L__BB0_107:
	mul.f32 	%f1289, %f271, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1290, %f1289;
	add.f32 	%f1288, %f1290, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1287,%f1288;
	// end inline asm
	mov.f32 	%f1291, 0f3F800000;
	mov.f32 	%f1292, 0fC0000000;
	fma.rn.ftz.f32 	%f1293, %f1287, %f1292, %f1291;
	setp.ge.f32 	%p115, %f271, 0f41102CB4;
	selp.f32 	%f1294, 0f3F800000, %f1293, %p115;
	mov.b32 	%r455, %f1294;
	and.b32  	%r457, %r676, -2147483648;
	or.b32  	%r458, %r457, %r455;
	mov.b32 	%f2255, %r458;
$L__BB0_109:
	.loc	1 159 0
	mov.b32 	%r241, %f2323;
	// begin inline asm
	div.full.f32 %r679, %r238, %r125;
	// end inline asm
	mov.b32 	%f104, %r678;
	.loc	1 159 56
	abs.ftz.f32 	%f275, %f103;
	setp.ltu.f32 	%p116, %f275, 0f3F19999A;
	@%p116 bra 	$L__BB0_111;
	bra.uni 	$L__BB0_110;
$L__BB0_111:
	mul.f32 	%f1313, %f103, %f103;
	mov.f32 	%f1314, 0fBD563CAE;
	mov.f32 	%f1315, 0f3C80F082;
	fma.rn.ftz.f32 	%f1316, %f1315, %f1313, %f1314;
	mov.f32 	%f1317, 0f3E085941;
	fma.rn.ftz.f32 	%f1318, %f1316, %f1313, %f1317;
	mov.f32 	%f1319, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1320, %f1318, %f1313, %f1319;
	mov.f32 	%f1321, 0f00000000;
	fma.rn.ftz.f32 	%f1322, %f1320, %f1313, %f1321;
	fma.rn.ftz.f32 	%f2256, %f1322, %f103, %f103;
	bra.uni 	$L__BB0_112;
$L__BB0_110:
	mul.f32 	%f1307, %f275, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1308, %f1307;
	add.f32 	%f1306, %f1308, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1305,%f1306;
	// end inline asm
	mov.f32 	%f1309, 0f3F800000;
	mov.f32 	%f1310, 0fC0000000;
	fma.rn.ftz.f32 	%f1311, %f1305, %f1310, %f1309;
	setp.ge.f32 	%p117, %f275, 0f41102CB4;
	selp.f32 	%f1312, 0f3F800000, %f1311, %p117;
	mov.b32 	%r459, %f1312;
	and.b32  	%r461, %r677, -2147483648;
	or.b32  	%r462, %r461, %r459;
	mov.b32 	%f2256, %r462;
$L__BB0_112:
	.loc	1 159 0
	mov.b32 	%r244, %f2324;
	// begin inline asm
	div.full.f32 %r680, %r241, %r125;
	// end inline asm
	mov.b32 	%f105, %r679;
	.loc	1 159 56
	abs.ftz.f32 	%f279, %f104;
	setp.ltu.f32 	%p118, %f279, 0f3F19999A;
	@%p118 bra 	$L__BB0_114;
	bra.uni 	$L__BB0_113;
$L__BB0_114:
	mul.f32 	%f1331, %f104, %f104;
	mov.f32 	%f1332, 0fBD563CAE;
	mov.f32 	%f1333, 0f3C80F082;
	fma.rn.ftz.f32 	%f1334, %f1333, %f1331, %f1332;
	mov.f32 	%f1335, 0f3E085941;
	fma.rn.ftz.f32 	%f1336, %f1334, %f1331, %f1335;
	mov.f32 	%f1337, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1338, %f1336, %f1331, %f1337;
	mov.f32 	%f1339, 0f00000000;
	fma.rn.ftz.f32 	%f1340, %f1338, %f1331, %f1339;
	fma.rn.ftz.f32 	%f2257, %f1340, %f104, %f104;
	bra.uni 	$L__BB0_115;
$L__BB0_113:
	mul.f32 	%f1325, %f279, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1326, %f1325;
	add.f32 	%f1324, %f1326, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1323,%f1324;
	// end inline asm
	mov.f32 	%f1327, 0f3F800000;
	mov.f32 	%f1328, 0fC0000000;
	fma.rn.ftz.f32 	%f1329, %f1323, %f1328, %f1327;
	setp.ge.f32 	%p119, %f279, 0f41102CB4;
	selp.f32 	%f1330, 0f3F800000, %f1329, %p119;
	mov.b32 	%r463, %f1330;
	and.b32  	%r465, %r678, -2147483648;
	or.b32  	%r466, %r465, %r463;
	mov.b32 	%f2257, %r466;
$L__BB0_115:
	.loc	1 159 0
	mov.b32 	%r247, %f2325;
	// begin inline asm
	div.full.f32 %r681, %r244, %r125;
	// end inline asm
	mov.b32 	%f106, %r680;
	.loc	1 159 56
	abs.ftz.f32 	%f283, %f105;
	setp.ltu.f32 	%p120, %f283, 0f3F19999A;
	@%p120 bra 	$L__BB0_117;
	bra.uni 	$L__BB0_116;
$L__BB0_117:
	mul.f32 	%f1349, %f105, %f105;
	mov.f32 	%f1350, 0fBD563CAE;
	mov.f32 	%f1351, 0f3C80F082;
	fma.rn.ftz.f32 	%f1352, %f1351, %f1349, %f1350;
	mov.f32 	%f1353, 0f3E085941;
	fma.rn.ftz.f32 	%f1354, %f1352, %f1349, %f1353;
	mov.f32 	%f1355, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1356, %f1354, %f1349, %f1355;
	mov.f32 	%f1357, 0f00000000;
	fma.rn.ftz.f32 	%f1358, %f1356, %f1349, %f1357;
	fma.rn.ftz.f32 	%f2258, %f1358, %f105, %f105;
	bra.uni 	$L__BB0_118;
$L__BB0_116:
	mul.f32 	%f1343, %f283, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1344, %f1343;
	add.f32 	%f1342, %f1344, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1341,%f1342;
	// end inline asm
	mov.f32 	%f1345, 0f3F800000;
	mov.f32 	%f1346, 0fC0000000;
	fma.rn.ftz.f32 	%f1347, %f1341, %f1346, %f1345;
	setp.ge.f32 	%p121, %f283, 0f41102CB4;
	selp.f32 	%f1348, 0f3F800000, %f1347, %p121;
	mov.b32 	%r467, %f1348;
	and.b32  	%r469, %r679, -2147483648;
	or.b32  	%r470, %r469, %r467;
	mov.b32 	%f2258, %r470;
$L__BB0_118:
	.loc	1 159 0
	mov.b32 	%r250, %f2326;
	// begin inline asm
	div.full.f32 %r682, %r247, %r125;
	// end inline asm
	mov.b32 	%f107, %r681;
	.loc	1 159 56
	abs.ftz.f32 	%f287, %f106;
	setp.ltu.f32 	%p122, %f287, 0f3F19999A;
	@%p122 bra 	$L__BB0_120;
	bra.uni 	$L__BB0_119;
$L__BB0_120:
	mul.f32 	%f1367, %f106, %f106;
	mov.f32 	%f1368, 0fBD563CAE;
	mov.f32 	%f1369, 0f3C80F082;
	fma.rn.ftz.f32 	%f1370, %f1369, %f1367, %f1368;
	mov.f32 	%f1371, 0f3E085941;
	fma.rn.ftz.f32 	%f1372, %f1370, %f1367, %f1371;
	mov.f32 	%f1373, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1374, %f1372, %f1367, %f1373;
	mov.f32 	%f1375, 0f00000000;
	fma.rn.ftz.f32 	%f1376, %f1374, %f1367, %f1375;
	fma.rn.ftz.f32 	%f2259, %f1376, %f106, %f106;
	bra.uni 	$L__BB0_121;
$L__BB0_119:
	mul.f32 	%f1361, %f287, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1362, %f1361;
	add.f32 	%f1360, %f1362, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1359,%f1360;
	// end inline asm
	mov.f32 	%f1363, 0f3F800000;
	mov.f32 	%f1364, 0fC0000000;
	fma.rn.ftz.f32 	%f1365, %f1359, %f1364, %f1363;
	setp.ge.f32 	%p123, %f287, 0f41102CB4;
	selp.f32 	%f1366, 0f3F800000, %f1365, %p123;
	mov.b32 	%r471, %f1366;
	and.b32  	%r473, %r680, -2147483648;
	or.b32  	%r474, %r473, %r471;
	mov.b32 	%f2259, %r474;
$L__BB0_121:
	.loc	1 159 0
	mov.b32 	%r253, %f2327;
	// begin inline asm
	div.full.f32 %r683, %r250, %r125;
	// end inline asm
	mov.b32 	%f108, %r682;
	.loc	1 159 56
	abs.ftz.f32 	%f291, %f107;
	setp.ltu.f32 	%p124, %f291, 0f3F19999A;
	@%p124 bra 	$L__BB0_123;
	bra.uni 	$L__BB0_122;
$L__BB0_123:
	mul.f32 	%f1385, %f107, %f107;
	mov.f32 	%f1386, 0fBD563CAE;
	mov.f32 	%f1387, 0f3C80F082;
	fma.rn.ftz.f32 	%f1388, %f1387, %f1385, %f1386;
	mov.f32 	%f1389, 0f3E085941;
	fma.rn.ftz.f32 	%f1390, %f1388, %f1385, %f1389;
	mov.f32 	%f1391, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1392, %f1390, %f1385, %f1391;
	mov.f32 	%f1393, 0f00000000;
	fma.rn.ftz.f32 	%f1394, %f1392, %f1385, %f1393;
	fma.rn.ftz.f32 	%f2260, %f1394, %f107, %f107;
	bra.uni 	$L__BB0_124;
$L__BB0_122:
	mul.f32 	%f1379, %f291, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1380, %f1379;
	add.f32 	%f1378, %f1380, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1377,%f1378;
	// end inline asm
	mov.f32 	%f1381, 0f3F800000;
	mov.f32 	%f1382, 0fC0000000;
	fma.rn.ftz.f32 	%f1383, %f1377, %f1382, %f1381;
	setp.ge.f32 	%p125, %f291, 0f41102CB4;
	selp.f32 	%f1384, 0f3F800000, %f1383, %p125;
	mov.b32 	%r475, %f1384;
	and.b32  	%r477, %r681, -2147483648;
	or.b32  	%r478, %r477, %r475;
	mov.b32 	%f2260, %r478;
$L__BB0_124:
	.loc	1 159 0
	mov.b32 	%r256, %f2328;
	// begin inline asm
	div.full.f32 %r684, %r253, %r125;
	// end inline asm
	mov.b32 	%f109, %r683;
	.loc	1 159 56
	abs.ftz.f32 	%f295, %f108;
	setp.ltu.f32 	%p126, %f295, 0f3F19999A;
	@%p126 bra 	$L__BB0_126;
	bra.uni 	$L__BB0_125;
$L__BB0_126:
	mul.f32 	%f1403, %f108, %f108;
	mov.f32 	%f1404, 0fBD563CAE;
	mov.f32 	%f1405, 0f3C80F082;
	fma.rn.ftz.f32 	%f1406, %f1405, %f1403, %f1404;
	mov.f32 	%f1407, 0f3E085941;
	fma.rn.ftz.f32 	%f1408, %f1406, %f1403, %f1407;
	mov.f32 	%f1409, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1410, %f1408, %f1403, %f1409;
	mov.f32 	%f1411, 0f00000000;
	fma.rn.ftz.f32 	%f1412, %f1410, %f1403, %f1411;
	fma.rn.ftz.f32 	%f2261, %f1412, %f108, %f108;
	bra.uni 	$L__BB0_127;
$L__BB0_125:
	mul.f32 	%f1397, %f295, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1398, %f1397;
	add.f32 	%f1396, %f1398, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1395,%f1396;
	// end inline asm
	mov.f32 	%f1399, 0f3F800000;
	mov.f32 	%f1400, 0fC0000000;
	fma.rn.ftz.f32 	%f1401, %f1395, %f1400, %f1399;
	setp.ge.f32 	%p127, %f295, 0f41102CB4;
	selp.f32 	%f1402, 0f3F800000, %f1401, %p127;
	mov.b32 	%r479, %f1402;
	and.b32  	%r481, %r682, -2147483648;
	or.b32  	%r482, %r481, %r479;
	mov.b32 	%f2261, %r482;
$L__BB0_127:
	.loc	1 159 0
	mov.b32 	%r259, %f2329;
	// begin inline asm
	div.full.f32 %r685, %r256, %r125;
	// end inline asm
	mov.b32 	%f110, %r684;
	.loc	1 159 56
	abs.ftz.f32 	%f299, %f109;
	setp.ltu.f32 	%p128, %f299, 0f3F19999A;
	@%p128 bra 	$L__BB0_129;
	bra.uni 	$L__BB0_128;
$L__BB0_129:
	mul.f32 	%f1421, %f109, %f109;
	mov.f32 	%f1422, 0fBD563CAE;
	mov.f32 	%f1423, 0f3C80F082;
	fma.rn.ftz.f32 	%f1424, %f1423, %f1421, %f1422;
	mov.f32 	%f1425, 0f3E085941;
	fma.rn.ftz.f32 	%f1426, %f1424, %f1421, %f1425;
	mov.f32 	%f1427, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1428, %f1426, %f1421, %f1427;
	mov.f32 	%f1429, 0f00000000;
	fma.rn.ftz.f32 	%f1430, %f1428, %f1421, %f1429;
	fma.rn.ftz.f32 	%f2262, %f1430, %f109, %f109;
	bra.uni 	$L__BB0_130;
$L__BB0_128:
	mul.f32 	%f1415, %f299, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1416, %f1415;
	add.f32 	%f1414, %f1416, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1413,%f1414;
	// end inline asm
	mov.f32 	%f1417, 0f3F800000;
	mov.f32 	%f1418, 0fC0000000;
	fma.rn.ftz.f32 	%f1419, %f1413, %f1418, %f1417;
	setp.ge.f32 	%p129, %f299, 0f41102CB4;
	selp.f32 	%f1420, 0f3F800000, %f1419, %p129;
	mov.b32 	%r483, %f1420;
	and.b32  	%r485, %r683, -2147483648;
	or.b32  	%r486, %r485, %r483;
	mov.b32 	%f2262, %r486;
$L__BB0_130:
	.loc	1 159 0
	mov.b32 	%r262, %f2330;
	// begin inline asm
	div.full.f32 %r686, %r259, %r125;
	// end inline asm
	mov.b32 	%f111, %r685;
	.loc	1 159 56
	abs.ftz.f32 	%f303, %f110;
	setp.ltu.f32 	%p130, %f303, 0f3F19999A;
	@%p130 bra 	$L__BB0_132;
	bra.uni 	$L__BB0_131;
$L__BB0_132:
	mul.f32 	%f1439, %f110, %f110;
	mov.f32 	%f1440, 0fBD563CAE;
	mov.f32 	%f1441, 0f3C80F082;
	fma.rn.ftz.f32 	%f1442, %f1441, %f1439, %f1440;
	mov.f32 	%f1443, 0f3E085941;
	fma.rn.ftz.f32 	%f1444, %f1442, %f1439, %f1443;
	mov.f32 	%f1445, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1446, %f1444, %f1439, %f1445;
	mov.f32 	%f1447, 0f00000000;
	fma.rn.ftz.f32 	%f1448, %f1446, %f1439, %f1447;
	fma.rn.ftz.f32 	%f2263, %f1448, %f110, %f110;
	bra.uni 	$L__BB0_133;
$L__BB0_131:
	mul.f32 	%f1433, %f303, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1434, %f1433;
	add.f32 	%f1432, %f1434, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1431,%f1432;
	// end inline asm
	mov.f32 	%f1435, 0f3F800000;
	mov.f32 	%f1436, 0fC0000000;
	fma.rn.ftz.f32 	%f1437, %f1431, %f1436, %f1435;
	setp.ge.f32 	%p131, %f303, 0f41102CB4;
	selp.f32 	%f1438, 0f3F800000, %f1437, %p131;
	mov.b32 	%r487, %f1438;
	and.b32  	%r489, %r684, -2147483648;
	or.b32  	%r490, %r489, %r487;
	mov.b32 	%f2263, %r490;
$L__BB0_133:
	.loc	1 159 0
	mov.b32 	%r265, %f2331;
	// begin inline asm
	div.full.f32 %r687, %r262, %r125;
	// end inline asm
	mov.b32 	%f112, %r686;
	.loc	1 159 56
	abs.ftz.f32 	%f307, %f111;
	setp.ltu.f32 	%p132, %f307, 0f3F19999A;
	@%p132 bra 	$L__BB0_135;
	bra.uni 	$L__BB0_134;
$L__BB0_135:
	mul.f32 	%f1457, %f111, %f111;
	mov.f32 	%f1458, 0fBD563CAE;
	mov.f32 	%f1459, 0f3C80F082;
	fma.rn.ftz.f32 	%f1460, %f1459, %f1457, %f1458;
	mov.f32 	%f1461, 0f3E085941;
	fma.rn.ftz.f32 	%f1462, %f1460, %f1457, %f1461;
	mov.f32 	%f1463, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1464, %f1462, %f1457, %f1463;
	mov.f32 	%f1465, 0f00000000;
	fma.rn.ftz.f32 	%f1466, %f1464, %f1457, %f1465;
	fma.rn.ftz.f32 	%f2264, %f1466, %f111, %f111;
	bra.uni 	$L__BB0_136;
$L__BB0_134:
	mul.f32 	%f1451, %f307, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1452, %f1451;
	add.f32 	%f1450, %f1452, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1449,%f1450;
	// end inline asm
	mov.f32 	%f1453, 0f3F800000;
	mov.f32 	%f1454, 0fC0000000;
	fma.rn.ftz.f32 	%f1455, %f1449, %f1454, %f1453;
	setp.ge.f32 	%p133, %f307, 0f41102CB4;
	selp.f32 	%f1456, 0f3F800000, %f1455, %p133;
	mov.b32 	%r491, %f1456;
	and.b32  	%r493, %r685, -2147483648;
	or.b32  	%r494, %r493, %r491;
	mov.b32 	%f2264, %r494;
$L__BB0_136:
	.loc	1 159 0
	mov.b32 	%r268, %f2332;
	// begin inline asm
	div.full.f32 %r688, %r265, %r125;
	// end inline asm
	mov.b32 	%f113, %r687;
	.loc	1 159 56
	abs.ftz.f32 	%f311, %f112;
	setp.ltu.f32 	%p134, %f311, 0f3F19999A;
	@%p134 bra 	$L__BB0_138;
	bra.uni 	$L__BB0_137;
$L__BB0_138:
	mul.f32 	%f1475, %f112, %f112;
	mov.f32 	%f1476, 0fBD563CAE;
	mov.f32 	%f1477, 0f3C80F082;
	fma.rn.ftz.f32 	%f1478, %f1477, %f1475, %f1476;
	mov.f32 	%f1479, 0f3E085941;
	fma.rn.ftz.f32 	%f1480, %f1478, %f1475, %f1479;
	mov.f32 	%f1481, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1482, %f1480, %f1475, %f1481;
	mov.f32 	%f1483, 0f00000000;
	fma.rn.ftz.f32 	%f1484, %f1482, %f1475, %f1483;
	fma.rn.ftz.f32 	%f2265, %f1484, %f112, %f112;
	bra.uni 	$L__BB0_139;
$L__BB0_137:
	mul.f32 	%f1469, %f311, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1470, %f1469;
	add.f32 	%f1468, %f1470, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1467,%f1468;
	// end inline asm
	mov.f32 	%f1471, 0f3F800000;
	mov.f32 	%f1472, 0fC0000000;
	fma.rn.ftz.f32 	%f1473, %f1467, %f1472, %f1471;
	setp.ge.f32 	%p135, %f311, 0f41102CB4;
	selp.f32 	%f1474, 0f3F800000, %f1473, %p135;
	mov.b32 	%r495, %f1474;
	and.b32  	%r497, %r686, -2147483648;
	or.b32  	%r498, %r497, %r495;
	mov.b32 	%f2265, %r498;
$L__BB0_139:
	.loc	1 159 0
	mov.b32 	%r271, %f2333;
	// begin inline asm
	div.full.f32 %r689, %r268, %r125;
	// end inline asm
	mov.b32 	%f114, %r688;
	.loc	1 159 56
	abs.ftz.f32 	%f315, %f113;
	setp.ltu.f32 	%p136, %f315, 0f3F19999A;
	@%p136 bra 	$L__BB0_141;
	bra.uni 	$L__BB0_140;
$L__BB0_141:
	mul.f32 	%f1493, %f113, %f113;
	mov.f32 	%f1494, 0fBD563CAE;
	mov.f32 	%f1495, 0f3C80F082;
	fma.rn.ftz.f32 	%f1496, %f1495, %f1493, %f1494;
	mov.f32 	%f1497, 0f3E085941;
	fma.rn.ftz.f32 	%f1498, %f1496, %f1493, %f1497;
	mov.f32 	%f1499, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1500, %f1498, %f1493, %f1499;
	mov.f32 	%f1501, 0f00000000;
	fma.rn.ftz.f32 	%f1502, %f1500, %f1493, %f1501;
	fma.rn.ftz.f32 	%f2266, %f1502, %f113, %f113;
	bra.uni 	$L__BB0_142;
$L__BB0_140:
	mul.f32 	%f1487, %f315, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1488, %f1487;
	add.f32 	%f1486, %f1488, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1485,%f1486;
	// end inline asm
	mov.f32 	%f1489, 0f3F800000;
	mov.f32 	%f1490, 0fC0000000;
	fma.rn.ftz.f32 	%f1491, %f1485, %f1490, %f1489;
	setp.ge.f32 	%p137, %f315, 0f41102CB4;
	selp.f32 	%f1492, 0f3F800000, %f1491, %p137;
	mov.b32 	%r499, %f1492;
	and.b32  	%r501, %r687, -2147483648;
	or.b32  	%r502, %r501, %r499;
	mov.b32 	%f2266, %r502;
$L__BB0_142:
	.loc	1 159 0
	mov.b32 	%r274, %f2334;
	// begin inline asm
	div.full.f32 %r690, %r271, %r125;
	// end inline asm
	mov.b32 	%f115, %r689;
	.loc	1 159 56
	abs.ftz.f32 	%f319, %f114;
	setp.ltu.f32 	%p138, %f319, 0f3F19999A;
	@%p138 bra 	$L__BB0_144;
	bra.uni 	$L__BB0_143;
$L__BB0_144:
	mul.f32 	%f1511, %f114, %f114;
	mov.f32 	%f1512, 0fBD563CAE;
	mov.f32 	%f1513, 0f3C80F082;
	fma.rn.ftz.f32 	%f1514, %f1513, %f1511, %f1512;
	mov.f32 	%f1515, 0f3E085941;
	fma.rn.ftz.f32 	%f1516, %f1514, %f1511, %f1515;
	mov.f32 	%f1517, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1518, %f1516, %f1511, %f1517;
	mov.f32 	%f1519, 0f00000000;
	fma.rn.ftz.f32 	%f1520, %f1518, %f1511, %f1519;
	fma.rn.ftz.f32 	%f2267, %f1520, %f114, %f114;
	bra.uni 	$L__BB0_145;
$L__BB0_143:
	mul.f32 	%f1505, %f319, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1506, %f1505;
	add.f32 	%f1504, %f1506, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1503,%f1504;
	// end inline asm
	mov.f32 	%f1507, 0f3F800000;
	mov.f32 	%f1508, 0fC0000000;
	fma.rn.ftz.f32 	%f1509, %f1503, %f1508, %f1507;
	setp.ge.f32 	%p139, %f319, 0f41102CB4;
	selp.f32 	%f1510, 0f3F800000, %f1509, %p139;
	mov.b32 	%r503, %f1510;
	and.b32  	%r505, %r688, -2147483648;
	or.b32  	%r506, %r505, %r503;
	mov.b32 	%f2267, %r506;
$L__BB0_145:
	.loc	1 159 0
	mov.b32 	%r277, %f2335;
	// begin inline asm
	div.full.f32 %r691, %r274, %r125;
	// end inline asm
	mov.b32 	%f116, %r690;
	.loc	1 159 56
	abs.ftz.f32 	%f323, %f115;
	setp.ltu.f32 	%p140, %f323, 0f3F19999A;
	@%p140 bra 	$L__BB0_147;
	bra.uni 	$L__BB0_146;
$L__BB0_147:
	mul.f32 	%f1529, %f115, %f115;
	mov.f32 	%f1530, 0fBD563CAE;
	mov.f32 	%f1531, 0f3C80F082;
	fma.rn.ftz.f32 	%f1532, %f1531, %f1529, %f1530;
	mov.f32 	%f1533, 0f3E085941;
	fma.rn.ftz.f32 	%f1534, %f1532, %f1529, %f1533;
	mov.f32 	%f1535, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1536, %f1534, %f1529, %f1535;
	mov.f32 	%f1537, 0f00000000;
	fma.rn.ftz.f32 	%f1538, %f1536, %f1529, %f1537;
	fma.rn.ftz.f32 	%f2268, %f1538, %f115, %f115;
	bra.uni 	$L__BB0_148;
$L__BB0_146:
	mul.f32 	%f1523, %f323, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1524, %f1523;
	add.f32 	%f1522, %f1524, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1521,%f1522;
	// end inline asm
	mov.f32 	%f1525, 0f3F800000;
	mov.f32 	%f1526, 0fC0000000;
	fma.rn.ftz.f32 	%f1527, %f1521, %f1526, %f1525;
	setp.ge.f32 	%p141, %f323, 0f41102CB4;
	selp.f32 	%f1528, 0f3F800000, %f1527, %p141;
	mov.b32 	%r507, %f1528;
	and.b32  	%r509, %r689, -2147483648;
	or.b32  	%r510, %r509, %r507;
	mov.b32 	%f2268, %r510;
$L__BB0_148:
	.loc	1 159 0
	mov.b32 	%r280, %f2336;
	// begin inline asm
	div.full.f32 %r692, %r277, %r125;
	// end inline asm
	mov.b32 	%f117, %r691;
	.loc	1 159 56
	abs.ftz.f32 	%f327, %f116;
	setp.ltu.f32 	%p142, %f327, 0f3F19999A;
	@%p142 bra 	$L__BB0_150;
	bra.uni 	$L__BB0_149;
$L__BB0_150:
	mul.f32 	%f1547, %f116, %f116;
	mov.f32 	%f1548, 0fBD563CAE;
	mov.f32 	%f1549, 0f3C80F082;
	fma.rn.ftz.f32 	%f1550, %f1549, %f1547, %f1548;
	mov.f32 	%f1551, 0f3E085941;
	fma.rn.ftz.f32 	%f1552, %f1550, %f1547, %f1551;
	mov.f32 	%f1553, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1554, %f1552, %f1547, %f1553;
	mov.f32 	%f1555, 0f00000000;
	fma.rn.ftz.f32 	%f1556, %f1554, %f1547, %f1555;
	fma.rn.ftz.f32 	%f2269, %f1556, %f116, %f116;
	bra.uni 	$L__BB0_151;
$L__BB0_149:
	mul.f32 	%f1541, %f327, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1542, %f1541;
	add.f32 	%f1540, %f1542, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1539,%f1540;
	// end inline asm
	mov.f32 	%f1543, 0f3F800000;
	mov.f32 	%f1544, 0fC0000000;
	fma.rn.ftz.f32 	%f1545, %f1539, %f1544, %f1543;
	setp.ge.f32 	%p143, %f327, 0f41102CB4;
	selp.f32 	%f1546, 0f3F800000, %f1545, %p143;
	mov.b32 	%r511, %f1546;
	and.b32  	%r513, %r690, -2147483648;
	or.b32  	%r514, %r513, %r511;
	mov.b32 	%f2269, %r514;
$L__BB0_151:
	.loc	1 159 0
	mov.b32 	%r283, %f2337;
	// begin inline asm
	div.full.f32 %r693, %r280, %r125;
	// end inline asm
	mov.b32 	%f118, %r692;
	.loc	1 159 56
	abs.ftz.f32 	%f331, %f117;
	setp.ltu.f32 	%p144, %f331, 0f3F19999A;
	@%p144 bra 	$L__BB0_153;
	bra.uni 	$L__BB0_152;
$L__BB0_153:
	mul.f32 	%f1565, %f117, %f117;
	mov.f32 	%f1566, 0fBD563CAE;
	mov.f32 	%f1567, 0f3C80F082;
	fma.rn.ftz.f32 	%f1568, %f1567, %f1565, %f1566;
	mov.f32 	%f1569, 0f3E085941;
	fma.rn.ftz.f32 	%f1570, %f1568, %f1565, %f1569;
	mov.f32 	%f1571, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1572, %f1570, %f1565, %f1571;
	mov.f32 	%f1573, 0f00000000;
	fma.rn.ftz.f32 	%f1574, %f1572, %f1565, %f1573;
	fma.rn.ftz.f32 	%f2270, %f1574, %f117, %f117;
	bra.uni 	$L__BB0_154;
$L__BB0_152:
	mul.f32 	%f1559, %f331, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1560, %f1559;
	add.f32 	%f1558, %f1560, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1557,%f1558;
	// end inline asm
	mov.f32 	%f1561, 0f3F800000;
	mov.f32 	%f1562, 0fC0000000;
	fma.rn.ftz.f32 	%f1563, %f1557, %f1562, %f1561;
	setp.ge.f32 	%p145, %f331, 0f41102CB4;
	selp.f32 	%f1564, 0f3F800000, %f1563, %p145;
	mov.b32 	%r515, %f1564;
	and.b32  	%r517, %r691, -2147483648;
	or.b32  	%r518, %r517, %r515;
	mov.b32 	%f2270, %r518;
$L__BB0_154:
	.loc	1 159 0
	mov.b32 	%r286, %f2338;
	// begin inline asm
	div.full.f32 %r694, %r283, %r125;
	// end inline asm
	mov.b32 	%f119, %r693;
	.loc	1 159 56
	abs.ftz.f32 	%f335, %f118;
	setp.ltu.f32 	%p146, %f335, 0f3F19999A;
	@%p146 bra 	$L__BB0_156;
	bra.uni 	$L__BB0_155;
$L__BB0_156:
	mul.f32 	%f1583, %f118, %f118;
	mov.f32 	%f1584, 0fBD563CAE;
	mov.f32 	%f1585, 0f3C80F082;
	fma.rn.ftz.f32 	%f1586, %f1585, %f1583, %f1584;
	mov.f32 	%f1587, 0f3E085941;
	fma.rn.ftz.f32 	%f1588, %f1586, %f1583, %f1587;
	mov.f32 	%f1589, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1590, %f1588, %f1583, %f1589;
	mov.f32 	%f1591, 0f00000000;
	fma.rn.ftz.f32 	%f1592, %f1590, %f1583, %f1591;
	fma.rn.ftz.f32 	%f2271, %f1592, %f118, %f118;
	bra.uni 	$L__BB0_157;
$L__BB0_155:
	mul.f32 	%f1577, %f335, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1578, %f1577;
	add.f32 	%f1576, %f1578, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1575,%f1576;
	// end inline asm
	mov.f32 	%f1579, 0f3F800000;
	mov.f32 	%f1580, 0fC0000000;
	fma.rn.ftz.f32 	%f1581, %f1575, %f1580, %f1579;
	setp.ge.f32 	%p147, %f335, 0f41102CB4;
	selp.f32 	%f1582, 0f3F800000, %f1581, %p147;
	mov.b32 	%r519, %f1582;
	and.b32  	%r521, %r692, -2147483648;
	or.b32  	%r522, %r521, %r519;
	mov.b32 	%f2271, %r522;
$L__BB0_157:
	.loc	1 159 0
	mov.b32 	%r289, %f2339;
	// begin inline asm
	div.full.f32 %r695, %r286, %r125;
	// end inline asm
	mov.b32 	%f120, %r694;
	.loc	1 159 56
	abs.ftz.f32 	%f339, %f119;
	setp.ltu.f32 	%p148, %f339, 0f3F19999A;
	@%p148 bra 	$L__BB0_159;
	bra.uni 	$L__BB0_158;
$L__BB0_159:
	mul.f32 	%f1601, %f119, %f119;
	mov.f32 	%f1602, 0fBD563CAE;
	mov.f32 	%f1603, 0f3C80F082;
	fma.rn.ftz.f32 	%f1604, %f1603, %f1601, %f1602;
	mov.f32 	%f1605, 0f3E085941;
	fma.rn.ftz.f32 	%f1606, %f1604, %f1601, %f1605;
	mov.f32 	%f1607, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1608, %f1606, %f1601, %f1607;
	mov.f32 	%f1609, 0f00000000;
	fma.rn.ftz.f32 	%f1610, %f1608, %f1601, %f1609;
	fma.rn.ftz.f32 	%f2272, %f1610, %f119, %f119;
	bra.uni 	$L__BB0_160;
$L__BB0_158:
	mul.f32 	%f1595, %f339, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1596, %f1595;
	add.f32 	%f1594, %f1596, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1593,%f1594;
	// end inline asm
	mov.f32 	%f1597, 0f3F800000;
	mov.f32 	%f1598, 0fC0000000;
	fma.rn.ftz.f32 	%f1599, %f1593, %f1598, %f1597;
	setp.ge.f32 	%p149, %f339, 0f41102CB4;
	selp.f32 	%f1600, 0f3F800000, %f1599, %p149;
	mov.b32 	%r523, %f1600;
	and.b32  	%r525, %r693, -2147483648;
	or.b32  	%r526, %r525, %r523;
	mov.b32 	%f2272, %r526;
$L__BB0_160:
	.loc	1 159 0
	mov.b32 	%r292, %f2340;
	// begin inline asm
	div.full.f32 %r696, %r289, %r125;
	// end inline asm
	mov.b32 	%f121, %r695;
	.loc	1 159 56
	abs.ftz.f32 	%f343, %f120;
	setp.ltu.f32 	%p150, %f343, 0f3F19999A;
	@%p150 bra 	$L__BB0_162;
	bra.uni 	$L__BB0_161;
$L__BB0_162:
	mul.f32 	%f1619, %f120, %f120;
	mov.f32 	%f1620, 0fBD563CAE;
	mov.f32 	%f1621, 0f3C80F082;
	fma.rn.ftz.f32 	%f1622, %f1621, %f1619, %f1620;
	mov.f32 	%f1623, 0f3E085941;
	fma.rn.ftz.f32 	%f1624, %f1622, %f1619, %f1623;
	mov.f32 	%f1625, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1626, %f1624, %f1619, %f1625;
	mov.f32 	%f1627, 0f00000000;
	fma.rn.ftz.f32 	%f1628, %f1626, %f1619, %f1627;
	fma.rn.ftz.f32 	%f2273, %f1628, %f120, %f120;
	bra.uni 	$L__BB0_163;
$L__BB0_161:
	mul.f32 	%f1613, %f343, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1614, %f1613;
	add.f32 	%f1612, %f1614, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1611,%f1612;
	// end inline asm
	mov.f32 	%f1615, 0f3F800000;
	mov.f32 	%f1616, 0fC0000000;
	fma.rn.ftz.f32 	%f1617, %f1611, %f1616, %f1615;
	setp.ge.f32 	%p151, %f343, 0f41102CB4;
	selp.f32 	%f1618, 0f3F800000, %f1617, %p151;
	mov.b32 	%r527, %f1618;
	and.b32  	%r529, %r694, -2147483648;
	or.b32  	%r530, %r529, %r527;
	mov.b32 	%f2273, %r530;
$L__BB0_163:
	.loc	1 159 0
	mov.b32 	%r295, %f2341;
	// begin inline asm
	div.full.f32 %r697, %r292, %r125;
	// end inline asm
	mov.b32 	%f122, %r696;
	.loc	1 159 56
	abs.ftz.f32 	%f347, %f121;
	setp.ltu.f32 	%p152, %f347, 0f3F19999A;
	@%p152 bra 	$L__BB0_165;
	bra.uni 	$L__BB0_164;
$L__BB0_165:
	mul.f32 	%f1637, %f121, %f121;
	mov.f32 	%f1638, 0fBD563CAE;
	mov.f32 	%f1639, 0f3C80F082;
	fma.rn.ftz.f32 	%f1640, %f1639, %f1637, %f1638;
	mov.f32 	%f1641, 0f3E085941;
	fma.rn.ftz.f32 	%f1642, %f1640, %f1637, %f1641;
	mov.f32 	%f1643, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1644, %f1642, %f1637, %f1643;
	mov.f32 	%f1645, 0f00000000;
	fma.rn.ftz.f32 	%f1646, %f1644, %f1637, %f1645;
	fma.rn.ftz.f32 	%f2274, %f1646, %f121, %f121;
	bra.uni 	$L__BB0_166;
$L__BB0_164:
	mul.f32 	%f1631, %f347, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1632, %f1631;
	add.f32 	%f1630, %f1632, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1629,%f1630;
	// end inline asm
	mov.f32 	%f1633, 0f3F800000;
	mov.f32 	%f1634, 0fC0000000;
	fma.rn.ftz.f32 	%f1635, %f1629, %f1634, %f1633;
	setp.ge.f32 	%p153, %f347, 0f41102CB4;
	selp.f32 	%f1636, 0f3F800000, %f1635, %p153;
	mov.b32 	%r531, %f1636;
	and.b32  	%r533, %r695, -2147483648;
	or.b32  	%r534, %r533, %r531;
	mov.b32 	%f2274, %r534;
$L__BB0_166:
	.loc	1 159 0
	mov.b32 	%r298, %f2342;
	// begin inline asm
	div.full.f32 %r698, %r295, %r125;
	// end inline asm
	mov.b32 	%f123, %r697;
	.loc	1 159 56
	abs.ftz.f32 	%f351, %f122;
	setp.ltu.f32 	%p154, %f351, 0f3F19999A;
	@%p154 bra 	$L__BB0_168;
	bra.uni 	$L__BB0_167;
$L__BB0_168:
	mul.f32 	%f1655, %f122, %f122;
	mov.f32 	%f1656, 0fBD563CAE;
	mov.f32 	%f1657, 0f3C80F082;
	fma.rn.ftz.f32 	%f1658, %f1657, %f1655, %f1656;
	mov.f32 	%f1659, 0f3E085941;
	fma.rn.ftz.f32 	%f1660, %f1658, %f1655, %f1659;
	mov.f32 	%f1661, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1662, %f1660, %f1655, %f1661;
	mov.f32 	%f1663, 0f00000000;
	fma.rn.ftz.f32 	%f1664, %f1662, %f1655, %f1663;
	fma.rn.ftz.f32 	%f2275, %f1664, %f122, %f122;
	bra.uni 	$L__BB0_169;
$L__BB0_167:
	mul.f32 	%f1649, %f351, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1650, %f1649;
	add.f32 	%f1648, %f1650, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1647,%f1648;
	// end inline asm
	mov.f32 	%f1651, 0f3F800000;
	mov.f32 	%f1652, 0fC0000000;
	fma.rn.ftz.f32 	%f1653, %f1647, %f1652, %f1651;
	setp.ge.f32 	%p155, %f351, 0f41102CB4;
	selp.f32 	%f1654, 0f3F800000, %f1653, %p155;
	mov.b32 	%r535, %f1654;
	and.b32  	%r537, %r696, -2147483648;
	or.b32  	%r538, %r537, %r535;
	mov.b32 	%f2275, %r538;
$L__BB0_169:
	.loc	1 159 0
	mov.b32 	%r301, %f2343;
	// begin inline asm
	div.full.f32 %r699, %r298, %r125;
	// end inline asm
	mov.b32 	%f124, %r698;
	.loc	1 159 56
	abs.ftz.f32 	%f355, %f123;
	setp.ltu.f32 	%p156, %f355, 0f3F19999A;
	@%p156 bra 	$L__BB0_171;
	bra.uni 	$L__BB0_170;
$L__BB0_171:
	mul.f32 	%f1673, %f123, %f123;
	mov.f32 	%f1674, 0fBD563CAE;
	mov.f32 	%f1675, 0f3C80F082;
	fma.rn.ftz.f32 	%f1676, %f1675, %f1673, %f1674;
	mov.f32 	%f1677, 0f3E085941;
	fma.rn.ftz.f32 	%f1678, %f1676, %f1673, %f1677;
	mov.f32 	%f1679, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1680, %f1678, %f1673, %f1679;
	mov.f32 	%f1681, 0f00000000;
	fma.rn.ftz.f32 	%f1682, %f1680, %f1673, %f1681;
	fma.rn.ftz.f32 	%f2276, %f1682, %f123, %f123;
	bra.uni 	$L__BB0_172;
$L__BB0_170:
	mul.f32 	%f1667, %f355, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1668, %f1667;
	add.f32 	%f1666, %f1668, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1665,%f1666;
	// end inline asm
	mov.f32 	%f1669, 0f3F800000;
	mov.f32 	%f1670, 0fC0000000;
	fma.rn.ftz.f32 	%f1671, %f1665, %f1670, %f1669;
	setp.ge.f32 	%p157, %f355, 0f41102CB4;
	selp.f32 	%f1672, 0f3F800000, %f1671, %p157;
	mov.b32 	%r539, %f1672;
	and.b32  	%r541, %r697, -2147483648;
	or.b32  	%r542, %r541, %r539;
	mov.b32 	%f2276, %r542;
$L__BB0_172:
	.loc	1 159 0
	mov.b32 	%r304, %f2344;
	// begin inline asm
	div.full.f32 %r700, %r301, %r125;
	// end inline asm
	mov.b32 	%f125, %r699;
	.loc	1 159 56
	abs.ftz.f32 	%f359, %f124;
	setp.ltu.f32 	%p158, %f359, 0f3F19999A;
	@%p158 bra 	$L__BB0_174;
	bra.uni 	$L__BB0_173;
$L__BB0_174:
	mul.f32 	%f1691, %f124, %f124;
	mov.f32 	%f1692, 0fBD563CAE;
	mov.f32 	%f1693, 0f3C80F082;
	fma.rn.ftz.f32 	%f1694, %f1693, %f1691, %f1692;
	mov.f32 	%f1695, 0f3E085941;
	fma.rn.ftz.f32 	%f1696, %f1694, %f1691, %f1695;
	mov.f32 	%f1697, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1698, %f1696, %f1691, %f1697;
	mov.f32 	%f1699, 0f00000000;
	fma.rn.ftz.f32 	%f1700, %f1698, %f1691, %f1699;
	fma.rn.ftz.f32 	%f2277, %f1700, %f124, %f124;
	bra.uni 	$L__BB0_175;
$L__BB0_173:
	mul.f32 	%f1685, %f359, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1686, %f1685;
	add.f32 	%f1684, %f1686, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1683,%f1684;
	// end inline asm
	mov.f32 	%f1687, 0f3F800000;
	mov.f32 	%f1688, 0fC0000000;
	fma.rn.ftz.f32 	%f1689, %f1683, %f1688, %f1687;
	setp.ge.f32 	%p159, %f359, 0f41102CB4;
	selp.f32 	%f1690, 0f3F800000, %f1689, %p159;
	mov.b32 	%r543, %f1690;
	and.b32  	%r545, %r698, -2147483648;
	or.b32  	%r546, %r545, %r543;
	mov.b32 	%f2277, %r546;
$L__BB0_175:
	.loc	1 159 0
	mov.b32 	%r307, %f2345;
	// begin inline asm
	div.full.f32 %r701, %r304, %r125;
	// end inline asm
	mov.b32 	%f126, %r700;
	.loc	1 159 56
	abs.ftz.f32 	%f363, %f125;
	setp.ltu.f32 	%p160, %f363, 0f3F19999A;
	@%p160 bra 	$L__BB0_177;
	bra.uni 	$L__BB0_176;
$L__BB0_177:
	mul.f32 	%f1709, %f125, %f125;
	mov.f32 	%f1710, 0fBD563CAE;
	mov.f32 	%f1711, 0f3C80F082;
	fma.rn.ftz.f32 	%f1712, %f1711, %f1709, %f1710;
	mov.f32 	%f1713, 0f3E085941;
	fma.rn.ftz.f32 	%f1714, %f1712, %f1709, %f1713;
	mov.f32 	%f1715, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1716, %f1714, %f1709, %f1715;
	mov.f32 	%f1717, 0f00000000;
	fma.rn.ftz.f32 	%f1718, %f1716, %f1709, %f1717;
	fma.rn.ftz.f32 	%f2278, %f1718, %f125, %f125;
	bra.uni 	$L__BB0_178;
$L__BB0_176:
	mul.f32 	%f1703, %f363, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1704, %f1703;
	add.f32 	%f1702, %f1704, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1701,%f1702;
	// end inline asm
	mov.f32 	%f1705, 0f3F800000;
	mov.f32 	%f1706, 0fC0000000;
	fma.rn.ftz.f32 	%f1707, %f1701, %f1706, %f1705;
	setp.ge.f32 	%p161, %f363, 0f41102CB4;
	selp.f32 	%f1708, 0f3F800000, %f1707, %p161;
	mov.b32 	%r547, %f1708;
	and.b32  	%r549, %r699, -2147483648;
	or.b32  	%r550, %r549, %r547;
	mov.b32 	%f2278, %r550;
$L__BB0_178:
	.loc	1 159 0
	mov.b32 	%r310, %f2346;
	// begin inline asm
	div.full.f32 %r702, %r307, %r125;
	// end inline asm
	mov.b32 	%f127, %r701;
	.loc	1 159 56
	abs.ftz.f32 	%f367, %f126;
	setp.ltu.f32 	%p162, %f367, 0f3F19999A;
	@%p162 bra 	$L__BB0_180;
	bra.uni 	$L__BB0_179;
$L__BB0_180:
	mul.f32 	%f1727, %f126, %f126;
	mov.f32 	%f1728, 0fBD563CAE;
	mov.f32 	%f1729, 0f3C80F082;
	fma.rn.ftz.f32 	%f1730, %f1729, %f1727, %f1728;
	mov.f32 	%f1731, 0f3E085941;
	fma.rn.ftz.f32 	%f1732, %f1730, %f1727, %f1731;
	mov.f32 	%f1733, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1734, %f1732, %f1727, %f1733;
	mov.f32 	%f1735, 0f00000000;
	fma.rn.ftz.f32 	%f1736, %f1734, %f1727, %f1735;
	fma.rn.ftz.f32 	%f2279, %f1736, %f126, %f126;
	bra.uni 	$L__BB0_181;
$L__BB0_179:
	mul.f32 	%f1721, %f367, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1722, %f1721;
	add.f32 	%f1720, %f1722, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1719,%f1720;
	// end inline asm
	mov.f32 	%f1723, 0f3F800000;
	mov.f32 	%f1724, 0fC0000000;
	fma.rn.ftz.f32 	%f1725, %f1719, %f1724, %f1723;
	setp.ge.f32 	%p163, %f367, 0f41102CB4;
	selp.f32 	%f1726, 0f3F800000, %f1725, %p163;
	mov.b32 	%r551, %f1726;
	and.b32  	%r553, %r700, -2147483648;
	or.b32  	%r554, %r553, %r551;
	mov.b32 	%f2279, %r554;
$L__BB0_181:
	.loc	1 159 0
	mov.b32 	%r313, %f2347;
	// begin inline asm
	div.full.f32 %r703, %r310, %r125;
	// end inline asm
	mov.b32 	%f128, %r702;
	.loc	1 159 56
	abs.ftz.f32 	%f371, %f127;
	setp.ltu.f32 	%p164, %f371, 0f3F19999A;
	@%p164 bra 	$L__BB0_183;
	bra.uni 	$L__BB0_182;
$L__BB0_183:
	mul.f32 	%f1745, %f127, %f127;
	mov.f32 	%f1746, 0fBD563CAE;
	mov.f32 	%f1747, 0f3C80F082;
	fma.rn.ftz.f32 	%f1748, %f1747, %f1745, %f1746;
	mov.f32 	%f1749, 0f3E085941;
	fma.rn.ftz.f32 	%f1750, %f1748, %f1745, %f1749;
	mov.f32 	%f1751, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1752, %f1750, %f1745, %f1751;
	mov.f32 	%f1753, 0f00000000;
	fma.rn.ftz.f32 	%f1754, %f1752, %f1745, %f1753;
	fma.rn.ftz.f32 	%f2280, %f1754, %f127, %f127;
	bra.uni 	$L__BB0_184;
$L__BB0_182:
	mul.f32 	%f1739, %f371, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1740, %f1739;
	add.f32 	%f1738, %f1740, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1737,%f1738;
	// end inline asm
	mov.f32 	%f1741, 0f3F800000;
	mov.f32 	%f1742, 0fC0000000;
	fma.rn.ftz.f32 	%f1743, %f1737, %f1742, %f1741;
	setp.ge.f32 	%p165, %f371, 0f41102CB4;
	selp.f32 	%f1744, 0f3F800000, %f1743, %p165;
	mov.b32 	%r555, %f1744;
	and.b32  	%r557, %r701, -2147483648;
	or.b32  	%r558, %r557, %r555;
	mov.b32 	%f2280, %r558;
$L__BB0_184:
	.loc	1 159 0
	// begin inline asm
	div.full.f32 %r704, %r313, %r125;
	// end inline asm
	mov.b32 	%f129, %r703;
	.loc	1 159 56
	abs.ftz.f32 	%f375, %f128;
	setp.ltu.f32 	%p166, %f375, 0f3F19999A;
	@%p166 bra 	$L__BB0_186;
	bra.uni 	$L__BB0_185;
$L__BB0_186:
	mul.f32 	%f1763, %f128, %f128;
	mov.f32 	%f1764, 0fBD563CAE;
	mov.f32 	%f1765, 0f3C80F082;
	fma.rn.ftz.f32 	%f1766, %f1765, %f1763, %f1764;
	mov.f32 	%f1767, 0f3E085941;
	fma.rn.ftz.f32 	%f1768, %f1766, %f1763, %f1767;
	mov.f32 	%f1769, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1770, %f1768, %f1763, %f1769;
	mov.f32 	%f1771, 0f00000000;
	fma.rn.ftz.f32 	%f1772, %f1770, %f1763, %f1771;
	fma.rn.ftz.f32 	%f2281, %f1772, %f128, %f128;
	bra.uni 	$L__BB0_187;
$L__BB0_185:
	mul.f32 	%f1757, %f375, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1758, %f1757;
	add.f32 	%f1756, %f1758, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1755,%f1756;
	// end inline asm
	mov.f32 	%f1759, 0f3F800000;
	mov.f32 	%f1760, 0fC0000000;
	fma.rn.ftz.f32 	%f1761, %f1755, %f1760, %f1759;
	setp.ge.f32 	%p167, %f375, 0f41102CB4;
	selp.f32 	%f1762, 0f3F800000, %f1761, %p167;
	mov.b32 	%r559, %f1762;
	and.b32  	%r561, %r702, -2147483648;
	or.b32  	%r562, %r561, %r559;
	mov.b32 	%f2281, %r562;
$L__BB0_187:
	.loc	1 159 0
	mov.b32 	%f130, %r704;
	.loc	1 159 56
	abs.ftz.f32 	%f379, %f129;
	setp.ltu.f32 	%p168, %f379, 0f3F19999A;
	@%p168 bra 	$L__BB0_189;
	bra.uni 	$L__BB0_188;
$L__BB0_189:
	mul.f32 	%f1781, %f129, %f129;
	mov.f32 	%f1782, 0fBD563CAE;
	mov.f32 	%f1783, 0f3C80F082;
	fma.rn.ftz.f32 	%f1784, %f1783, %f1781, %f1782;
	mov.f32 	%f1785, 0f3E085941;
	fma.rn.ftz.f32 	%f1786, %f1784, %f1781, %f1785;
	mov.f32 	%f1787, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1788, %f1786, %f1781, %f1787;
	mov.f32 	%f1789, 0f00000000;
	fma.rn.ftz.f32 	%f1790, %f1788, %f1781, %f1789;
	fma.rn.ftz.f32 	%f2282, %f1790, %f129, %f129;
	bra.uni 	$L__BB0_190;
$L__BB0_188:
	mul.f32 	%f1775, %f379, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1776, %f1775;
	add.f32 	%f1774, %f1776, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1773,%f1774;
	// end inline asm
	mov.f32 	%f1777, 0f3F800000;
	mov.f32 	%f1778, 0fC0000000;
	fma.rn.ftz.f32 	%f1779, %f1773, %f1778, %f1777;
	setp.ge.f32 	%p169, %f379, 0f41102CB4;
	selp.f32 	%f1780, 0f3F800000, %f1779, %p169;
	mov.b32 	%r563, %f1780;
	and.b32  	%r565, %r703, -2147483648;
	or.b32  	%r566, %r565, %r563;
	mov.b32 	%f2282, %r566;
$L__BB0_190:
	abs.ftz.f32 	%f383, %f130;
	setp.ltu.f32 	%p170, %f383, 0f3F19999A;
	@%p170 bra 	$L__BB0_192;
	bra.uni 	$L__BB0_191;
$L__BB0_192:
	mul.f32 	%f1799, %f130, %f130;
	mov.f32 	%f1800, 0fBD563CAE;
	mov.f32 	%f1801, 0f3C80F082;
	fma.rn.ftz.f32 	%f1802, %f1801, %f1799, %f1800;
	mov.f32 	%f1803, 0f3E085941;
	fma.rn.ftz.f32 	%f1804, %f1802, %f1799, %f1803;
	mov.f32 	%f1805, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f1806, %f1804, %f1799, %f1805;
	mov.f32 	%f1807, 0f00000000;
	fma.rn.ftz.f32 	%f1808, %f1806, %f1799, %f1807;
	fma.rn.ftz.f32 	%f2283, %f1808, %f130, %f130;
	bra.uni 	$L__BB0_193;
$L__BB0_191:
	mul.f32 	%f1793, %f383, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f1794, %f1793;
	add.f32 	%f1792, %f1794, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f1791,%f1792;
	// end inline asm
	mov.f32 	%f1795, 0f3F800000;
	mov.f32 	%f1796, 0fC0000000;
	fma.rn.ftz.f32 	%f1797, %f1791, %f1796, %f1795;
	setp.ge.f32 	%p171, %f383, 0f41102CB4;
	selp.f32 	%f1798, 0f3F800000, %f1797, %p171;
	mov.b32 	%r567, %f1798;
	and.b32  	%r569, %r704, -2147483648;
	or.b32  	%r570, %r569, %r567;
	mov.b32 	%f2283, %r570;
$L__BB0_193:
	.loc	1 159 44
	mul.f32 	%f2347, %f2283, %f66;
	mul.f32 	%f2346, %f2282, %f66;
	mul.f32 	%f2345, %f2281, %f66;
	mul.f32 	%f2344, %f2280, %f66;
	mul.f32 	%f2343, %f2279, %f66;
	mul.f32 	%f2342, %f2278, %f66;
	mul.f32 	%f2341, %f2277, %f66;
	mul.f32 	%f2340, %f2276, %f66;
	mul.f32 	%f2339, %f2275, %f66;
	mul.f32 	%f2338, %f2274, %f66;
	mul.f32 	%f2337, %f2273, %f66;
	mul.f32 	%f2336, %f2272, %f66;
	mul.f32 	%f2335, %f2271, %f66;
	mul.f32 	%f2334, %f2270, %f66;
	mul.f32 	%f2333, %f2269, %f66;
	mul.f32 	%f2332, %f2268, %f66;
	mul.f32 	%f2331, %f2267, %f66;
	mul.f32 	%f2330, %f2266, %f66;
	mul.f32 	%f2329, %f2265, %f66;
	mul.f32 	%f2328, %f2264, %f66;
	mul.f32 	%f2327, %f2263, %f66;
	mul.f32 	%f2326, %f2262, %f66;
	mul.f32 	%f2325, %f2261, %f66;
	mul.f32 	%f2324, %f2260, %f66;
	mul.f32 	%f2323, %f2259, %f66;
	mul.f32 	%f2322, %f2258, %f66;
	mul.f32 	%f2321, %f2257, %f66;
	mul.f32 	%f2320, %f2256, %f66;
	mul.f32 	%f2319, %f2255, %f66;
	mul.f32 	%f2318, %f2254, %f66;
	mul.f32 	%f2317, %f2253, %f66;
	mul.f32 	%f2316, %f2252, %f66;
	mul.f32 	%f2315, %f2251, %f66;
	mul.f32 	%f2314, %f2250, %f66;
	mul.f32 	%f2313, %f2249, %f66;
	mul.f32 	%f2312, %f2248, %f66;
	mul.f32 	%f2311, %f2247, %f66;
	mul.f32 	%f2310, %f2246, %f66;
	mul.f32 	%f2309, %f2245, %f66;
	mul.f32 	%f2308, %f2244, %f66;
	mul.f32 	%f2307, %f2243, %f66;
	mul.f32 	%f2306, %f2242, %f66;
	mul.f32 	%f2305, %f2241, %f66;
	mul.f32 	%f2304, %f2240, %f66;
	mul.f32 	%f2303, %f2239, %f66;
	mul.f32 	%f2302, %f2238, %f66;
	mul.f32 	%f2301, %f2237, %f66;
	mul.f32 	%f2300, %f2236, %f66;
	mul.f32 	%f2299, %f2235, %f66;
	mul.f32 	%f2298, %f2234, %f66;
	mul.f32 	%f2297, %f2233, %f66;
	mul.f32 	%f2296, %f2232, %f66;
	mul.f32 	%f2295, %f2231, %f66;
	mul.f32 	%f2294, %f2230, %f66;
	mul.f32 	%f2293, %f2229, %f66;
	mul.f32 	%f2292, %f2228, %f66;
	mul.f32 	%f2291, %f2227, %f66;
	mul.f32 	%f2290, %f2226, %f66;
	mul.f32 	%f2289, %f2225, %f66;
	mul.f32 	%f2288, %f2224, %f66;
	mul.f32 	%f2287, %f2223, %f66;
	mul.f32 	%f2286, %f2222, %f66;
	mul.f32 	%f2285, %f2221, %f66;
	mul.f32 	%f2284, %f2220, %f66;
$L__BB0_194:
$L__tmp1:
	.loc	2 163 27
	max.f32 	%f1937, %f2284, %f2285;
	max.f32 	%f1938, %f1937, %f2286;
	max.f32 	%f1939, %f1938, %f2287;
	max.f32 	%f1940, %f1939, %f2288;
	max.f32 	%f1941, %f1940, %f2289;
	max.f32 	%f1942, %f1941, %f2290;
	max.f32 	%f1943, %f1942, %f2291;
	max.f32 	%f1944, %f1943, %f2292;
	max.f32 	%f1945, %f1944, %f2293;
	max.f32 	%f1946, %f1945, %f2294;
	max.f32 	%f1947, %f1946, %f2295;
	max.f32 	%f1948, %f1947, %f2296;
	max.f32 	%f1949, %f1948, %f2297;
	max.f32 	%f1950, %f1949, %f2298;
	max.f32 	%f1951, %f1950, %f2299;
	max.f32 	%f1952, %f1951, %f2300;
	max.f32 	%f1953, %f1952, %f2301;
	max.f32 	%f1954, %f1953, %f2302;
	max.f32 	%f1955, %f1954, %f2303;
	max.f32 	%f1956, %f1955, %f2304;
	max.f32 	%f1957, %f1956, %f2305;
	max.f32 	%f1958, %f1957, %f2306;
	max.f32 	%f1959, %f1958, %f2307;
	max.f32 	%f1960, %f1959, %f2308;
	max.f32 	%f1961, %f1960, %f2309;
	max.f32 	%f1962, %f1961, %f2310;
	max.f32 	%f1963, %f1962, %f2311;
	max.f32 	%f1964, %f1963, %f2312;
	max.f32 	%f1965, %f1964, %f2313;
	max.f32 	%f1966, %f1965, %f2314;
	max.f32 	%f1967, %f1966, %f2315;
	max.f32 	%f1968, %f1967, %f2316;
	max.f32 	%f1969, %f1968, %f2317;
	max.f32 	%f1970, %f1969, %f2318;
	max.f32 	%f1971, %f1970, %f2319;
	max.f32 	%f1972, %f1971, %f2320;
	max.f32 	%f1973, %f1972, %f2321;
	max.f32 	%f1974, %f1973, %f2322;
	max.f32 	%f1975, %f1974, %f2323;
	max.f32 	%f1976, %f1975, %f2324;
	max.f32 	%f1977, %f1976, %f2325;
	max.f32 	%f1978, %f1977, %f2326;
	max.f32 	%f1979, %f1978, %f2327;
	max.f32 	%f1980, %f1979, %f2328;
	max.f32 	%f1981, %f1980, %f2329;
	max.f32 	%f1982, %f1981, %f2330;
	max.f32 	%f1983, %f1982, %f2331;
	max.f32 	%f1984, %f1983, %f2332;
	max.f32 	%f1985, %f1984, %f2333;
	max.f32 	%f1986, %f1985, %f2334;
	max.f32 	%f1987, %f1986, %f2335;
	max.f32 	%f1988, %f1987, %f2336;
	max.f32 	%f1989, %f1988, %f2337;
	max.f32 	%f1990, %f1989, %f2338;
	max.f32 	%f1991, %f1990, %f2339;
	max.f32 	%f1992, %f1991, %f2340;
	max.f32 	%f1993, %f1992, %f2341;
	max.f32 	%f1994, %f1993, %f2342;
	max.f32 	%f1995, %f1994, %f2343;
	max.f32 	%f1996, %f1995, %f2344;
	max.f32 	%f1997, %f1996, %f2345;
	max.f32 	%f1998, %f1997, %f2346;
	max.f32 	%f1999, %f1998, %f2347;
	.loc	2 184 40
	mov.b32 	%r583, %f1999;
	shfl.sync.bfly.b32	%r584, %r583, 16, 31, -1;
	mov.b32 	%f2000, %r584;
	.loc	2 163 27
	max.f32 	%f2001, %f1999, %f2000;
	.loc	2 184 40
	mov.b32 	%r585, %f2001;
	shfl.sync.bfly.b32	%r586, %r585, 8, 31, -1;
	mov.b32 	%f2002, %r586;
	.loc	2 163 27
	max.f32 	%f2003, %f2001, %f2002;
	.loc	2 184 40
	mov.b32 	%r587, %f2003;
	shfl.sync.bfly.b32	%r588, %r587, 4, 31, -1;
	mov.b32 	%f2004, %r588;
	.loc	2 163 27
	max.f32 	%f2005, %f2003, %f2004;
	.loc	2 184 40
	mov.b32 	%r589, %f2005;
	shfl.sync.bfly.b32	%r590, %r589, 2, 31, -1;
	mov.b32 	%f2006, %r590;
	.loc	2 163 27
	max.f32 	%f2007, %f2005, %f2006;
	.loc	2 184 40
	mov.b32 	%r591, %f2007;
	shfl.sync.bfly.b32	%r592, %r591, 1, 31, -1;
	mov.b32 	%f2008, %r592;
	.loc	2 163 27
	max.f32 	%f2009, %f2007, %f2008;
	.loc	2 184 40
	setp.eq.s32 	%p172, %r4, 0;
	and.b32  	%r593, %r5, 31;
	shl.b32 	%r594, %r593, 2;
	mov.u32 	%r595, global_smem;
	add.s32 	%r571, %r595, %r594;
	mov.b32 	%r572, %f2009;
	// begin inline asm
	@%p172 st.shared.b32 [ %r571 + 0 ], %r572;
	// end inline asm
	bar.sync 	0;
	setp.lt.s32 	%p173, %r3, 32;
	shl.b32 	%r596, %r3, 2;
	add.s32 	%r574, %r595, %r596;
	// begin inline asm
	@%p173 ld.shared.b32 %r573, [ %r574 + 0 ];
	// end inline asm
	mov.b32 	%f2010, %r573;
	shfl.sync.bfly.b32	%r597, %r573, 16, 31, -1;
	mov.b32 	%f2011, %r597;
	.loc	2 163 27
	max.f32 	%f2012, %f2010, %f2011;
	.loc	2 184 40
	mov.b32 	%r598, %f2012;
	shfl.sync.bfly.b32	%r599, %r598, 8, 31, -1;
	mov.b32 	%f2013, %r599;
	.loc	2 163 27
	max.f32 	%f2014, %f2012, %f2013;
	.loc	2 184 40
	mov.b32 	%r600, %f2014;
	shfl.sync.bfly.b32	%r601, %r600, 4, 31, -1;
	mov.b32 	%f2015, %r601;
	.loc	2 163 27
	max.f32 	%f2016, %f2014, %f2015;
	.loc	2 184 40
	mov.b32 	%r602, %f2016;
	shfl.sync.bfly.b32	%r603, %r602, 2, 31, -1;
	mov.b32 	%f2017, %r603;
	.loc	2 163 27
	max.f32 	%f2018, %f2016, %f2017;
	.loc	2 184 40
	mov.b32 	%r604, %f2018;
	shfl.sync.bfly.b32	%r605, %r604, 1, 31, -1;
	mov.b32 	%f2019, %r605;
	.loc	2 163 27
	max.f32 	%f2020, %f2018, %f2019;
	.loc	2 184 40
	and.pred  	%p174, %p173, %p172;
	mov.b32 	%r576, %f2020;
	// begin inline asm
	@%p174 st.shared.b32 [ %r574 + 0 ], %r576;
	// end inline asm
	bar.sync 	0;
	ld.shared.f32 	%f515, [global_smem];
$L__tmp2:
	.loc	1 162 50
	sub.f32 	%f2021, %f2284, %f515;
	sub.f32 	%f2022, %f2285, %f515;
	sub.f32 	%f2023, %f2286, %f515;
	sub.f32 	%f2024, %f2287, %f515;
	sub.f32 	%f2025, %f2288, %f515;
	sub.f32 	%f2026, %f2289, %f515;
	sub.f32 	%f2027, %f2290, %f515;
	sub.f32 	%f2028, %f2291, %f515;
	sub.f32 	%f2029, %f2292, %f515;
	sub.f32 	%f2030, %f2293, %f515;
	sub.f32 	%f2031, %f2294, %f515;
	sub.f32 	%f2032, %f2295, %f515;
	sub.f32 	%f2033, %f2296, %f515;
	sub.f32 	%f2034, %f2297, %f515;
	sub.f32 	%f2035, %f2298, %f515;
	sub.f32 	%f2036, %f2299, %f515;
	sub.f32 	%f2037, %f2300, %f515;
	sub.f32 	%f2038, %f2301, %f515;
	sub.f32 	%f2039, %f2302, %f515;
	sub.f32 	%f2040, %f2303, %f515;
	sub.f32 	%f2041, %f2304, %f515;
	sub.f32 	%f2042, %f2305, %f515;
	sub.f32 	%f2043, %f2306, %f515;
	sub.f32 	%f2044, %f2307, %f515;
	sub.f32 	%f2045, %f2308, %f515;
	sub.f32 	%f2046, %f2309, %f515;
	sub.f32 	%f2047, %f2310, %f515;
	sub.f32 	%f2048, %f2311, %f515;
	sub.f32 	%f2049, %f2312, %f515;
	sub.f32 	%f2050, %f2313, %f515;
	sub.f32 	%f2051, %f2314, %f515;
	sub.f32 	%f2052, %f2315, %f515;
	sub.f32 	%f2053, %f2316, %f515;
	sub.f32 	%f2054, %f2317, %f515;
	sub.f32 	%f2055, %f2318, %f515;
	sub.f32 	%f2056, %f2319, %f515;
	sub.f32 	%f2057, %f2320, %f515;
	sub.f32 	%f2058, %f2321, %f515;
	sub.f32 	%f2059, %f2322, %f515;
	sub.f32 	%f2060, %f2323, %f515;
	sub.f32 	%f2061, %f2324, %f515;
	sub.f32 	%f2062, %f2325, %f515;
	sub.f32 	%f2063, %f2326, %f515;
	sub.f32 	%f2064, %f2327, %f515;
	sub.f32 	%f2065, %f2328, %f515;
	sub.f32 	%f2066, %f2329, %f515;
	sub.f32 	%f2067, %f2330, %f515;
	sub.f32 	%f2068, %f2331, %f515;
	sub.f32 	%f2069, %f2332, %f515;
	sub.f32 	%f2070, %f2333, %f515;
	sub.f32 	%f2071, %f2334, %f515;
	sub.f32 	%f2072, %f2335, %f515;
	sub.f32 	%f2073, %f2336, %f515;
	sub.f32 	%f2074, %f2337, %f515;
	sub.f32 	%f2075, %f2338, %f515;
	sub.f32 	%f2076, %f2339, %f515;
	sub.f32 	%f2077, %f2340, %f515;
	sub.f32 	%f2078, %f2341, %f515;
	sub.f32 	%f2079, %f2342, %f515;
	sub.f32 	%f2080, %f2343, %f515;
	sub.f32 	%f2081, %f2344, %f515;
	sub.f32 	%f2082, %f2345, %f515;
	sub.f32 	%f2083, %f2346, %f515;
	sub.f32 	%f2084, %f2347, %f515;
	.loc	1 162 41
	mul.f32 	%f1810, %f2021, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1809, %f1810;
	// end inline asm
	mul.f32 	%f1812, %f2022, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1811, %f1812;
	// end inline asm
	mul.f32 	%f1814, %f2023, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1813, %f1814;
	// end inline asm
	mul.f32 	%f1816, %f2024, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1815, %f1816;
	// end inline asm
	mul.f32 	%f1818, %f2025, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1817, %f1818;
	// end inline asm
	mul.f32 	%f1820, %f2026, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1819, %f1820;
	// end inline asm
	mul.f32 	%f1822, %f2027, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1821, %f1822;
	// end inline asm
	mul.f32 	%f1824, %f2028, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1823, %f1824;
	// end inline asm
	mul.f32 	%f1826, %f2029, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1825, %f1826;
	// end inline asm
	mul.f32 	%f1828, %f2030, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1827, %f1828;
	// end inline asm
	mul.f32 	%f1830, %f2031, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1829, %f1830;
	// end inline asm
	mul.f32 	%f1832, %f2032, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1831, %f1832;
	// end inline asm
	mul.f32 	%f1834, %f2033, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1833, %f1834;
	// end inline asm
	mul.f32 	%f1836, %f2034, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1835, %f1836;
	// end inline asm
	mul.f32 	%f1838, %f2035, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1837, %f1838;
	// end inline asm
	mul.f32 	%f1840, %f2036, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1839, %f1840;
	// end inline asm
	mul.f32 	%f1842, %f2037, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1841, %f1842;
	// end inline asm
	mul.f32 	%f1844, %f2038, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1843, %f1844;
	// end inline asm
	mul.f32 	%f1846, %f2039, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1845, %f1846;
	// end inline asm
	mul.f32 	%f1848, %f2040, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1847, %f1848;
	// end inline asm
	mul.f32 	%f1850, %f2041, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1849, %f1850;
	// end inline asm
	mul.f32 	%f1852, %f2042, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1851, %f1852;
	// end inline asm
	mul.f32 	%f1854, %f2043, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1853, %f1854;
	// end inline asm
	mul.f32 	%f1856, %f2044, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1855, %f1856;
	// end inline asm
	mul.f32 	%f1858, %f2045, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1857, %f1858;
	// end inline asm
	mul.f32 	%f1860, %f2046, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1859, %f1860;
	// end inline asm
	mul.f32 	%f1862, %f2047, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1861, %f1862;
	// end inline asm
	mul.f32 	%f1864, %f2048, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1863, %f1864;
	// end inline asm
	mul.f32 	%f1866, %f2049, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1865, %f1866;
	// end inline asm
	mul.f32 	%f1868, %f2050, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1867, %f1868;
	// end inline asm
	mul.f32 	%f1870, %f2051, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1869, %f1870;
	// end inline asm
	mul.f32 	%f1872, %f2052, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1871, %f1872;
	// end inline asm
	mul.f32 	%f1874, %f2053, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1873, %f1874;
	// end inline asm
	mul.f32 	%f1876, %f2054, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1875, %f1876;
	// end inline asm
	mul.f32 	%f1878, %f2055, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1877, %f1878;
	// end inline asm
	mul.f32 	%f1880, %f2056, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1879, %f1880;
	// end inline asm
	mul.f32 	%f1882, %f2057, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1881, %f1882;
	// end inline asm
	mul.f32 	%f1884, %f2058, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1883, %f1884;
	// end inline asm
	mul.f32 	%f1886, %f2059, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1885, %f1886;
	// end inline asm
	mul.f32 	%f1888, %f2060, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1887, %f1888;
	// end inline asm
	mul.f32 	%f1890, %f2061, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1889, %f1890;
	// end inline asm
	mul.f32 	%f1892, %f2062, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1891, %f1892;
	// end inline asm
	mul.f32 	%f1894, %f2063, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1893, %f1894;
	// end inline asm
	mul.f32 	%f1896, %f2064, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1895, %f1896;
	// end inline asm
	mul.f32 	%f1898, %f2065, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1897, %f1898;
	// end inline asm
	mul.f32 	%f1900, %f2066, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1899, %f1900;
	// end inline asm
	mul.f32 	%f1902, %f2067, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1901, %f1902;
	// end inline asm
	mul.f32 	%f1904, %f2068, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1903, %f1904;
	// end inline asm
	mul.f32 	%f1906, %f2069, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1905, %f1906;
	// end inline asm
	mul.f32 	%f1908, %f2070, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1907, %f1908;
	// end inline asm
	mul.f32 	%f1910, %f2071, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1909, %f1910;
	// end inline asm
	mul.f32 	%f1912, %f2072, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1911, %f1912;
	// end inline asm
	mul.f32 	%f1914, %f2073, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1913, %f1914;
	// end inline asm
	mul.f32 	%f1916, %f2074, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1915, %f1916;
	// end inline asm
	mul.f32 	%f1918, %f2075, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1917, %f1918;
	// end inline asm
	mul.f32 	%f1920, %f2076, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1919, %f1920;
	// end inline asm
	mul.f32 	%f1922, %f2077, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1921, %f1922;
	// end inline asm
	mul.f32 	%f1924, %f2078, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1923, %f1924;
	// end inline asm
	mul.f32 	%f1926, %f2079, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1925, %f1926;
	// end inline asm
	mul.f32 	%f1928, %f2080, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1927, %f1928;
	// end inline asm
	mul.f32 	%f1930, %f2081, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1929, %f1930;
	// end inline asm
	mul.f32 	%f1932, %f2082, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1931, %f1932;
	// end inline asm
	mul.f32 	%f1934, %f2083, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1933, %f1934;
	// end inline asm
	mul.f32 	%f1936, %f2084, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1935, %f1936;
	// end inline asm
$L__tmp3:
	.loc	2 267 36
	bar.sync 	0;
	.loc	2 256 15
	add.f32 	%f2085, %f1809, %f1811;
	add.f32 	%f2086, %f2085, %f1813;
	add.f32 	%f2087, %f2086, %f1815;
	add.f32 	%f2088, %f2087, %f1817;
	add.f32 	%f2089, %f2088, %f1819;
	add.f32 	%f2090, %f2089, %f1821;
	add.f32 	%f2091, %f2090, %f1823;
	add.f32 	%f2092, %f2091, %f1825;
	add.f32 	%f2093, %f2092, %f1827;
	add.f32 	%f2094, %f2093, %f1829;
	add.f32 	%f2095, %f2094, %f1831;
	add.f32 	%f2096, %f2095, %f1833;
	add.f32 	%f2097, %f2096, %f1835;
	add.f32 	%f2098, %f2097, %f1837;
	add.f32 	%f2099, %f2098, %f1839;
	add.f32 	%f2100, %f2099, %f1841;
	add.f32 	%f2101, %f2100, %f1843;
	add.f32 	%f2102, %f2101, %f1845;
	add.f32 	%f2103, %f2102, %f1847;
	add.f32 	%f2104, %f2103, %f1849;
	add.f32 	%f2105, %f2104, %f1851;
	add.f32 	%f2106, %f2105, %f1853;
	add.f32 	%f2107, %f2106, %f1855;
	add.f32 	%f2108, %f2107, %f1857;
	add.f32 	%f2109, %f2108, %f1859;
	add.f32 	%f2110, %f2109, %f1861;
	add.f32 	%f2111, %f2110, %f1863;
	add.f32 	%f2112, %f2111, %f1865;
	add.f32 	%f2113, %f2112, %f1867;
	add.f32 	%f2114, %f2113, %f1869;
	add.f32 	%f2115, %f2114, %f1871;
	add.f32 	%f2116, %f2115, %f1873;
	add.f32 	%f2117, %f2116, %f1875;
	add.f32 	%f2118, %f2117, %f1877;
	add.f32 	%f2119, %f2118, %f1879;
	add.f32 	%f2120, %f2119, %f1881;
	add.f32 	%f2121, %f2120, %f1883;
	add.f32 	%f2122, %f2121, %f1885;
	add.f32 	%f2123, %f2122, %f1887;
	add.f32 	%f2124, %f2123, %f1889;
	add.f32 	%f2125, %f2124, %f1891;
	add.f32 	%f2126, %f2125, %f1893;
	add.f32 	%f2127, %f2126, %f1895;
	add.f32 	%f2128, %f2127, %f1897;
	add.f32 	%f2129, %f2128, %f1899;
	add.f32 	%f2130, %f2129, %f1901;
	add.f32 	%f2131, %f2130, %f1903;
	add.f32 	%f2132, %f2131, %f1905;
	add.f32 	%f2133, %f2132, %f1907;
	add.f32 	%f2134, %f2133, %f1909;
	add.f32 	%f2135, %f2134, %f1911;
	add.f32 	%f2136, %f2135, %f1913;
	add.f32 	%f2137, %f2136, %f1915;
	add.f32 	%f2138, %f2137, %f1917;
	add.f32 	%f2139, %f2138, %f1919;
	add.f32 	%f2140, %f2139, %f1921;
	add.f32 	%f2141, %f2140, %f1923;
	add.f32 	%f2142, %f2141, %f1925;
	add.f32 	%f2143, %f2142, %f1927;
	add.f32 	%f2144, %f2143, %f1929;
	add.f32 	%f2145, %f2144, %f1931;
	add.f32 	%f2146, %f2145, %f1933;
	add.f32 	%f2147, %f2146, %f1935;
	.loc	2 267 36
	mov.b32 	%r606, %f2147;
	shfl.sync.bfly.b32	%r607, %r606, 16, 31, -1;
	mov.b32 	%f2148, %r607;
	.loc	2 256 15
	add.f32 	%f2149, %f2147, %f2148;
	.loc	2 267 36
	mov.b32 	%r608, %f2149;
	shfl.sync.bfly.b32	%r609, %r608, 8, 31, -1;
	mov.b32 	%f2150, %r609;
	.loc	2 256 15
	add.f32 	%f2151, %f2149, %f2150;
	.loc	2 267 36
	mov.b32 	%r610, %f2151;
	shfl.sync.bfly.b32	%r611, %r610, 4, 31, -1;
	mov.b32 	%f2152, %r611;
	.loc	2 256 15
	add.f32 	%f2153, %f2151, %f2152;
	.loc	2 267 36
	mov.b32 	%r612, %f2153;
	shfl.sync.bfly.b32	%r613, %r612, 2, 31, -1;
	mov.b32 	%f2154, %r613;
	.loc	2 256 15
	add.f32 	%f2155, %f2153, %f2154;
	.loc	2 267 36
	mov.b32 	%r614, %f2155;
	shfl.sync.bfly.b32	%r615, %r614, 1, 31, -1;
	mov.b32 	%f2156, %r615;
	.loc	2 256 15
	add.f32 	%f2157, %f2155, %f2156;
	.loc	2 267 36
	mov.b32 	%r578, %f2157;
	// begin inline asm
	@%p172 st.shared.b32 [ %r571 + 0 ], %r578;
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p173 ld.shared.b32 %r579, [ %r574 + 0 ];
	// end inline asm
	mov.b32 	%f2158, %r579;
	shfl.sync.bfly.b32	%r616, %r579, 16, 31, -1;
	mov.b32 	%f2159, %r616;
	.loc	2 256 15
	add.f32 	%f2160, %f2158, %f2159;
	.loc	2 267 36
	mov.b32 	%r617, %f2160;
	shfl.sync.bfly.b32	%r618, %r617, 8, 31, -1;
	mov.b32 	%f2161, %r618;
	.loc	2 256 15
	add.f32 	%f2162, %f2160, %f2161;
	.loc	2 267 36
	mov.b32 	%r619, %f2162;
	shfl.sync.bfly.b32	%r620, %r619, 4, 31, -1;
	mov.b32 	%f2163, %r620;
	.loc	2 256 15
	add.f32 	%f2164, %f2162, %f2163;
	.loc	2 267 36
	mov.b32 	%r621, %f2164;
	shfl.sync.bfly.b32	%r622, %r621, 2, 31, -1;
	mov.b32 	%f2165, %r622;
	.loc	2 256 15
	add.f32 	%f2166, %f2164, %f2165;
	.loc	2 267 36
	mov.b32 	%r623, %f2166;
	shfl.sync.bfly.b32	%r624, %r623, 1, 31, -1;
	mov.b32 	%f2167, %r624;
	.loc	2 256 15
	add.f32 	%f2168, %f2166, %f2167;
	.loc	2 267 36
	mov.b32 	%r582, %f2168;
	// begin inline asm
	@%p174 st.shared.b32 [ %r574 + 0 ], %r582;
	// end inline asm
	bar.sync 	0;
	ld.shared.f32 	%f2169, [global_smem];
$L__tmp4:
	.loc	1 162 27
	setp.lt.f32 	%p178, %f2169, 0f00800000;
	mul.f32 	%f2170, %f2169, 0f4B000000;
	selp.f32 	%f516, %f2170, %f2169, %p178;
	selp.f32 	%f2171, 0fC1B80000, 0f00000000, %p178;
	mov.b32 	%r625, %f516;
	add.s32 	%r626, %r625, -1059760811;
	and.b32  	%r627, %r626, -8388608;
	sub.s32 	%r628, %r625, %r627;
	mov.b32 	%f2172, %r628;
	cvt.rn.f32.s32 	%f2173, %r627;
	mov.f32 	%f2174, 0f34000000;
	fma.rn.ftz.f32 	%f2175, %f2173, %f2174, %f2171;
	add.f32 	%f2176, %f2172, 0fBF800000;
	mov.f32 	%f2177, 0f3E1039F6;
	mov.f32 	%f2178, 0fBE055027;
	fma.rn.ftz.f32 	%f2179, %f2178, %f2176, %f2177;
	mov.f32 	%f2180, 0fBDF8CDCC;
	fma.rn.ftz.f32 	%f2181, %f2179, %f2176, %f2180;
	mov.f32 	%f2182, 0f3E0F2955;
	fma.rn.ftz.f32 	%f2183, %f2181, %f2176, %f2182;
	mov.f32 	%f2184, 0fBE2AD8B9;
	fma.rn.ftz.f32 	%f2185, %f2183, %f2176, %f2184;
	mov.f32 	%f2186, 0f3E4CED0B;
	fma.rn.ftz.f32 	%f2187, %f2185, %f2176, %f2186;
	mov.f32 	%f2188, 0fBE7FFF22;
	fma.rn.ftz.f32 	%f2189, %f2187, %f2176, %f2188;
	mov.f32 	%f2190, 0f3EAAAA78;
	fma.rn.ftz.f32 	%f2191, %f2189, %f2176, %f2190;
	mov.f32 	%f2192, 0fBF000000;
	fma.rn.ftz.f32 	%f2193, %f2191, %f2176, %f2192;
	mul.f32 	%f2194, %f2176, %f2193;
	fma.rn.ftz.f32 	%f2195, %f2194, %f2176, %f2176;
	mov.f32 	%f2196, 0f3F317218;
	fma.rn.ftz.f32 	%f2348, %f2175, %f2196, %f2195;
	setp.lt.u32 	%p179, %r625, 2139095040;
	@%p179 bra 	$L__BB0_196;
	.loc	1 0 27
	mov.f32 	%f2197, 0f7F800000;
	fma.rn.ftz.f32 	%f2348, %f516, %f2197, %f2197;
$L__BB0_196:
	ld.param.u32 	%r9, [_chunked_cross_entropy_forward_param_6];
	ld.param.u64 	%rd3, [_chunked_cross_entropy_forward_param_3];
	.loc	1 164 20
	setp.ne.s32 	%p180, %r12, 0;
	setp.eq.s32 	%p188, %r3, 0;
	.loc	1 164 7
	@%p180 bra 	$L__BB0_205;
	.loc	1 0 7
	ld.param.u64 	%rd15, [_chunked_cross_entropy_forward_param_2];
	mul.wide.s32 	%rd19, %r11, 4;
	add.s64 	%rd24, %rd15, %rd19;
	cvt.u32.u64 	%r6, %rd4;
	.loc	1 167 24
	setp.eq.s32 	%p181, %r6, -100;
	mov.b32 	%r706, 0;
	.loc	1 167 11
	@%p181 bra 	$L__BB0_204;
	.loc	1 168 37
	mul.wide.s32 	%rd23, %r6, 2;
	add.s64 	%rd22, %rd1, %rd23;
	.loc	1 168 24
	// begin inline asm
	mov.u16 %rs69, 0x0;
	@%p3 ld.global.b16 { %rs69 }, [ %rd22 + 0 ];
	// end inline asm
	.loc	1 168 51
	cvt.f32.f16 	%f2198, %rs69;
	.loc	1 170 15
	mul.f32 	%f2199, %f1, %f2198;
	selp.f32 	%f2350, %f2199, %f2198, %p2;
	.loc	1 172 15
	@!%p1 bra 	$L__BB0_203;
	bra.uni 	$L__BB0_199;
$L__BB0_199:
	.loc	1 172 63
	cvt.rn.f32.s32 	%f521, %r10;
	mov.b32 	%r631, %f2350;
	mov.b32 	%r632, %f521;
	// begin inline asm
	div.full.f32 %r705, %r631, %r632;
	// end inline asm
	mov.b32 	%f522, %r705;
	.loc	1 172 59
	abs.ftz.f32 	%f523, %f522;
	setp.ltu.f32 	%p183, %f523, 0f3F19999A;
	@%p183 bra 	$L__BB0_201;
	bra.uni 	$L__BB0_200;
$L__BB0_201:
	mul.f32 	%f2208, %f522, %f522;
	mov.f32 	%f2209, 0fBD563CAE;
	mov.f32 	%f2210, 0f3C80F082;
	fma.rn.ftz.f32 	%f2211, %f2210, %f2208, %f2209;
	mov.f32 	%f2212, 0f3E085941;
	fma.rn.ftz.f32 	%f2213, %f2211, %f2208, %f2212;
	mov.f32 	%f2214, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f2215, %f2213, %f2208, %f2214;
	mov.f32 	%f2216, 0f00000000;
	fma.rn.ftz.f32 	%f2217, %f2215, %f2208, %f2216;
	fma.rn.ftz.f32 	%f2349, %f2217, %f522, %f522;
	bra.uni 	$L__BB0_202;
$L__BB0_200:
	mul.f32 	%f2202, %f523, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f2203, %f2202;
	add.f32 	%f2201, %f2203, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f2200,%f2201;
	// end inline asm
	mov.f32 	%f2204, 0f3F800000;
	mov.f32 	%f2205, 0fC0000000;
	fma.rn.ftz.f32 	%f2206, %f2200, %f2205, %f2204;
	setp.ge.f32 	%p184, %f523, 0f41102CB4;
	selp.f32 	%f2207, 0f3F800000, %f2206, %p184;
	mov.b32 	%r633, %f2207;
	and.b32  	%r635, %r705, -2147483648;
	or.b32  	%r636, %r635, %r633;
	mov.b32 	%f2349, %r636;
$L__BB0_202:
	.loc	1 172 47
	mul.f32 	%f2350, %f2349, %f521;
$L__BB0_203:
	.loc	1 173 26
	mov.b32 	%r637, %f2350;
	.loc	1 176 27
	xor.b32  	%r706, %r637, -2147483648;
$L__BB0_204:
	// begin inline asm
	@%p188 st.global.b32 [ %rd24 + 0 ], { %r706 };
	// end inline asm
$L__BB0_205:
	.loc	1 162 27
	setp.eq.f32 	%p187, %f516, 0f00000000;
	selp.f32 	%f2218, 0fFF800000, %f2348, %p187;
	.loc	1 162 20
	add.f32 	%f2219, %f515, %f2218;
	.loc	1 147 42
	mad.lo.s32 	%r640, %r11, %r9, %r12;
	.loc	1 147 21
	mul.wide.s32 	%rd26, %r640, 4;
	add.s64 	%rd25, %rd3, %rd26;
	.loc	1 178 28
	mov.b32 	%r639, %f2219;
	// begin inline asm
	@%p188 st.global.b32 [ %rd25 + 0 ], { %r639 };
	// end inline asm
	.loc	1 178 4
	ret;
$L__tmp5:
$L__func_end0:

}
	.file	1 "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/unsloth/kernels/cross_entropy_loss.py"
	.file	2 "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 1
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 2
.b8 46
.b8 0
.b8 3
.b8 8
.b8 32
.b8 11
.b8 0
.b8 0
.b8 3
.b8 46
.b8 1
.b8 17
.b8 1
.b8 18
.b8 1
.b8 49
.b8 19
.b8 0
.b8 0
.b8 4
.b8 29
.b8 0
.b8 49
.b8 19
.b8 17
.b8 1
.b8 18
.b8 1
.b8 88
.b8 11
.b8 89
.b8 11
.b8 87
.b8 11
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 246
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 99
.b8 114
.b8 111
.b8 115
.b8 115
.b8 95
.b8 101
.b8 110
.b8 116
.b8 114
.b8 111
.b8 112
.b8 121
.b8 95
.b8 108
.b8 111
.b8 115
.b8 115
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 47
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 122
.b8 101
.b8 117
.b8 115
.b8 47
.b8 109
.b8 105
.b8 110
.b8 105
.b8 99
.b8 111
.b8 110
.b8 100
.b8 97
.b8 51
.b8 47
.b8 101
.b8 110
.b8 118
.b8 115
.b8 47
.b8 99
.b8 108
.b8 111
.b8 117
.b8 100
.b8 115
.b8 112
.b8 97
.b8 99
.b8 101
.b8 47
.b8 108
.b8 105
.b8 98
.b8 47
.b8 112
.b8 121
.b8 116
.b8 104
.b8 111
.b8 110
.b8 51
.b8 46
.b8 49
.b8 49
.b8 47
.b8 115
.b8 105
.b8 116
.b8 101
.b8 45
.b8 112
.b8 97
.b8 99
.b8 107
.b8 97
.b8 103
.b8 101
.b8 115
.b8 47
.b8 117
.b8 110
.b8 115
.b8 108
.b8 111
.b8 116
.b8 104
.b8 47
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 115
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
.b8 2
.b8 95
.b8 99
.b8 104
.b8 117
.b8 110
.b8 107
.b8 101
.b8 100
.b8 95
.b8 99
.b8 114
.b8 111
.b8 115
.b8 115
.b8 95
.b8 101
.b8 110
.b8 116
.b8 114
.b8 111
.b8 112
.b8 121
.b8 95
.b8 102
.b8 111
.b8 114
.b8 119
.b8 97
.b8 114
.b8 100
.b8 0
.b8 1
.b8 3
.b64 $L__func_begin0
.b64 $L__func_end0
.b32 146
.b8 4
.b32 146
.b64 $L__tmp1
.b64 $L__tmp2
.b8 1
.b8 161
.b8 23
.b8 4
.b32 146
.b64 $L__tmp3
.b64 $L__tmp4
.b8 1
.b8 162
.b8 54
.b8 0
.b8 0
	}
	.section	.debug_loc	{	}
