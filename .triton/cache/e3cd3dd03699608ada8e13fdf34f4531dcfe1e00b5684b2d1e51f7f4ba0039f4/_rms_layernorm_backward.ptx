//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_75
.address_size 64

	// .globl	_rms_layernorm_backward
.extern .shared .align 16 .b8 global_smem[];

.visible .entry _rms_layernorm_backward(
	.param .u64 _rms_layernorm_backward_param_0,
	.param .u32 _rms_layernorm_backward_param_1,
	.param .u64 _rms_layernorm_backward_param_2,
	.param .u32 _rms_layernorm_backward_param_3,
	.param .u64 _rms_layernorm_backward_param_4,
	.param .u32 _rms_layernorm_backward_param_5,
	.param .u64 _rms_layernorm_backward_param_6,
	.param .u64 _rms_layernorm_backward_param_7,
	.param .u32 _rms_layernorm_backward_param_8,
	.param .f32 _rms_layernorm_backward_param_9
)
.maxntid 256, 1, 1
{
	.reg .pred 	%p<38>;
	.reg .b16 	%rs<89>;
	.reg .b32 	%r<142>;
	.reg .f32 	%f<182>;
	.reg .b64 	%rd<20>;
	.loc	1 58 0
$L__func_begin0:
	.loc	1 58 0

	ld.param.u64 	%rd10, [_rms_layernorm_backward_param_0];
	ld.param.u32 	%r68, [_rms_layernorm_backward_param_1];
$L__tmp0:
	.loc	1 74 28
	// begin inline asm
	mov.u32 %r1, %ctaid.x;
	// end inline asm
	.loc	1 75 31
	mov.u32 	%r69, %tid.x;
	and.b32  	%r70, %r69, 31;
	ld.param.u64 	%rd11, [_rms_layernorm_backward_param_4];
	shl.b32 	%r71, %r69, 3;
	ld.param.u32 	%r72, [_rms_layernorm_backward_param_5];
	and.b32  	%r73, %r71, 2040;
	ld.param.u64 	%rd12, [_rms_layernorm_backward_param_6];
	or.b32  	%r74, %r73, 2048;
	ld.param.u64 	%rd13, [_rms_layernorm_backward_param_7];
	ld.param.u32 	%r75, [_rms_layernorm_backward_param_8];
	.loc	1 76 25
	setp.lt.s32 	%p1, %r73, %r75;
	setp.lt.s32 	%p6, %r74, %r75;
	.loc	1 78 20
	mul.lo.s32 	%r76, %r1, %r68;
	.loc	1 78 10
	mul.wide.s32 	%rd14, %r76, 2;
	add.s64 	%rd15, %rd10, %rd14;
	.loc	1 79 21
	mul.lo.s32 	%r77, %r1, %r72;
	.loc	1 79 10
	mul.wide.s32 	%rd16, %r77, 2;
	add.s64 	%rd17, %rd11, %rd16;
	.loc	1 80 10
	mul.wide.s32 	%rd18, %r1, 4;
	add.s64 	%rd7, %rd13, %rd18;
	.loc	1 85 26
	mul.wide.u32 	%rd19, %r73, 2;
	add.s64 	%rd1, %rd15, %rd19;
	add.s64 	%rd2, %rd1, 4096;
	mov.b32 	%r6, 0;
	.loc	1 85 21
	// begin inline asm
	mov.u32 %r2, 0x0;
	mov.u32 %r3, 0x0;
	mov.u32 %r4, 0x0;
	mov.u32 %r5, 0x0;
	@%p1 ld.global.v4.b32 { %r2, %r3, %r4, %r5 }, [ %rd1 + 0 ];
	@!%p1 mov.u32 %r2, %r6;
	@!%p1 mov.u32 %r3, %r6;
	@!%p1 mov.u32 %r4, %r6;
	@!%p1 mov.u32 %r5, %r6;
	// end inline asm
	// begin inline asm
	mov.u32 %r10, 0x0;
	mov.u32 %r11, 0x0;
	mov.u32 %r12, 0x0;
	mov.u32 %r13, 0x0;
	@%p6 ld.global.v4.b32 { %r10, %r11, %r12, %r13 }, [ %rd2 + 0 ];
	@!%p6 mov.u32 %r10, %r6;
	@!%p6 mov.u32 %r11, %r6;
	@!%p6 mov.u32 %r12, %r6;
	@!%p6 mov.u32 %r13, %r6;
	// end inline asm
	.loc	1 86 26
	add.s64 	%rd3, %rd17, %rd19;
	add.s64 	%rd4, %rd3, 4096;
	.loc	1 86 21
	// begin inline asm
	mov.u32 %r18, 0x0;
	mov.u32 %r19, 0x0;
	mov.u32 %r20, 0x0;
	mov.u32 %r21, 0x0;
	@%p1 ld.global.v4.b32 { %r18, %r19, %r20, %r21 }, [ %rd3 + 0 ];
	@!%p1 mov.u32 %r18, %r6;
	@!%p1 mov.u32 %r19, %r6;
	@!%p1 mov.u32 %r20, %r6;
	@!%p1 mov.u32 %r21, %r6;
	// end inline asm
	// begin inline asm
	mov.u32 %r26, 0x0;
	mov.u32 %r27, 0x0;
	mov.u32 %r28, 0x0;
	mov.u32 %r29, 0x0;
	@%p6 ld.global.v4.b32 { %r26, %r27, %r28, %r29 }, [ %rd4 + 0 ];
	@!%p6 mov.u32 %r26, %r6;
	@!%p6 mov.u32 %r27, %r6;
	@!%p6 mov.u32 %r28, %r6;
	@!%p6 mov.u32 %r29, %r6;
	// end inline asm
	.loc	1 87 26
	add.s64 	%rd5, %rd12, %rd19;
	add.s64 	%rd6, %rd5, 4096;
	.loc	1 87 21
	// begin inline asm
	mov.u32 %r34, 0x0;
	mov.u32 %r35, 0x0;
	mov.u32 %r36, 0x0;
	mov.u32 %r37, 0x0;
	@%p1 ld.global.v4.b32 { %r34, %r35, %r36, %r37 }, [ %rd5 + 0 ];
	@!%p1 mov.u32 %r34, %r6;
	@!%p1 mov.u32 %r35, %r6;
	@!%p1 mov.u32 %r36, %r6;
	@!%p1 mov.u32 %r37, %r6;
	// end inline asm
	// begin inline asm
	mov.u32 %r42, 0x0;
	mov.u32 %r43, 0x0;
	mov.u32 %r44, 0x0;
	mov.u32 %r45, 0x0;
	@%p6 ld.global.v4.b32 { %r42, %r43, %r44, %r45 }, [ %rd6 + 0 ];
	@!%p6 mov.u32 %r42, %r6;
	@!%p6 mov.u32 %r43, %r6;
	@!%p6 mov.u32 %r44, %r6;
	@!%p6 mov.u32 %r45, %r6;
	// end inline asm
	mov.pred 	%p31, -1;
	.loc	1 90 22
	// begin inline asm
	mov.u32 %r58, 0x0;
	@%p31 ld.global.b32 { %r58 }, [ %rd7 + 0 ];
	// end inline asm
	mov.b32 	%f1, %r58;
	.loc	1 85 21
	cvt.u16.u32 	%rs1, %r10;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs2}, %r10; }
	mov.b32 	%r90, {%rs2, %rs1};
	.loc	1 85 66
	mov.b32 	{%rs3, %rs4}, %r90;
	cvt.f32.f16 	%f2, %rs4;
	cvt.f32.f16 	%f3, %rs3;
	.loc	1 86 21
	cvt.u16.u32 	%rs5, %r26;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs6}, %r26; }
	mov.b32 	%r92, {%rs6, %rs5};
	.loc	1 86 66
	mov.b32 	{%rs7, %rs8}, %r92;
	cvt.f32.f16 	%f4, %rs8;
	cvt.f32.f16 	%f5, %rs7;
	.loc	1 87 21
	cvt.u16.u32 	%rs9, %r42;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs10}, %r42; }
	mov.b32 	%r94, {%rs10, %rs9};
	.loc	1 87 66
	mov.b32 	{%rs11, %rs12}, %r94;
	cvt.f32.f16 	%f6, %rs12;
	cvt.f32.f16 	%f7, %rs11;
	.loc	1 91 21
	mul.f32 	%f8, %f1, %f5;
	mul.f32 	%f9, %f1, %f4;
	.loc	1 94 30
	mul.f32 	%f10, %f3, %f7;
	mul.f32 	%f11, %f2, %f6;
	.loc	1 85 21
	cvt.u16.u32 	%rs13, %r11;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs14}, %r11; }
	mov.b32 	%r96, {%rs14, %rs13};
	.loc	1 85 66
	mov.b32 	{%rs15, %rs16}, %r96;
	cvt.f32.f16 	%f12, %rs16;
	cvt.f32.f16 	%f13, %rs15;
	.loc	1 86 21
	cvt.u16.u32 	%rs17, %r27;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs18}, %r27; }
	mov.b32 	%r98, {%rs18, %rs17};
	.loc	1 86 66
	mov.b32 	{%rs19, %rs20}, %r98;
	cvt.f32.f16 	%f14, %rs20;
	cvt.f32.f16 	%f15, %rs19;
	.loc	1 87 21
	cvt.u16.u32 	%rs21, %r43;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs22}, %r43; }
	mov.b32 	%r100, {%rs22, %rs21};
	.loc	1 87 66
	mov.b32 	{%rs23, %rs24}, %r100;
	cvt.f32.f16 	%f16, %rs24;
	cvt.f32.f16 	%f17, %rs23;
	.loc	1 91 21
	mul.f32 	%f18, %f1, %f15;
	mul.f32 	%f19, %f1, %f14;
	.loc	1 94 30
	mul.f32 	%f20, %f13, %f17;
	mul.f32 	%f21, %f12, %f16;
	.loc	1 85 21
	cvt.u16.u32 	%rs25, %r12;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs26}, %r12; }
	mov.b32 	%r102, {%rs26, %rs25};
	.loc	1 85 66
	mov.b32 	{%rs27, %rs28}, %r102;
	cvt.f32.f16 	%f22, %rs28;
	cvt.f32.f16 	%f23, %rs27;
	.loc	1 86 21
	cvt.u16.u32 	%rs29, %r28;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs30}, %r28; }
	mov.b32 	%r104, {%rs30, %rs29};
	.loc	1 86 66
	mov.b32 	{%rs31, %rs32}, %r104;
	cvt.f32.f16 	%f24, %rs32;
	cvt.f32.f16 	%f25, %rs31;
	.loc	1 87 21
	cvt.u16.u32 	%rs33, %r44;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs34}, %r44; }
	mov.b32 	%r106, {%rs34, %rs33};
	.loc	1 87 66
	mov.b32 	{%rs35, %rs36}, %r106;
	cvt.f32.f16 	%f26, %rs36;
	cvt.f32.f16 	%f27, %rs35;
	.loc	1 91 21
	mul.f32 	%f28, %f1, %f25;
	mul.f32 	%f29, %f1, %f24;
	.loc	1 94 30
	mul.f32 	%f30, %f23, %f27;
	mul.f32 	%f31, %f22, %f26;
	.loc	1 85 21
	cvt.u16.u32 	%rs37, %r13;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs38}, %r13; }
	mov.b32 	%r108, {%rs38, %rs37};
	.loc	1 85 66
	mov.b32 	{%rs39, %rs40}, %r108;
	cvt.f32.f16 	%f32, %rs40;
	cvt.f32.f16 	%f33, %rs39;
	.loc	1 86 21
	cvt.u16.u32 	%rs41, %r29;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs42}, %r29; }
	mov.b32 	%r110, {%rs42, %rs41};
	.loc	1 86 66
	mov.b32 	{%rs43, %rs44}, %r110;
	cvt.f32.f16 	%f34, %rs44;
	cvt.f32.f16 	%f35, %rs43;
	.loc	1 87 21
	cvt.u16.u32 	%rs45, %r45;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs46}, %r45; }
	mov.b32 	%r112, {%rs46, %rs45};
	.loc	1 87 66
	mov.b32 	{%rs47, %rs48}, %r112;
	cvt.f32.f16 	%f36, %rs48;
	cvt.f32.f16 	%f37, %rs47;
	.loc	1 91 21
	mul.f32 	%f38, %f1, %f35;
	mul.f32 	%f39, %f1, %f34;
	.loc	1 94 30
	mul.f32 	%f40, %f33, %f37;
	mul.f32 	%f41, %f32, %f36;
$L__tmp1:
	.loc	2 267 36
	setp.eq.s32 	%p32, %r70, 0;
	shr.u32 	%r114, %r69, 3;
	and.b32  	%r115, %r114, 28;
	mov.u32 	%r116, global_smem;
	add.s32 	%r51, %r116, %r115;
	setp.lt.s32 	%p33, %r69, 8;
	shl.b32 	%r117, %r69, 2;
	add.s32 	%r54, %r116, %r117;
	and.b32  	%r118, %r69, 7;
	setp.eq.s32 	%p37, %r118, 0;
	and.pred  	%p34, %p33, %p37;
$L__tmp2:
	.loc	1 97 21
	cvt.rn.f32.s32 	%f42, %r75;
	.loc	1 85 66
	mov.b32 	{%rs49, %rs50}, %r5;
	cvt.f32.f16 	%f43, %rs49;
	cvt.f32.f16 	%f44, %rs50;
	.loc	1 86 66
	mov.b32 	{%rs51, %rs52}, %r21;
	cvt.f32.f16 	%f45, %rs51;
	cvt.f32.f16 	%f46, %rs52;
	.loc	1 87 66
	mov.b32 	{%rs53, %rs54}, %r37;
	cvt.f32.f16 	%f47, %rs53;
	cvt.f32.f16 	%f48, %rs54;
	.loc	1 91 21
	mul.f32 	%f49, %f1, %f46;
	mul.f32 	%f50, %f1, %f45;
	.loc	1 94 30
	mul.f32 	%f51, %f44, %f48;
	mul.f32 	%f52, %f43, %f47;
	.loc	1 85 66
	mov.b32 	{%rs55, %rs56}, %r4;
	cvt.f32.f16 	%f53, %rs55;
	cvt.f32.f16 	%f54, %rs56;
	.loc	1 86 66
	mov.b32 	{%rs57, %rs58}, %r20;
	cvt.f32.f16 	%f55, %rs57;
	cvt.f32.f16 	%f56, %rs58;
	.loc	1 87 66
	mov.b32 	{%rs59, %rs60}, %r36;
	cvt.f32.f16 	%f57, %rs59;
	cvt.f32.f16 	%f58, %rs60;
	.loc	1 91 21
	mul.f32 	%f59, %f1, %f56;
	mul.f32 	%f60, %f1, %f55;
	.loc	1 94 30
	mul.f32 	%f61, %f54, %f58;
	mul.f32 	%f62, %f53, %f57;
	.loc	1 85 66
	mov.b32 	{%rs61, %rs62}, %r3;
	cvt.f32.f16 	%f63, %rs61;
	cvt.f32.f16 	%f64, %rs62;
	.loc	1 86 66
	mov.b32 	{%rs63, %rs64}, %r19;
	cvt.f32.f16 	%f65, %rs63;
	cvt.f32.f16 	%f66, %rs64;
	.loc	1 87 66
	mov.b32 	{%rs65, %rs66}, %r35;
	cvt.f32.f16 	%f67, %rs65;
	cvt.f32.f16 	%f68, %rs66;
	.loc	1 91 21
	mul.f32 	%f69, %f1, %f66;
	mul.f32 	%f70, %f1, %f65;
	.loc	1 94 30
	mul.f32 	%f71, %f64, %f68;
	mul.f32 	%f72, %f63, %f67;
	.loc	1 85 66
	mov.b32 	{%rs67, %rs68}, %r2;
	cvt.f32.f16 	%f73, %rs68;
	cvt.f32.f16 	%f74, %rs67;
	.loc	1 86 66
	mov.b32 	{%rs69, %rs70}, %r18;
	cvt.f32.f16 	%f75, %rs70;
	cvt.f32.f16 	%f76, %rs69;
	.loc	1 87 66
	mov.b32 	{%rs71, %rs72}, %r34;
	cvt.f32.f16 	%f77, %rs72;
	cvt.f32.f16 	%f78, %rs71;
	.loc	1 91 21
	mul.f32 	%f79, %f1, %f76;
	mul.f32 	%f80, %f1, %f75;
	.loc	1 94 30
	mul.f32 	%f81, %f74, %f78;
	mul.f32 	%f82, %f73, %f77;
	.loc	1 96 37
	mul.f32 	%f83, %f80, %f82;
$L__tmp3:
	.loc	2 256 15
	fma.rn.f32 	%f84, %f79, %f81, %f83;
	fma.rn.f32 	%f85, %f70, %f72, %f84;
	fma.rn.f32 	%f86, %f69, %f71, %f85;
	fma.rn.f32 	%f87, %f60, %f62, %f86;
	fma.rn.f32 	%f88, %f59, %f61, %f87;
	fma.rn.f32 	%f89, %f50, %f52, %f88;
	fma.rn.f32 	%f90, %f49, %f51, %f89;
	fma.rn.f32 	%f91, %f9, %f11, %f90;
	fma.rn.f32 	%f92, %f8, %f10, %f91;
	fma.rn.f32 	%f93, %f19, %f21, %f92;
	fma.rn.f32 	%f94, %f18, %f20, %f93;
	fma.rn.f32 	%f95, %f29, %f31, %f94;
	fma.rn.f32 	%f96, %f28, %f30, %f95;
	fma.rn.f32 	%f97, %f39, %f41, %f96;
	fma.rn.f32 	%f98, %f38, %f40, %f97;
	.loc	2 267 36
	mov.b32 	%r119, %f98;
	shfl.sync.bfly.b32	%r120, %r119, 16, 31, -1;
	mov.b32 	%f99, %r120;
	.loc	2 256 15
	add.f32 	%f100, %f98, %f99;
	.loc	2 267 36
	mov.b32 	%r121, %f100;
	shfl.sync.bfly.b32	%r122, %r121, 8, 31, -1;
	mov.b32 	%f101, %r122;
	.loc	2 256 15
	add.f32 	%f102, %f100, %f101;
	.loc	2 267 36
	mov.b32 	%r123, %f102;
	shfl.sync.bfly.b32	%r124, %r123, 4, 31, -1;
	mov.b32 	%f103, %r124;
	.loc	2 256 15
	add.f32 	%f104, %f102, %f103;
	.loc	2 267 36
	mov.b32 	%r125, %f104;
	shfl.sync.bfly.b32	%r126, %r125, 2, 31, -1;
	mov.b32 	%f105, %r126;
	.loc	2 256 15
	add.f32 	%f106, %f104, %f105;
	.loc	2 267 36
	mov.b32 	%r127, %f106;
	shfl.sync.bfly.b32	%r128, %r127, 1, 31, -1;
	mov.b32 	%f107, %r128;
	.loc	2 256 15
	add.f32 	%f108, %f106, %f107;
	.loc	2 267 36
	mov.b32 	%r52, %f108;
	// begin inline asm
	@%p32 st.shared.b32 [ %r51 + 0 ], %r52;
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p33 ld.shared.b32 %r53, [ %r54 + 0 ];
	// end inline asm
	mov.b32 	%f109, %r53;
	shfl.sync.bfly.b32	%r129, %r53, 4, 31, -1;
	mov.b32 	%f110, %r129;
	.loc	2 256 15
	add.f32 	%f111, %f109, %f110;
	.loc	2 267 36
	mov.b32 	%r130, %f111;
	shfl.sync.bfly.b32	%r131, %r130, 2, 31, -1;
	mov.b32 	%f112, %r131;
	.loc	2 256 15
	add.f32 	%f113, %f111, %f112;
	.loc	2 267 36
	mov.b32 	%r132, %f113;
	shfl.sync.bfly.b32	%r133, %r132, 1, 31, -1;
	mov.b32 	%f114, %r133;
	.loc	2 256 15
	add.f32 	%f115, %f113, %f114;
	.loc	2 267 36
	mov.b32 	%r56, %f115;
	// begin inline asm
	@%p34 st.shared.b32 [ %r54 + 0 ], %r56;
	// end inline asm
	bar.sync 	0;
	ld.shared.f32 	%f116, [global_smem];
$L__tmp4:
	.loc	1 97 21
	mov.b32 	%r59, %f42;
	// begin inline asm
	div.full.f32 %r57, %r58, %r59;
	// end inline asm
	mov.b32 	%f117, %r57;
	.loc	1 97 52
	mul.f32 	%f118, %f79, %f116;
	mul.f32 	%f119, %f80, %f116;
	mul.f32 	%f120, %f70, %f116;
	mul.f32 	%f121, %f69, %f116;
	mul.f32 	%f122, %f60, %f116;
	mul.f32 	%f123, %f59, %f116;
	mul.f32 	%f124, %f50, %f116;
	mul.f32 	%f125, %f49, %f116;
	.loc	1 97 45
	neg.f32 	%f126, %f119;
	fma.rn.f32 	%f127, %f82, %f42, %f126;
	neg.f32 	%f128, %f118;
	fma.rn.f32 	%f129, %f81, %f42, %f128;
	neg.f32 	%f130, %f121;
	fma.rn.f32 	%f131, %f71, %f42, %f130;
	neg.f32 	%f132, %f120;
	fma.rn.f32 	%f133, %f72, %f42, %f132;
	neg.f32 	%f134, %f123;
	fma.rn.f32 	%f135, %f61, %f42, %f134;
	neg.f32 	%f136, %f122;
	fma.rn.f32 	%f137, %f62, %f42, %f136;
	neg.f32 	%f138, %f125;
	fma.rn.f32 	%f139, %f51, %f42, %f138;
	neg.f32 	%f140, %f124;
	fma.rn.f32 	%f141, %f52, %f42, %f140;
	.loc	1 97 31
	mul.f32 	%f142, %f117, %f129;
	mul.f32 	%f143, %f117, %f127;
	mul.f32 	%f144, %f117, %f133;
	mul.f32 	%f145, %f117, %f131;
	mul.f32 	%f146, %f117, %f137;
	mul.f32 	%f147, %f117, %f135;
	mul.f32 	%f148, %f117, %f141;
	mul.f32 	%f149, %f117, %f139;
	.loc	1 98 31
	cvt.rn.f16.f32 	%rs73, %f143;
	cvt.rn.f16.f32 	%rs74, %f142;
	mov.b32 	%r134, {%rs74, %rs73};
	cvt.rn.f16.f32 	%rs75, %f145;
	cvt.rn.f16.f32 	%rs76, %f144;
	mov.b32 	%r135, {%rs76, %rs75};
	cvt.rn.f16.f32 	%rs77, %f147;
	cvt.rn.f16.f32 	%rs78, %f146;
	mov.b32 	%r136, {%rs78, %rs77};
	cvt.rn.f16.f32 	%rs79, %f149;
	cvt.rn.f16.f32 	%rs80, %f148;
	mov.b32 	%r137, {%rs80, %rs79};
	.loc	1 97 52
	mul.f32 	%f150, %f9, %f116;
	mul.f32 	%f151, %f8, %f116;
	.loc	1 97 45
	neg.f32 	%f152, %f151;
	fma.rn.f32 	%f153, %f10, %f42, %f152;
	neg.f32 	%f154, %f150;
	fma.rn.f32 	%f155, %f11, %f42, %f154;
	.loc	1 97 31
	mul.f32 	%f156, %f117, %f155;
	mul.f32 	%f157, %f117, %f153;
	.loc	1 98 31
	cvt.rn.f16.f32 	%rs81, %f157;
	cvt.rn.f16.f32 	%rs82, %f156;
	.loc	1 97 52
	mul.f32 	%f158, %f19, %f116;
	mul.f32 	%f159, %f18, %f116;
	.loc	1 97 45
	neg.f32 	%f160, %f159;
	fma.rn.f32 	%f161, %f20, %f42, %f160;
	neg.f32 	%f162, %f158;
	fma.rn.f32 	%f163, %f21, %f42, %f162;
	.loc	1 97 31
	mul.f32 	%f164, %f117, %f163;
	mul.f32 	%f165, %f117, %f161;
	.loc	1 98 31
	cvt.rn.f16.f32 	%rs83, %f165;
	cvt.rn.f16.f32 	%rs84, %f164;
	.loc	1 97 52
	mul.f32 	%f166, %f29, %f116;
	mul.f32 	%f167, %f28, %f116;
	.loc	1 97 45
	neg.f32 	%f168, %f167;
	fma.rn.f32 	%f169, %f30, %f42, %f168;
	neg.f32 	%f170, %f166;
	fma.rn.f32 	%f171, %f31, %f42, %f170;
	.loc	1 97 31
	mul.f32 	%f172, %f117, %f171;
	mul.f32 	%f173, %f117, %f169;
	.loc	1 98 31
	cvt.rn.f16.f32 	%rs85, %f173;
	cvt.rn.f16.f32 	%rs86, %f172;
	.loc	1 97 52
	mul.f32 	%f174, %f39, %f116;
	mul.f32 	%f175, %f38, %f116;
	.loc	1 97 45
	neg.f32 	%f176, %f175;
	fma.rn.f32 	%f177, %f40, %f42, %f176;
	neg.f32 	%f178, %f174;
	fma.rn.f32 	%f179, %f41, %f42, %f178;
	.loc	1 97 31
	mul.f32 	%f180, %f117, %f179;
	mul.f32 	%f181, %f117, %f177;
	.loc	1 98 31
	cvt.rn.f16.f32 	%rs87, %f181;
	cvt.rn.f16.f32 	%rs88, %f180;
	// begin inline asm
	@%p1 st.global.v4.b32 [ %rd1 + 0 ], { %r134, %r135, %r136, %r137 };
	// end inline asm
	mov.b32 	%r138, {%rs82, %rs81};
	mov.b32 	%r139, {%rs84, %rs83};
	mov.b32 	%r140, {%rs86, %rs85};
	mov.b32 	%r141, {%rs88, %rs87};
	// begin inline asm
	@%p6 st.global.v4.b32 [ %rd2 + 0 ], { %r138, %r139, %r140, %r141 };
	// end inline asm
	.loc	1 98 4
	ret;
$L__tmp5:
$L__func_end0:

}
	.file	1 "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/unsloth/kernels/rms_layernorm.py"
	.file	2 "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 1
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 2
.b8 46
.b8 0
.b8 3
.b8 8
.b8 32
.b8 11
.b8 0
.b8 0
.b8 3
.b8 46
.b8 1
.b8 17
.b8 1
.b8 18
.b8 1
.b8 49
.b8 19
.b8 0
.b8 0
.b8 4
.b8 29
.b8 0
.b8 49
.b8 19
.b8 17
.b8 1
.b8 18
.b8 1
.b8 88
.b8 11
.b8 89
.b8 11
.b8 87
.b8 11
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 210
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 114
.b8 109
.b8 115
.b8 95
.b8 108
.b8 97
.b8 121
.b8 101
.b8 114
.b8 110
.b8 111
.b8 114
.b8 109
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 47
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 122
.b8 101
.b8 117
.b8 115
.b8 47
.b8 109
.b8 105
.b8 110
.b8 105
.b8 99
.b8 111
.b8 110
.b8 100
.b8 97
.b8 51
.b8 47
.b8 101
.b8 110
.b8 118
.b8 115
.b8 47
.b8 99
.b8 108
.b8 111
.b8 117
.b8 100
.b8 115
.b8 112
.b8 97
.b8 99
.b8 101
.b8 47
.b8 108
.b8 105
.b8 98
.b8 47
.b8 112
.b8 121
.b8 116
.b8 104
.b8 111
.b8 110
.b8 51
.b8 46
.b8 49
.b8 49
.b8 47
.b8 115
.b8 105
.b8 116
.b8 101
.b8 45
.b8 112
.b8 97
.b8 99
.b8 107
.b8 97
.b8 103
.b8 101
.b8 115
.b8 47
.b8 117
.b8 110
.b8 115
.b8 108
.b8 111
.b8 116
.b8 104
.b8 47
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 115
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
.b8 2
.b8 95
.b8 114
.b8 109
.b8 115
.b8 95
.b8 108
.b8 97
.b8 121
.b8 101
.b8 114
.b8 110
.b8 111
.b8 114
.b8 109
.b8 95
.b8 98
.b8 97
.b8 99
.b8 107
.b8 119
.b8 97
.b8 114
.b8 100
.b8 0
.b8 1
.b8 3
.b64 $L__func_begin0
.b64 $L__func_end0
.b32 141
.b8 4
.b32 141
.b64 $L__tmp1
.b64 $L__tmp4
.b8 1
.b8 96
.b8 30
.b8 0
.b8 0
	}
	.section	.debug_loc	{	}
